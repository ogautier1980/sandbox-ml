{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz d'Auto-√âvaluation - Chapitre 07 : Deep Learning - CNN\n",
    "\n",
    "**Instructions** :\n",
    "- Ce quiz contient 15 questions pour tester votre compr√©hension du chapitre\n",
    "- R√©pondez aux questions par vous-m√™me avant de regarder les r√©ponses\n",
    "- Les r√©ponses sont dans une cellule masqu√©e √† la fin\n",
    "- Comptez 1 point par bonne r√©ponse\n",
    "\n",
    "**Bar√®me** :\n",
    "- 13-15 : Excellent ! Vous ma√Ætrisez le chapitre üí™\n",
    "- 10-12 : Bien, relisez les sections o√π vous avez des lacunes\n",
    "- 7-9 : Moyen, relisez le chapitre attentivement\n",
    "- < 7 : Insuffisant, reprenez le chapitre depuis le d√©but\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Question 1 : Motivation des CNN\n",
    "Parmi les limites suivantes des MLP pour traiter les images, laquelle est FAUSSE ?\n",
    "\n",
    "A) Nombre de param√®tres explosif pour des images haute r√©solution  \n",
    "B) Pas d'invariance spatiale (chat en haut √† gauche vs en bas √† droite)  \n",
    "C) Perte de structure 2D lors de l'aplatissement en vecteur 1D  \n",
    "D) Impossibilit√© d'utiliser des fonctions d'activation non-lin√©aires  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Op√©ration de Convolution\n",
    "Dans une convolution 2D, que repr√©sente le filtre (kernel) ?\n",
    "\n",
    "A) L'image d'entr√©e transform√©e  \n",
    "B) Une petite matrice de poids apprenables  \n",
    "C) La fonction d'activation  \n",
    "D) Le r√©sultat de la convolution  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : Taille de Sortie\n",
    "Entr√©e 32√ó32, filtre 5√ó5, padding 2, stride 1. Quelle est la taille de sortie ?\n",
    "\n",
    "A) 28√ó28  \n",
    "B) 30√ó30  \n",
    "C) 32√ó32  \n",
    "D) 36√ó36  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Param√®tres d'une Convolution\n",
    "Conv2D avec 64 filtres 3√ó3 sur entr√©e RGB (3 canaux). Combien de param√®tres (avec biais) ?\n",
    "\n",
    "A) 576  \n",
    "B) 1,728  \n",
    "C) 1,792  \n",
    "D) 27,648  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : Max Pooling\n",
    "Quelle est la principale fonction du Max Pooling ?\n",
    "\n",
    "A) Augmenter la r√©solution spatiale  \n",
    "B) Apprendre de nouveaux filtres  \n",
    "C) R√©duire la dimension spatiale et augmenter l'invariance locale  \n",
    "D) Calculer la moyenne des activations  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Architecture LeNet-5\n",
    "LeNet-5 (1998) a √©t√© con√ßu pour quelle t√¢che ?\n",
    "\n",
    "A) Classification d'images RGB (ImageNet)  \n",
    "B) Reconnaissance de chiffres manuscrits (MNIST)  \n",
    "C) D√©tection d'objets  \n",
    "D) Segmentation s√©mantique  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 : AlexNet (2012)\n",
    "Quelle innovation N'a PAS √©t√© introduite par AlexNet ?\n",
    "\n",
    "A) Utilisation de ReLU au lieu de Tanh  \n",
    "B) Dropout pour r√©gularisation  \n",
    "C) Skip connections (residual blocks)  \n",
    "D) Data augmentation intensive  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 : VGG\n",
    "Pourquoi VGG utilise exclusivement des filtres 3√ó3 ?\n",
    "\n",
    "A) Pour r√©duire le nombre de param√®tres par rapport √† des filtres plus grands  \n",
    "B) Pour augmenter la vitesse d'entra√Ænement  \n",
    "C) Car c'est obligatoire dans les CNN  \n",
    "D) Pour √©viter l'overfitting  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 : ResNet - Skip Connections\n",
    "Dans un bloc r√©siduel, que calcule-t-on ?\n",
    "\n",
    "A) $y = F(x)$  \n",
    "B) $y = F(x) + x$  \n",
    "C) $y = F(x) - x$  \n",
    "D) $y = F(x) \\times x$  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 : Avantage des Skip Connections\n",
    "Pourquoi les skip connections de ResNet permettent d'entra√Æner des r√©seaux tr√®s profonds ?\n",
    "\n",
    "A) Elles r√©duisent le nombre de param√®tres  \n",
    "B) Elles am√©liorent le gradient flow et √©vitent le vanishing gradient  \n",
    "C) Elles acc√©l√®rent l'entra√Ænement  \n",
    "D) Elles augmentent la taille des feature maps  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 : Transfer Learning - Feature Extraction\n",
    "Dans la strat√©gie \"Feature Extraction\" du transfer learning, que fait-on ?\n",
    "\n",
    "A) On entra√Æne tout le r√©seau from scratch  \n",
    "B) On g√®le les couches convolutionnelles et on entra√Æne uniquement la derni√®re couche FC  \n",
    "C) On entra√Æne tout le r√©seau avec un learning rate faible  \n",
    "D) On supprime toutes les couches FC  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 : Transfer Learning - Quand Fine-Tuner ?\n",
    "Selon les bonnes pratiques, quand doit-on faire du fine-tuning complet ?\n",
    "\n",
    "A) Avec moins de 1000 images  \n",
    "B) Avec 1K-10K images (fine-tuning des derni√®res couches)  \n",
    "C) Avec plus de 10K images  \n",
    "D) Jamais, feature extraction suffit toujours  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 : Data Augmentation\n",
    "Parmi ces techniques, laquelle N'est PAS une data augmentation classique ?\n",
    "\n",
    "A) RandomHorizontalFlip (flip horizontal)  \n",
    "B) RandomRotation (rotation al√©atoire)  \n",
    "C) Gradient Clipping  \n",
    "D) ColorJitter (perturbations de couleur)  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14 : Grad-CAM\n",
    "√Ä quoi sert Grad-CAM dans les CNN ?\n",
    "\n",
    "A) Acc√©l√©rer l'entra√Ænement  \n",
    "B) Visualiser quelles r√©gions de l'image influencent la pr√©diction  \n",
    "C) R√©duire l'overfitting  \n",
    "D) Augmenter la pr√©cision du mod√®le  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15 : Bonnes Pratiques Architecture\n",
    "Quelle pratique est recommand√©e pour les CNN modernes ?\n",
    "\n",
    "A) Utiliser des filtres 7√ó7 ou plus  \n",
    "B) Ne jamais utiliser de Batch Normalization  \n",
    "C) Doubler les canaux quand on divise la r√©solution spatiale par 2  \n",
    "D) √âviter les skip connections  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Auto-Correction\n",
    "\n",
    "Avant de regarder les r√©ponses, comptez combien de r√©ponses vous avez donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrez vos r√©ponses ici (ex: ['D', 'B', 'A', ...])\n",
    "mes_reponses = []  # TODO: remplir avec vos r√©ponses\n",
    "\n",
    "# R√©ponses correctes (masqu√©es)\n",
    "reponses_correctes = ['D', 'B', 'C', 'C', 'C', 'B', 'C', 'A', 'B', 'B', 'B', 'C', 'C', 'B', 'C']\n",
    "\n",
    "if len(mes_reponses) == 15:\n",
    "    score = sum([1 for i, r in enumerate(mes_reponses) if r.upper() == reponses_correctes[i]])\n",
    "    print(f\"Votre score : {score}/15\")\n",
    "    \n",
    "    if score >= 13:\n",
    "        print(\"\\nüéâ Excellent ! Vous ma√Ætrisez le chapitre !\")\n",
    "    elif score >= 10:\n",
    "        print(\"\\n‚úÖ Bien ! Relisez les sections o√π vous avez des lacunes.\")\n",
    "    elif score >= 7:\n",
    "        print(\"\\n‚ö†Ô∏è  Moyen. Relisez le chapitre attentivement.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Insuffisant. Reprenez le chapitre depuis le d√©but.\")\n",
    "    \n",
    "    # Afficher les erreurs\n",
    "    print(\"\\nD√©tail :\")\n",
    "    for i, (ma_rep, bonne_rep) in enumerate(zip(mes_reponses, reponses_correctes), 1):\n",
    "        if ma_rep.upper() == bonne_rep:\n",
    "            print(f\"Q{i}: ‚úì Correct\")\n",
    "        else:\n",
    "            print(f\"Q{i}: ‚úó Votre r√©ponse: {ma_rep}, Correcte: {bonne_rep}\")\n",
    "else:\n",
    "    print(\"Veuillez remplir toutes les r√©ponses (15 lettres A, B, C ou D)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Explications des R√©ponses\n",
    "\n",
    "### Q1 : D\n",
    "**FAUX** : Les MLP peuvent utiliser des fonctions d'activation non-lin√©aires (ReLU, Sigmoid, etc.). Le vrai probl√®me est le nombre de param√®tres, la perte de structure 2D et l'absence d'invariance spatiale.\n",
    "\n",
    "### Q2 : B\n",
    "Le **filtre (kernel)** est une petite matrice de **poids apprenables** (ex: 3√ó3, 5√ó5) qui \"glisse\" sur l'image pour d√©tecter des features.\n",
    "\n",
    "### Q3 : C\n",
    "Formule : $H_{out} = \\lfloor (H + 2p - k)/s \\rfloor + 1 = \\lfloor (32 + 2 \\times 2 - 5)/1 \\rfloor + 1 = 32$. Le padding=2 est choisi pour avoir \"same padding\" (sortie m√™me taille).\n",
    "\n",
    "### Q4 : C\n",
    "Formule : $(k \\times k \\times C_{in} + 1) \\times C_{out} = (3 \\times 3 \\times 3 + 1) \\times 64 = 28 \\times 64 = 1{,}792$.\n",
    "\n",
    "### Q5 : C\n",
    "Le **Max Pooling** r√©duit la dimension spatiale (sous-√©chantillonnage), augmente l'invariance locale par translation, et r√©duit le nombre de param√®tres dans les couches suivantes.\n",
    "\n",
    "### Q6 : B\n",
    "**LeNet-5** (1998) de Yann LeCun a √©t√© con√ßu pour la **reconnaissance de chiffres manuscrits** sur le dataset MNIST.\n",
    "\n",
    "### Q7 : C\n",
    "Les **skip connections** ont √©t√© introduites par **ResNet (2015)**, pas par AlexNet (2012). AlexNet a introduit ReLU, Dropout, data augmentation et GPU training.\n",
    "\n",
    "### Q8 : A\n",
    "VGG utilise des filtres **3√ó3** car 2 convolutions 3√ó3 donnent un champ r√©cepteur de 5√ó5 mais avec **moins de param√®tres** ($18C^2$ vs $25C^2$) et **plus de non-lin√©arit√©** (2 ReLU au lieu de 1).\n",
    "\n",
    "### Q9 : B\n",
    "Un **bloc r√©siduel** calcule $y = F(x) + x$, o√π $F(x)$ est appris par les couches convolutionnelles. La connexion $+x$ est la \"skip connection\".\n",
    "\n",
    "### Q10 : B\n",
    "Les skip connections am√©liorent le **gradient flow** : le gradient peut se propager directement via la connexion $+x$, √©vitant le **vanishing gradient** dans les r√©seaux tr√®s profonds.\n",
    "\n",
    "### Q11 : B\n",
    "**Feature Extraction** : on **g√®le** (freeze) toutes les couches convolutionnelles pr√©-entra√Æn√©es et on entra√Æne uniquement la nouvelle couche FC (pour notre t√¢che sp√©cifique).\n",
    "\n",
    "### Q12 : C\n",
    "**R√®gle g√©n√©rale** : \n",
    "- < 1K images ‚Üí Feature extraction\n",
    "- 1K-10K images ‚Üí Fine-tuning des derni√®res couches\n",
    "- \\> 10K images ‚Üí Fine-tuning complet ou entra√Ænement from scratch\n",
    "\n",
    "### Q13 : C\n",
    "**Gradient Clipping** est une technique d'optimisation (limiter la norme du gradient), PAS une data augmentation. Les autres (flip, rotation, color jitter) sont bien des data augmentations.\n",
    "\n",
    "### Q14 : B\n",
    "**Grad-CAM** (Gradient-weighted Class Activation Mapping) permet de **visualiser quelles r√©gions** de l'image influencent la pr√©diction du CNN (interpr√©tabilit√©).\n",
    "\n",
    "### Q15 : C\n",
    "**Bonne pratique** : Quand on r√©duit la r√©solution spatiale (pooling ou stride=2), on **double le nombre de canaux** pour maintenir la capacit√© repr√©sentationnelle du r√©seau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prochaines √âtapes\n",
    "\n",
    "- **Score < 10** : Relisez le chapitre 07 attentivement, en particulier :\n",
    "  - Section 2 : Op√©ration de convolution et calcul de taille\n",
    "  - Section 5 : Architectures classiques (LeNet, AlexNet, VGG, ResNet)\n",
    "  - Section 7 : Transfer Learning\n",
    "\n",
    "- **Score >= 10** : Passez au Chapitre 08 (Deep Learning : RNN et Transformers)\n",
    "\n",
    "- **Notebooks recommand√©s** :\n",
    "  - `07_demo_lenet_cifar.ipynb` : LeNet-5 sur CIFAR-10\n",
    "  - `07_demo_resnet_transfer.ipynb` : Transfer Learning avec ResNet\n",
    "  - `07_exercices.ipynb` : Exercices pratiques\n",
    "\n",
    "- **R√©vision** : Refaites le quiz dans 2-3 jours pour ancrer les connaissances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
