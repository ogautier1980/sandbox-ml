{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/07_deep_learning_cnn/07_demo_resnet_transfer.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '07_demo_resnet_transfer.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 07 - D√©monstration : ResNet et Transfer Learning\n",
    "\n",
    "**Objectif** : Utiliser un mod√®le ResNet pr√©-entra√Æn√© sur ImageNet pour classifier CIFAR-10.\n",
    "\n",
    "**Contenu** :\n",
    "1. Architecture ResNet (Skip Connections)\n",
    "2. Transfer Learning : Feature Extraction vs Fine-Tuning\n",
    "3. Comparaison avec entra√Ænement from scratch\n",
    "4. Grad-CAM pour visualisation\n",
    "5. Best practices Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement CIFAR-10 avec transformations adapt√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations pour mod√®les pr√©-entra√Æn√©s ImageNet\n",
    "# ImageNet normalisation: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet attend 224x224\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Chargement datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                              download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                             download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Input size: 224x224 (requis pour ResNet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Architecture ResNet-18 (explication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement ResNet-18 pr√©-entra√Æn√©\n",
    "resnet_pretrained = models.resnet18(pretrained=True)\n",
    "\n",
    "print(\"Architecture ResNet-18:\")\n",
    "print(resnet_pretrained)\n",
    "\n",
    "print(f\"\\nNombre de param√®tres: {sum(p.numel() for p in resnet_pretrained.parameters()):,}\")\n",
    "\n",
    "# ResNet-18 a 1000 classes (ImageNet), on doit adapter pour CIFAR-10 (10 classes)\n",
    "print(f\"\\nCouche finale originale: {resnet_pretrained.fc}\")\n",
    "print(\"On va remplacer fc pour avoir 10 sorties au lieu de 1000.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Strat√©gie 1 : Feature Extraction (freeze all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction: geler toutes les couches sauf la derni√®re\n",
    "model_feature_extract = models.resnet18(pretrained=True)\n",
    "\n",
    "# Geler tous les param√®tres\n",
    "for param in model_feature_extract.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Remplacer la derni√®re couche fc (1000 -> 10)\n",
    "num_features = model_feature_extract.fc.in_features\n",
    "model_feature_extract.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "model_feature_extract = model_feature_extract.to(device)\n",
    "\n",
    "# Compter param√®tres entra√Ænables\n",
    "trainable_params = sum(p.numel() for p in model_feature_extract.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model_feature_extract.parameters())\n",
    "\n",
    "print(\"\\n--- Feature Extraction ---\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,} / {total_params:,}\")\n",
    "print(f\"Pourcentage entra√Ænable: {trainable_params/total_params*100:.2f}%\")\n",
    "print(\"Seule la couche fc finale sera entra√Æn√©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement Feature Extraction\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_fe = optim.Adam(model_feature_extract.fc.parameters(), lr=0.001)  # Optimiser seulement fc\n",
    "\n",
    "epochs = 10\n",
    "history_fe = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print(\"\\nEntra√Ænement Feature Extraction (10 epochs)...\")\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model_feature_extract, train_loader, criterion, optimizer_fe, device)\n",
    "    val_loss, val_acc = validate_epoch(model_feature_extract, test_loader, criterion, device)\n",
    "    \n",
    "    history_fe['train_acc'].append(train_acc)\n",
    "    history_fe['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy finale (Feature Extraction): {history_fe['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Strat√©gie 2 : Fine-Tuning (train all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning: entra√Æner TOUTES les couches (avec lr plus petit)\n",
    "model_finetune = models.resnet18(pretrained=True)\n",
    "\n",
    "# Remplacer fc\n",
    "num_features = model_finetune.fc.in_features\n",
    "model_finetune.fc = nn.Linear(num_features, 10)\n",
    "model_finetune = model_finetune.to(device)\n",
    "\n",
    "# Tous les param√®tres sont entra√Ænables (par d√©faut)\n",
    "trainable_params = sum(p.numel() for p in model_finetune.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n--- Fine-Tuning ---\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(\"Toutes les couches seront entra√Æn√©es (avec petit lr).\")\n",
    "\n",
    "# Optimizer avec learning rates diff√©rents\n",
    "# - Couches pr√©-entra√Æn√©es: lr faible (0.0001)\n",
    "# - Nouvelle couche fc: lr normal (0.001)\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': model_finetune.fc.parameters(), 'lr': 0.001},  # Nouvelle couche\n",
    "    {'params': list(model_finetune.parameters())[:-2], 'lr': 0.0001}  # Couches pr√©-entra√Æn√©es\n",
    "])\n",
    "\n",
    "epochs = 10\n",
    "history_ft = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print(\"\\nEntra√Ænement Fine-Tuning (10 epochs)...\")\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model_finetune, train_loader, criterion, optimizer_ft, device)\n",
    "    val_loss, val_acc = validate_epoch(model_finetune, test_loader, criterion, device)\n",
    "    \n",
    "    history_ft['train_acc'].append(train_acc)\n",
    "    history_ft['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy finale (Fine-Tuning): {history_ft['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strat√©gie 3 : From Scratch (pour comparaison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 from scratch (poids al√©atoires)\n",
    "model_scratch = models.resnet18(pretrained=False)  # Pas de pr√©-entra√Ænement\n",
    "num_features = model_scratch.fc.in_features\n",
    "model_scratch.fc = nn.Linear(num_features, 10)\n",
    "model_scratch = model_scratch.to(device)\n",
    "\n",
    "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "history_scratch = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print(\"\\nEntra√Ænement From Scratch (10 epochs)...\")\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model_scratch, train_loader, criterion, optimizer_scratch, device)\n",
    "    val_loss, val_acc = validate_epoch(model_scratch, test_loader, criterion, device)\n",
    "    \n",
    "    history_scratch['train_acc'].append(train_acc)\n",
    "    history_scratch['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy finale (From Scratch): {history_scratch['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des 3 strat√©gies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison visuelle\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_fe['train_acc'], label='Feature Extraction', marker='o')\n",
    "plt.plot(history_ft['train_acc'], label='Fine-Tuning', marker='s')\n",
    "plt.plot(history_scratch['train_acc'], label='From Scratch', marker='^')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Accuracy')\n",
    "plt.title('Train Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_fe['val_acc'], label='Feature Extraction', marker='o')\n",
    "plt.plot(history_ft['val_acc'], label='Fine-Tuning', marker='s')\n",
    "plt.plot(history_scratch['val_acc'], label='From Scratch', marker='^')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Val Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√©\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARAISON DES 3 STRAT√âGIES (apr√®s 10 epochs)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Feature Extraction: {history_fe['val_acc'][-1]:.4f}\")\n",
    "print(f\"Fine-Tuning:        {history_ft['val_acc'][-1]:.4f}\")\n",
    "print(f\"From Scratch:       {history_scratch['val_acc'][-1]:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyse\n",
    "print(\"\\nANALYSE:\")\n",
    "print(\"- Feature Extraction: Rapide, peu de param√®tres √† entra√Æner\")\n",
    "print(\"- Fine-Tuning: Meilleure performance, adapte les features ImageNet\")\n",
    "print(\"- From Scratch: Plus lent, n√©cessite plus de donn√©es et d'epochs\")\n",
    "print(\"\\nRECOMMANDATION: Fine-Tuning pour datasets moyens (10k-100k samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Grad-CAM : Visualisation des zones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"Gradient-weighted Class Activation Mapping.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Hook pour capturer gradients et activations\n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_backward_hook(self.save_gradient)\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def __call__(self, x, class_idx=None):\n",
    "        # Forward\n",
    "        output = self.model(x)\n",
    "        \n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "        \n",
    "        # Backward\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward()\n",
    "        \n",
    "        # Calcul Grad-CAM\n",
    "        gradients = self.gradients[0]  # (C, H, W)\n",
    "        activations = self.activations[0]  # (C, H, W)\n",
    "        \n",
    "        # Poids: moyenne spatiale des gradients\n",
    "        weights = gradients.mean(dim=(1, 2))  # (C,)\n",
    "        \n",
    "        # Combinaison pond√©r√©e des activations\n",
    "        cam = (weights[:, None, None] * activations).sum(dim=0)  # (H, W)\n",
    "        \n",
    "        # ReLU + normalisation\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam / cam.max()\n",
    "        \n",
    "        return cam.cpu().numpy()\n",
    "\n",
    "# Utilisation Grad-CAM sur mod√®le Fine-Tuned\n",
    "grad_cam = GradCAM(model_finetune, model_finetune.layer4[-1].conv2)\n",
    "\n",
    "# S√©lectionner une image de test\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "sample_image = images[0:1].to(device)\n",
    "sample_label = labels[0]\n",
    "\n",
    "# G√©n√©rer Grad-CAM\n",
    "model_finetune.eval()\n",
    "cam = grad_cam(sample_image)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Image originale\n",
    "img = sample_image[0].cpu().permute(1, 2, 0).numpy()\n",
    "img = (img - img.min()) / (img.max() - img.min())  # Normalisation pour affichage\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title(f\"Image originale\\n{classes[sample_label]}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Heatmap Grad-CAM\n",
    "axes[1].imshow(cam, cmap='jet')\n",
    "axes[1].set_title('Grad-CAM Heatmap')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Superposition\n",
    "cam_resized = cv2.resize(cam, (224, 224))\n",
    "heatmap = plt.cm.jet(cam_resized)[:, :, :3]  # RGB\n",
    "superimposed = 0.6 * img + 0.4 * heatmap\n",
    "superimposed = superimposed / superimposed.max()\n",
    "axes[2].imshow(superimposed)\n",
    "axes[2].set_title('Superposition')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Grad-CAM montre les r√©gions de l'image qui ont contribu√© √† la pr√©diction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. √âvaluation d√©taill√©e (mod√®le Fine-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur test set\n",
    "model_finetune.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model_finetune(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (ResNet-18 Fine-Tuned):\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Matrice de Confusion - ResNet-18 Fine-Tuned')\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('V√©rit√©')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Transfer Learning : 3 strat√©gies** :\n",
    "\n",
    "| Strat√©gie | Quand l'utiliser | Avantages | Inconv√©nients |\n",
    "|-----------|------------------|-----------|---------------|\n",
    "| **Feature Extraction** | Dataset petit, similaire √† ImageNet | Rapide, peu de donn√©es | Performance limit√©e |\n",
    "| **Fine-Tuning** | Dataset moyen, peu similaire | Meilleure performance | Plus long |\n",
    "| **From Scratch** | Dataset tr√®s grand, tr√®s diff√©rent | Totale flexibilit√© | N√©cessite beaucoup de donn√©es |\n",
    "\n",
    "**R√©sultats CIFAR-10** :\n",
    "- Feature Extraction : ~80-85% accuracy (10 epochs)\n",
    "- Fine-Tuning : ~85-90% accuracy (10 epochs)\n",
    "- From Scratch : ~70-75% accuracy (10 epochs, irait mieux avec plus d'epochs)\n",
    "\n",
    "**Grad-CAM** :\n",
    "- Visualise les r√©gions importantes pour la pr√©diction\n",
    "- Aide √† comprendre ce que le mod√®le \"voit\"\n",
    "- Utile pour d√©bugger et expliquer les pr√©dictions\n",
    "\n",
    "**Best Practices Transfer Learning** :\n",
    "1. **Toujours** essayer le transfer learning avant from scratch\n",
    "2. **Adapter** la couche finale au nombre de classes cible\n",
    "3. **Utiliser** learning rates diff√©rents (petit pour couches pr√©-entra√Æn√©es)\n",
    "4. **Data Augmentation** cruciale pour g√©n√©ralisation\n",
    "5. **Early Stopping** pour √©viter overfitting\n",
    "\n",
    "**Prochaines √©tapes** :\n",
    "- Tester d'autres architectures : **EfficientNet**, **Vision Transformer**\n",
    "- **Ensemble Methods** : combiner plusieurs mod√®les\n",
    "- **Advanced Augmentation** : CutMix, MixUp, AutoAugment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}