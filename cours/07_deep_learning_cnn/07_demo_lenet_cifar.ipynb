{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/07_deep_learning_cnn/07_demo_lenet_cifar.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '07_demo_lenet_cifar.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 07 - D√©monstration : LeNet-5 et CIFAR-10\n",
    "\n",
    "**Objectif** : Impl√©menter LeNet-5 (architecture CNN historique) et l'appliquer sur CIFAR-10.\n",
    "\n",
    "**Contenu** :\n",
    "1. Architecture LeNet-5 (Conv ‚Üí Pool ‚Üí Conv ‚Üí Pool ‚Üí FC)\n",
    "2. Training sur CIFAR-10 (images couleur 32x32)\n",
    "3. Visualisation des filtres et feature maps\n",
    "4. Data Augmentation pour am√©liorer performance\n",
    "5. Comparaison avec MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations (normalisation)\n",
    "transform_basic = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisation [-1, 1]\n",
    "])\n",
    "\n",
    "# Data Augmentation pour training\n",
    "transform_augmented = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Chargement CIFAR-10\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                              download=True, transform=transform_augmented)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                             download=True, transform=transform_basic)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation √©chantillons\n",
    "def imshow(img, title=None):\n",
    "    img = img / 2 + 0.5  # D√©normalisation\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Afficher 25 images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i].permute(1, 2, 0) / 2 + 0.5)\n",
    "    ax.set_title(classes[labels[i]])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Architecture LeNet-5 (adapt√©e pour CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"LeNet-5 modifi√©e pour CIFAR-10 (images 32x32 RGB).\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # Feature extraction (Convolutional layers)\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=0)  # 3 canaux RGB\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Classifier (Fully connected layers)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv1 + Pool1: 32x32x3 -> 28x28x6 -> 14x14x6\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "        \n",
    "        # Conv2 + Pool2: 14x14x6 -> 10x10x16 -> 5x5x16\n",
    "        x = self.pool2(self.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten: 5x5x16 = 400\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instanciation\n",
    "model = LeNet5(num_classes=10).to(device)\n",
    "\n",
    "# R√©sum√©\n",
    "print(model)\n",
    "print(f\"\\nNombre de param√®tres: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "dummy_output = model(dummy_input)\n",
    "print(f\"\\nInput shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {dummy_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "epochs = 20\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"\\nD√©but de l'entra√Ænement LeNet-5 sur CIFAR-10...\")\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate_epoch(model, test_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"\\nEntra√Ænement termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation des courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss pendant l\\'entra√Ænement')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy pendant l\\'entra√Ænement')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy finale: {history['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluation et matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Matrice de Confusion - CIFAR-10')\n",
    "plt.xlabel('Pr√©diction')\n",
    "plt.ylabel('V√©rit√©')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des filtres (Conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des poids de Conv1\n",
    "conv1_weights = model.conv1.weight.data.cpu().numpy()  # Shape: (6, 3, 5, 5)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Visualiser les 3 canaux RGB du filtre i\n",
    "    filter_rgb = conv1_weights[i].transpose(1, 2, 0)  # (5, 5, 3)\n",
    "    \n",
    "    # Normalisation pour affichage\n",
    "    filter_rgb = (filter_rgb - filter_rgb.min()) / (filter_rgb.max() - filter_rgb.min())\n",
    "    \n",
    "    ax.imshow(filter_rgb)\n",
    "    ax.set_title(f\"Filtre Conv1 #{i+1}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Filtres appris par Conv1 (6 filtres 5x5 RGB)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisation des feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook pour capturer les activations\n",
    "activations = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Enregistrer hooks\n",
    "model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "model.conv2.register_forward_hook(get_activation('conv2'))\n",
    "\n",
    "# Forward pass sur une image\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "sample_image = images[0:1].to(device)\n",
    "sample_label = labels[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(sample_image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "# Visualisation\n",
    "fig = plt.figure(figsize=(18, 8))\n",
    "\n",
    "# Image originale\n",
    "ax1 = plt.subplot(2, 7, 1)\n",
    "img = sample_image[0].cpu().permute(1, 2, 0) / 2 + 0.5\n",
    "ax1.imshow(img)\n",
    "ax1.set_title(f\"Original\\n{classes[sample_label]}\")\n",
    "ax1.axis('off')\n",
    "\n",
    "# Feature maps Conv1 (6 feature maps)\n",
    "conv1_features = activations['conv1'][0].cpu().numpy()  # (6, 28, 28)\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(2, 7, i + 2)\n",
    "    ax.imshow(conv1_features[i], cmap='viridis')\n",
    "    ax.set_title(f\"Conv1 FM{i+1}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Feature maps Conv2 (8 des 16 feature maps)\n",
    "conv2_features = activations['conv2'][0].cpu().numpy()  # (16, 10, 10)\n",
    "for i in range(7):\n",
    "    ax = plt.subplot(2, 7, i + 8)\n",
    "    ax.imshow(conv2_features[i], cmap='viridis')\n",
    "    ax.set_title(f\"Conv2 FM{i+1}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"Feature Maps pour: {classes[sample_label]} (Pr√©dit: {classes[predicted[0]]})\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison CNN vs MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP simple pour comparaison\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "mlp = SimpleMLP().to(device)\n",
    "optimizer_mlp = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"\\nLeNet-5 param√®tres: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"MLP param√®tres: {sum(p.numel() for p in mlp.parameters()):,}\")\n",
    "\n",
    "# Entra√Æner MLP (5 epochs seulement pour comparaison)\n",
    "print(\"\\nEntra√Ænement MLP (5 epochs)...\")\n",
    "mlp_history = {'train_acc': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_epoch(mlp, train_loader, criterion, optimizer_mlp, device)\n",
    "    val_loss, val_acc = validate_epoch(mlp, test_loader, criterion, device)\n",
    "    \n",
    "    mlp_history['train_acc'].append(train_acc)\n",
    "    mlp_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/5 | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Comparaison\n",
    "print(\"\\n--- Comparaison CNN vs MLP ---\")\n",
    "print(f\"LeNet-5 (20 epochs) - Val Acc: {history['val_acc'][-1]:.4f}\")\n",
    "print(f\"MLP (5 epochs) - Val Acc: {mlp_history['val_acc'][-1]:.4f}\")\n",
    "print(\"\\nCNN capture la structure spatiale des images -> Meilleure performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Points cl√©s** :\n",
    "1. **LeNet-5** : Architecture pionni√®re des CNN (LeCun, 1998)\n",
    "2. **Convolution** : Extrait des features locales (contours, textures)\n",
    "3. **Pooling** : R√©duit la dimensionnalit√©, invariance spatiale\n",
    "4. **Feature maps** : Visualisation des activations montre ce que le r√©seau \"voit\"\n",
    "5. **Data Augmentation** : Am√©liore g√©n√©ralisation (flip, crop, rotation)\n",
    "\n",
    "**R√©sultats CIFAR-10** :\n",
    "- LeNet-5 : ~65-70% accuracy (20 epochs)\n",
    "- MLP : ~45-50% accuracy (5 epochs)\n",
    "- CNN > MLP car capture structure spatiale\n",
    "\n",
    "**Limitations LeNet-5** :\n",
    "- Architecture peu profonde (2 couches conv)\n",
    "- Peu de filtres (6 et 16)\n",
    "- Pas de BatchNorm, Dropout, Skip Connections\n",
    "\n",
    "**Prochaines √©tapes** :\n",
    "- Architectures modernes : **VGG**, **ResNet**, **EfficientNet**\n",
    "- **Transfer Learning** : Pr√©-entra√Ænement sur ImageNet\n",
    "- **Data Augmentation avanc√©e** : Cutout, Mixup, AutoAugment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}