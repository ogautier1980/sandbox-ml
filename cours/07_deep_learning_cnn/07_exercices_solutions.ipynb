{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup",
    "",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/07_deep_learning_cnn/07_exercices_solutions.ipynb)",
    "",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)import sysIN_COLAB = 'google.colab' in sys.modulesif IN_COLAB:    print('üì¶ Installation des packages...')        # Packages ML de base    !pip install -q numpy pandas matplotlib seaborn scikit-learn        # D√©tection du chapitre et installation des d√©pendances sp√©cifiques    notebook_name = '07_exercices.ipynb'  # Sera remplac√© automatiquement        # Ch 06-08 : Deep Learning    if any(x in notebook_name for x in ['06_', '07_', '08_']):        !pip install -q torch torchvision torchaudio        # Ch 08 : NLP    if '08_' in notebook_name:        !pip install -q transformers datasets tokenizers        if 'rag' in notebook_name:            !pip install -q sentence-transformers faiss-cpu rank-bm25        # Ch 09 : Reinforcement Learning    if '09_' in notebook_name:        !pip install -q gymnasium[classic-control]        # Ch 04 : Boosting    if '04_' in notebook_name and 'boosting' in notebook_name:        !pip install -q xgboost lightgbm catboost        # Ch 05 : Clustering avanc√©    if '05_' in notebook_name:        !pip install -q umap-learn        # Ch 11 : S√©ries temporelles    if '11_' in notebook_name:        !pip install -q statsmodels prophet        # Ch 12 : Vision avanc√©e    if '12_' in notebook_name:        !pip install -q ultralytics timm segmentation-models-pytorch        # Ch 13 : Recommandation    if '13_' in notebook_name:        !pip install -q scikit-surprise implicit        # Ch 14 : MLOps    if '14_' in notebook_name:        !pip install -q mlflow fastapi pydantic        print('‚úÖ Installation termin√©e !')else:    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 07 - Solutions : CNN et Transfer Learning",
    "",
    "**Objectifs** :",
    "1. Impl√©menter des architectures CNN personnalis√©es",
    "2. Exp√©rimenter avec Transfer Learning",
    "3. Optimiser performance avec Data Augmentation",
    "4. Visualiser et interpr√©ter les pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch",
    "import torch.nn as nn",
    "import torch.optim as optim",
    "import torchvision",
    "import torchvision.transforms as transforms",
    "import torchvision.models as models",
    "from torch.utils.data import DataLoader",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "from sklearn.metrics import accuracy_score, classification_report",
    "import seaborn as sns",
    "",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
    "print(f\"Device: {device}\")",
    "",
    "torch.manual_seed(42)",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Impl√©menter VGG-like architecture",
    "",
    "**Objectif** : Cr√©er une architecture inspir√©e de VGG (blocs Conv-Conv-Pool).",
    "",
    "**Architecture cible** :",
    "- Block 1: Conv(32) -> Conv(32) -> MaxPool",
    "- Block 2: Conv(64) -> Conv(64) -> MaxPool",
    "- Block 3: Conv(128) -> Conv(128) -> MaxPool",
    "- Classifier: FC(512) -> FC(10)",
    "",
    "**TODO** :",
    "1. Impl√©menter la classe `VGGLike`",
    "2. Entra√Æner sur CIFAR-10 (10 epochs)",
    "3. Comparer avec LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLike(nn.Module):",
    "    \"\"\"Architecture VGG-like pour CIFAR-10.\"\"\"",
    "    ",
    "    def __init__(self, num_classes=10):",
    "        super(VGGLike, self).__init__()",
    "        ",
    "        # SOLUTION: Impl√©menter les blocs convolutifs",
    "        # Block 1: 3 -> 32 -> 32, puis MaxPool",
    "        # Block 2: 32 -> 64 -> 64, puis MaxPool",
    "        # Block 3: 64 -> 128 -> 128, puis MaxPool",
    "        ",
    "        # SOLUTION: Impl√©menter le classifier",
    "        # Flatten -> FC(512) -> ReLU -> Dropout(0.5) -> FC(10)",
    "        ",
    "        pass",
    "    ",
    "    def forward(self, x):",
    "        # SOLUTION: Forward pass",
    "        pass",
    "",
    "# SOLUTION: Instancier, entra√Æner et √©valuer",
    "# model = VGGLike().to(device)",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)",
    "# criterion = nn.CrossEntropyLoss()",
    "",
    "# SOLUTION: Comparer accuracy avec LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Impl√©menter Residual Block",
    "",
    "**Objectif** : Comprendre les skip connections en impl√©mentant un bloc r√©siduel.",
    "",
    "**TODO** :",
    "1. Impl√©menter `ResidualBlock` avec skip connection",
    "2. Cr√©er un petit ResNet (3 blocs r√©siduels)",
    "3. Comparer avec CNN classique (sans skip connections)",
    "4. Analyser la stabilit√© du gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):",
    "    \"\"\"Bloc r√©siduel : F(x) + x.\"\"\"",
    "    ",
    "    def __init__(self, in_channels, out_channels, stride=1):",
    "        super(ResidualBlock, self).__init__()",
    "        ",
    "        # SOLUTION: Impl√©menter le bloc r√©siduel",
    "        # conv1 (3x3) -> BN -> ReLU -> conv2 (3x3) -> BN",
    "        ",
    "        # SOLUTION: Shortcut connection (si in_channels != out_channels)",
    "        # Utiliser Conv 1x1 pour adapter dimensions",
    "        ",
    "        pass",
    "    ",
    "    def forward(self, x):",
    "        # SOLUTION: Forward avec skip connection",
    "        # out = F(x) + shortcut(x)",
    "        # out = ReLU(out)",
    "        pass",
    "",
    "class TinyResNet(nn.Module):",
    "    \"\"\"Petit ResNet avec 3 blocs r√©siduels.\"\"\"",
    "    ",
    "    def __init__(self, num_classes=10):",
    "        super(TinyResNet, self).__init__()",
    "        ",
    "        # SOLUTION: Impl√©menter",
    "        # - Conv initiale 3x3",
    "        # - 3 ResidualBlocks",
    "        # - Global Average Pooling",
    "        # - FC finale",
    "        pass",
    "    ",
    "    def forward(self, x):",
    "        # SOLUTION: Forward pass",
    "        pass",
    "",
    "# SOLUTION: Entra√Æner TinyResNet et comparer avec CNN classique",
    "# - Loss convergence plus rapide?",
    "# - Gradient vanishing moins probl√©matique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Data Augmentation Impact",
    "",
    "**Objectif** : Mesurer l'impact de la data augmentation sur la g√©n√©ralisation.",
    "",
    "**TODO** :",
    "1. Entra√Æner 2 mod√®les identiques:",
    "   - Mod√®le A: Aucune augmentation",
    "   - Mod√®le B: Augmentation agressive",
    "2. Comparer overfitting (train vs val accuracy)",
    "3. Tester robustesse aux transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: D√©finir 2 transformations",
    "# Transform 1: Seulement ToTensor + Normalize",
    "# Transform 2: RandomCrop, RandomHorizontalFlip, ColorJitter, RandomRotation",
    "",
    "# SOLUTION: Cr√©er 2 datasets avec transformations diff√©rentes",
    "",
    "# SOLUTION: Entra√Æner 2 mod√®les identiques (ex: LeNet-5)",
    "",
    "# SOLUTION: Comparer:",
    "# - Gap train-val accuracy",
    "# - Robustesse aux images transform√©es (rotation, crop, etc.)",
    "",
    "# SOLUTION: Visualiser exemples d'augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 : Transfer Learning sur Custom Dataset",
    "",
    "**Objectif** : Appliquer transfer learning sur un nouveau dataset (CIFAR-100).",
    "",
    "**TODO** :",
    "1. Charger CIFAR-100 (100 classes)",
    "2. Tester 3 mod√®les pr√©-entra√Æn√©s:",
    "   - ResNet-18",
    "   - ResNet-50",
    "   - EfficientNet-B0",
    "3. Comparer performance et temps d'entra√Ænement",
    "4. Analyser classes les plus difficiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement CIFAR-100",
    "# SOLUTION: Charger train/test datasets",
    "# CIFAR-100 a 100 classes fines (ex: apple, aquarium_fish, baby, etc.)",
    "",
    "# SOLUTION: Adapter 3 mod√®les pr√©-entra√Æn√©s pour 100 classes",
    "# resnet18 = models.resnet18(pretrained=True)",
    "# resnet18.fc = nn.Linear(resnet18.fc.in_features, 100)",
    "",
    "# resnet50 = models.resnet50(pretrained=True)",
    "# resnet50.fc = nn.Linear(resnet50.fc.in_features, 100)",
    "",
    "# efficientnet = models.efficientnet_b0(pretrained=True)",
    "# efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, 100)",
    "",
    "# SOLUTION: Entra√Æner les 3 mod√®les (10 epochs) et comparer:",
    "# - Accuracy finale",
    "# - Temps d'entra√Ænement par epoch",
    "# - Nombre de param√®tres",
    "",
    "# SOLUTION: Identifier les 5 classes les plus difficiles (worst accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 : Visualisation Feature Maps",
    "",
    "**Objectif** : Visualiser l'√©volution des feature maps √† travers les couches.",
    "",
    "**TODO** :",
    "1. Extraire feature maps de toutes les couches Conv d'un ResNet",
    "2. Visualiser 16 feature maps par couche",
    "3. Analyser l'√©volution des features (low-level -> high-level)",
    "4. Comparer pour diff√©rentes classes d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Charger ResNet-18 pr√©-entra√Æn√©",
    "",
    "# SOLUTION: Enregistrer hooks sur toutes les couches Conv",
    "# Couches cibles: layer1, layer2, layer3, layer4",
    "",
    "# SOLUTION: Forward pass sur une image",
    "",
    "# SOLUTION: Visualiser 16 feature maps pour chaque couche",
    "# - Layer 1: features bas niveau (contours, textures)",
    "# - Layer 4: features haut niveau (objets, formes complexes)",
    "",
    "# SOLUTION: Comparer pour 3 images de classes diff√©rentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6 : Impl√©mentation Grad-CAM from Scratch",
    "",
    "**Objectif** : Impl√©menter Grad-CAM pour comprendre le m√©canisme.",
    "",
    "**TODO** :",
    "1. Impl√©menter la fonction `grad_cam(model, image, target_class)`",
    "2. Visualiser heatmaps pour 10 images",
    "3. Comparer heatmaps pour bonne vs mauvaise pr√©diction",
    "4. Analyser si le mod√®le \"regarde\" les bonnes zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(model, image, target_class, target_layer):",
    "    \"\"\"",
    "    Calcule Grad-CAM pour une image donn√©e.",
    "    ",
    "    Parameters",
    "    ----------",
    "    model : nn.Module",
    "        Mod√®le CNN",
    "    image : torch.Tensor",
    "        Image (1, C, H, W)",
    "    target_class : int",
    "        Classe cible",
    "    target_layer : nn.Module",
    "        Couche o√π extraire Grad-CAM (ex: model.layer4)",
    "    ",
    "    Returns",
    "    -------",
    "    cam : np.ndarray",
    "        Heatmap Grad-CAM (H, W)",
    "    \"\"\"",
    "    # SOLUTION: Impl√©menter Grad-CAM",
    "    # 1. Enregistrer hook pour capturer activations et gradients",
    "    # 2. Forward pass",
    "    # 3. Backward sur la classe cible",
    "    # 4. Calculer poids: moyenne spatiale des gradients",
    "    # 5. Combinaison pond√©r√©e: sum(weights * activations)",
    "    # 6. ReLU + normalisation",
    "    pass",
    "",
    "# SOLUTION: Tester sur 10 images de CIFAR-10",
    "# SOLUTION: Visualiser c√¥te √† c√¥te: image, heatmap, superposition",
    "",
    "# SOLUTION: Analyser:",
    "# - Le mod√®le regarde-t-il les bonnes zones?",
    "# - Diff√©rence entre bonnes et mauvaises pr√©dictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 7 : Optimisation Architecture",
    "",
    "**Objectif** : Trouver la meilleure architecture pour CIFAR-10 avec contrainte de param√®tres.",
    "",
    "**Contrainte** : < 500k param√®tres",
    "",
    "**TODO** :",
    "1. Tester 5 architectures diff√©rentes:",
    "   - Shallow & Wide (peu de couches, beaucoup de filtres)",
    "   - Deep & Narrow (beaucoup de couches, peu de filtres)",
    "   - Avec/sans BatchNorm",
    "   - Avec/sans Dropout",
    "   - Avec/sans Skip Connections",
    "2. Comparer performance et temps d'entra√Ænement",
    "3. Identifier la meilleure architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: D√©finir 5 architectures",
    "",
    "# Architecture 1: Shallow & Wide",
    "# 3 Conv layers (128, 256, 512 filtres)",
    "",
    "# Architecture 2: Deep & Narrow",
    "# 6 Conv layers (32, 32, 64, 64, 128, 128)",
    "",
    "# Architecture 3: Deep + BatchNorm",
    "# 6 Conv layers + BatchNorm apr√®s chaque Conv",
    "",
    "# Architecture 4: Deep + Dropout",
    "# 6 Conv layers + Dropout(0.3) apr√®s Pooling",
    "",
    "# Architecture 5: Tiny ResNet",
    "# 4 Residual Blocks",
    "",
    "# SOLUTION: Entra√Æner les 5 architectures (20 epochs)",
    "",
    "# SOLUTION: Comparer:",
    "# - Accuracy finale",
    "# - Temps d'entra√Ænement total",
    "# - Nombre de param√®tres",
    "# - Overfitting (train-val gap)",
    "",
    "# SOLUTION: Cr√©er un tableau r√©capitulatif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 8 : Mini-Projet - Classification Dogs vs Cats",
    "",
    "**Objectif** : Projet complet de classification binaire avec Transfer Learning.",
    "",
    "**Dataset** : Utiliser un subset de Dogs vs Cats (Kaggle)",
    "",
    "**TODO** :",
    "1. T√©l√©charger/cr√©er un petit dataset (1000 images par classe)",
    "2. Appliquer Transfer Learning avec ResNet-50",
    "3. Fine-tuning avec data augmentation agressive",
    "4. Atteindre >95% accuracy sur test set",
    "5. Analyser erreurs avec Grad-CAM",
    "6. D√©ployer un mini-classifieur interactif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Cr√©er dataset Dogs vs Cats",
    "# Structure:",
    "# data/",
    "#   train/",
    "#     dogs/",
    "#     cats/",
    "#   test/",
    "#     dogs/",
    "#     cats/",
    "",
    "# SOLUTION: Utiliser ImageFolder de PyTorch",
    "# from torchvision.datasets import ImageFolder",
    "",
    "# SOLUTION: Data Augmentation agressive:",
    "# - RandomResizedCrop",
    "# - RandomHorizontalFlip",
    "# - ColorJitter",
    "# - RandomRotation",
    "# - RandomGrayscale",
    "",
    "# SOLUTION: Transfer Learning avec ResNet-50",
    "# - Feature Extraction: 5 epochs",
    "# - Fine-Tuning: 10 epochs",
    "",
    "# SOLUTION: √âvaluation compl√®te:",
    "# - Accuracy, Precision, Recall, F1-Score",
    "# - Confusion Matrix",
    "# - ROC Curve et AUC",
    "",
    "# SOLUTION: Grad-CAM sur erreurs de classification",
    "# - Identifier pourquoi le mod√®le se trompe",
    "",
    "# SOLUTION: (Bonus) Cr√©er une interface Gradio pour uploader une image",
    "# import gradio as gr",
    "# def classify(image):",
    "#     # Predict dog or cat",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions et Indices",
    "",
    "### Exercice 1 - VGG-like",
    "```python",
    "self.features = nn.Sequential(",
    "    # Block 1",
    "    nn.Conv2d(3, 32, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.Conv2d(32, 32, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.MaxPool2d(2, 2),",
    "    ",
    "    # Block 2",
    "    nn.Conv2d(32, 64, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.Conv2d(64, 64, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.MaxPool2d(2, 2),",
    "    ",
    "    # Block 3",
    "    nn.Conv2d(64, 128, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.Conv2d(128, 128, 3, padding=1),",
    "    nn.ReLU(),",
    "    nn.MaxPool2d(2, 2)",
    ")",
    "```",
    "",
    "### Exercice 2 - Residual Block",
    "```python",
    "def forward(self, x):",
    "    identity = x",
    "    ",
    "    out = self.conv1(x)",
    "    out = self.bn1(out)",
    "    out = self.relu(out)",
    "    ",
    "    out = self.conv2(out)",
    "    out = self.bn2(out)",
    "    ",
    "    if self.shortcut:",
    "        identity = self.shortcut(x)",
    "    ",
    "    out += identity  # Skip connection!",
    "    out = self.relu(out)",
    "    ",
    "    return out",
    "```",
    "",
    "### Exercice 3 - Data Augmentation",
    "Augmentation agressive am√©liore g√©n√©ralisation:",
    "- R√©duit overfitting (train-val gap plus petit)",
    "- Mod√®le plus robuste aux variations",
    "- N√©cessite plus d'epochs pour converger",
    "",
    "### Exercice 6 - Grad-CAM",
    "```python",
    "# Poids: moyenne spatiale des gradients",
    "weights = gradients.mean(dim=(2, 3))  # (C,)",
    "",
    "# Combinaison pond√©r√©e",
    "cam = torch.zeros(activations.shape[2:], dtype=torch.float32)",
    "for i, w in enumerate(weights):",
    "    cam += w * activations[i]",
    "",
    "# ReLU + normalisation",
    "cam = torch.relu(cam)",
    "cam = cam / cam.max()",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}