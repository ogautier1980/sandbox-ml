{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/00_introduction/00_exercices.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "\n",
    "    print('üì¶ Installation des packages...')\n",
    "\n",
    "    \n",
    "\n",
    "    # Packages ML de base\n",
    "\n",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "    \n",
    "\n",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques\n",
    "\n",
    "    notebook_name = '00_exercices.ipynb'  # Sera remplac√© automatiquement\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 06-08 : Deep Learning\n",
    "\n",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):\n",
    "\n",
    "        !pip install -q torch torchvision torchaudio\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 08 : NLP\n",
    "\n",
    "    if '08_' in notebook_name:\n",
    "\n",
    "        !pip install -q transformers datasets tokenizers\n",
    "\n",
    "        if 'rag' in notebook_name:\n",
    "\n",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 09 : Reinforcement Learning\n",
    "\n",
    "    if '09_' in notebook_name:\n",
    "\n",
    "        !pip install -q gymnasium[classic-control]\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 04 : Boosting\n",
    "\n",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:\n",
    "\n",
    "        !pip install -q xgboost lightgbm catboost\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 05 : Clustering avanc√©\n",
    "\n",
    "    if '05_' in notebook_name:\n",
    "\n",
    "        !pip install -q umap-learn\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 11 : S√©ries temporelles\n",
    "\n",
    "    if '11_' in notebook_name:\n",
    "\n",
    "        !pip install -q statsmodels prophet\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 12 : Vision avanc√©e\n",
    "\n",
    "    if '12_' in notebook_name:\n",
    "\n",
    "        !pip install -q ultralytics timm segmentation-models-pytorch\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 13 : Recommandation\n",
    "\n",
    "    if '13_' in notebook_name:\n",
    "\n",
    "        !pip install -q scikit-surprise implicit\n",
    "\n",
    "    \n",
    "\n",
    "    # Ch 14 : MLOps\n",
    "\n",
    "    if '14_' in notebook_name:\n",
    "\n",
    "        !pip install -q mlflow fastapi pydantic\n",
    "\n",
    "    \n",
    "\n",
    "    print('‚úÖ Installation termin√©e !')\n",
    "\n",
    "else:\n",
    "\n",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 00 - Exercices : Introduction au Machine Learning\n",
    "\n",
    "Ce notebook contient des exercices pratiques pour consolider les concepts du Chapitre 00.\n",
    "\n",
    "**Instructions** :\n",
    "- Compl√©tez les cellules marqu√©es `# VOTRE CODE ICI`\n",
    "- Les solutions sont disponibles dans `00_exercices_solutions.ipynb`\n",
    "- N'h√©sitez pas √† consulter la documentation (scikit-learn, pandas, matplotlib)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Biblioth√®ques import√©es\n"
     ]
    }
   ],
   "source": "# Imports n√©cessaires\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.data  # type: ignoresets import load_wine, load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Configuration\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\nnp.random.seed(42)\n\nprint(\"‚úì Biblioth√®ques import√©es\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 1 : Analyse Exploratoire (EDA)\n",
    "\n",
    "**Dataset** : Wine (vins)\n",
    "\n",
    "**Objectif** : Effectuer une analyse exploratoire compl√®te du dataset Wine.\n",
    "\n",
    "### 1.1 Chargement et Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez le dataset Wine et cr√©ez un DataFrame\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "wine = None  # Remplacez par load_wine()\n",
    "df_wine = None  # Cr√©ez un DataFrame avec les donn√©es et les colonnes\n",
    "\n",
    "# Affichez les premi√®res lignes\n",
    "# VOTRE CODE ICI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions** :\n",
    "1. Combien y a-t-il d'√©chantillons et de features ?\n",
    "2. Quelles sont les classes cibles ?\n",
    "3. Y a-t-il des valeurs manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©pondez aux questions ci-dessus\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# 1. Nombre d'√©chantillons et features\n",
    "\n",
    "# 2. Classes cibles\n",
    "\n",
    "# 3. Valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichez les statistiques descriptives du DataFrame\n",
    "# VOTRE CODE ICI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Distribution des Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez la distribution des classes (countplot ou pie chart)\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# Question : Le dataset est-il √©quilibr√© ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Matrice de Corr√©lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez et visualisez la matrice de corr√©lation\n",
    "# Utilisez une heatmap avec annotations\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# Question : Quelles features sont les plus corr√©l√©es ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ez un pairplot pour les 4 premi√®res features\n",
    "# VOTRE CODE ICI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 2 : Pipeline ML Complet\n",
    "\n",
    "**Dataset** : Breast Cancer (cancer du sein)\n",
    "\n",
    "**Objectif** : Construire un pipeline complet de classification binaire.\n",
    "\n",
    "### 2.1 Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Chargez le dataset Breast Cancer\n# VOTRE CODE ICI\n\ncancer = None  # load_breast_cancer()\nX = None\ny = None\n\nprint(f\"Nombre d'√©chantillons : {X.shape[0]}\")\nprint(f\"Nombre de features : {X.shape[1]}\")\nprint(f\"Classes : {cancer.target  # type: ignore_names}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©parez les donn√©es en train/test (70/30)\n",
    "# Utilisez stratify=y pour pr√©server la distribution des classes\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "\n",
    "# V√©rifiez les tailles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisez les features\n",
    "# ATTENTION : fit uniquement sur le train set !\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = None\n",
    "X_test_scaled = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Entra√Ænement de Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænez au moins 3 mod√®les diff√©rents :\n",
    "# - Logistic Regression\n",
    "# - Random Forest\n",
    "# - SVM\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Cr√©ez un dictionnaire de mod√®les\n",
    "models = {\n",
    "    # VOTRE CODE ICI\n",
    "}\n",
    "\n",
    "# Entra√Ænez chaque mod√®le et stockez les r√©sultats\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # VOTRE CODE ICI\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 √âvaluation et Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparez les performances des mod√®les\n",
    "# Cr√©ez un DataFrame avec les r√©sultats\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# Visualisez les performances (barplot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 √âvaluation D√©taill√©e du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionnez le meilleur mod√®le\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "best_model = None\n",
    "\n",
    "# Affichez le classification report\n",
    "\n",
    "# Affichez la matrice de confusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 3 : D√©tection d'Overfitting\n",
    "\n",
    "**Objectif** : Cr√©er un sc√©nario d'overfitting et apprendre √† le d√©tecter.\n",
    "\n",
    "### 3.1 Cr√©ation d'un Dataset avec Peu d'√âchantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisez le dataset Wine, mais ne gardez que 30 √©chantillons al√©atoires\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "wine = load_wine()\n",
    "# S√©lectionnez al√©atoirement 30 indices\n",
    "indices = None  # np.random.choice(...)\n",
    "\n",
    "X_small = None\n",
    "y_small = None\n",
    "\n",
    "# Split train/test (20 train, 10 test)\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = None, None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entra√Ænement d'un Mod√®le Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænez un DecisionTreeClassifier SANS limitation de profondeur\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_overfit = None  # DecisionTreeClassifier(max_depth=None)\n",
    "\n",
    "# Calculez l'accuracy sur le train set et le test set\n",
    "train_accuracy = None\n",
    "test_accuracy = None\n",
    "\n",
    "print(f\"Train Accuracy : {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy  : {test_accuracy:.4f}\")\n",
    "\n",
    "# Question : Y a-t-il de l'overfitting ? Pourquoi ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 R√©gularisation pour R√©duire l'Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez diff√©rentes valeurs de max_depth pour r√©duire l'overfitting\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "max_depths = [2, 3, 4, 5, 6, 7, 8, None]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    # Entra√Ænez un arbre avec cette profondeur\n",
    "    # Stockez les accuracies train et test\n",
    "    pass\n",
    "\n",
    "# Visualisez les courbes train vs test\n",
    "plt.figure(figsize=(10, 6))\n",
    "# VOTRE CODE ICI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 4 : Feature Engineering (Bonus)\n",
    "\n",
    "**Objectif** : Am√©liorer les performances en cr√©ant de nouvelles features.\n",
    "\n",
    "### 4.1 Cr√©ation de Nouvelles Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Utilisez le dataset Iris\nfrom sklearn.data  # type: ignoresets import load_iris\n\niris = load_iris()\ndf_iris = pd.DataFrame(iris.data  # type: ignore, columns=iris.feature_names  # type: ignore)\ndf_iris['target'] = iris.target  # type: ignore\n\n# Cr√©ez de nouvelles features :\n# 1. Ratio sepal_length / sepal_width\n# 2. Ratio petal_length / petal_width\n# 3. Surface des p√©tales (petal_length * petal_width)\n# VOTRE CODE ICI\n\ndf_iris['sepal_ratio'] = None\ndf_iris['petal_ratio'] = None\ndf_iris['petal_area'] = None\n\ndisplay(df_iris.head())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Comparaison Avant/Apr√®s Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comparez les performances d'un mod√®le avec et sans les nouvelles features\n# VOTRE CODE ICI\n\n# Mod√®le sans nouvelles features\nX_original = iris.data  # type: ignore\ny = iris.target  # type: ignore\n\n# Mod√®le avec nouvelles features\nX_engineered = None  # df_iris[toutes les features sauf 'target']\n\n# Entra√Ænez et comparez\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 5 : Interpr√©tation des R√©sultats\n",
    "\n",
    "**Objectif** : Analyser et interpr√©ter les m√©triques de classification.\n",
    "\n",
    "### 5.1 Analyse d'une Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voici une matrice de confusion fictive pour un probl√®me de classification binaire\n",
    "# (d√©tection de spam)\n",
    "\n",
    "cm = np.array([\n",
    "    [85, 15],  # Classe 0 (non-spam) : 85 vrais n√©gatifs, 15 faux positifs\n",
    "    [10, 90]   # Classe 1 (spam)     : 10 faux n√©gatifs, 90 vrais positifs\n",
    "])\n",
    "\n",
    "# Questions :\n",
    "# 1. Calculez manuellement : Accuracy, Precision, Recall, F1-Score\n",
    "# 2. Dans le contexte du spam, quelle m√©trique est la plus importante ? Pourquoi ?\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# True Positives (TP)\n",
    "TP = None\n",
    "\n",
    "# True Negatives (TN)\n",
    "TN = None\n",
    "\n",
    "# False Positives (FP)\n",
    "FP = None\n",
    "\n",
    "# False Negatives (FN)\n",
    "FN = None\n",
    "\n",
    "# Accuracy\n",
    "accuracy = None\n",
    "\n",
    "# Precision\n",
    "precision = None\n",
    "\n",
    "# Recall\n",
    "recall = None\n",
    "\n",
    "# F1-Score\n",
    "f1 = None\n",
    "\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 6 : Questions de R√©flexion\n",
    "\n",
    "R√©pondez aux questions suivantes dans les cellules markdown :\n",
    "\n",
    "### 6.1 Overfitting vs Underfitting\n",
    "\n",
    "**Question** : Expliquez avec vos propres mots la diff√©rence entre overfitting et underfitting. Donnez un exemple concret pour chaque cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VOTRE R√âPONSE ICI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Choix de Mod√®le\n",
    "\n",
    "**Question** : Vous devez pr√©dire le prix d'une maison √† partir de ses caract√©ristiques (surface, nombre de chambres, localisation, etc.). Quel(s) algorithme(s) utiliseriez-vous et pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VOTRE R√âPONSE ICI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 √âthique en ML\n",
    "\n",
    "**Question** : Vous d√©veloppez un syst√®me de tri de CV pour une entreprise. Quels biais potentiels pourriez-vous rencontrer ? Comment les att√©nuer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VOTRE R√âPONSE ICI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "F√©licitations pour avoir compl√©t√© ces exercices !\n",
    "\n",
    "**Points cl√©s √† retenir** :\n",
    "- L'EDA est cruciale pour comprendre les donn√©es\n",
    "- Un pipeline ML structur√© am√©liore la reproductibilit√©\n",
    "- La validation crois√©e donne une meilleure estimation de la performance\n",
    "- L'overfitting est un probl√®me courant qu'on peut d√©tecter et att√©nuer\n",
    "- Le feature engineering peut significativement am√©liorer les performances\n",
    "\n",
    "**Prochaines √©tapes** :\n",
    "- Consultez les solutions dans `00_exercices_solutions.ipynb`\n",
    "- Pratiquez sur d'autres datasets (Kaggle)\n",
    "- Passez au Chapitre 01 pour approfondir les fondamentaux math√©matiques\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}