{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/XX_CHAPTER/XX_NOTEBOOK.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '00_demo_ml_pipeline.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 00 - D√©monstration : Pipeline ML Complet\n",
    "\n",
    "**Objectif** : Illustrer un pipeline Machine Learning complet sur le c√©l√®bre dataset Iris.\n",
    "\n",
    "**√âtapes** :\n",
    "1. Chargement et exploration des donn√©es\n",
    "2. Visualisation et analyse exploratoire\n",
    "3. Pr√©paration des donn√©es (split train/test)\n",
    "4. Entra√Ænement de plusieurs mod√®les\n",
    "5. √âvaluation et comparaison des performances\n",
    "6. Pr√©diction sur de nouvelles donn√©es\n",
    "7. Sauvegarde du mod√®le\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des Biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation de donn√©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# M√©triques d'√©valuation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Sauvegarde de mod√®les\n",
    "import joblib\n",
    "\n",
    "# Configuration\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Biblioth√®ques import√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Donn√©es\n",
    "\n",
    "Le dataset **Iris** est un classique du Machine Learning cr√©√© par Ronald Fisher en 1936. Il contient 150 √©chantillons de fleurs iris de 3 esp√®ces diff√©rentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Cr√©ation d'un DataFrame pour faciliter l'exploration\n",
    "df = pd.DataFrame(\n",
    "    data=iris.data,\n",
    "    columns=iris.feature_names\n",
    ")\n",
    "df['species'] = iris.target\n",
    "df['species_name'] = df['species'].map(\n",
    "    {i: name for i, name in enumerate(iris.target_names)}\n",
    ")\n",
    "\n",
    "print(\"üìä Dataset Iris charg√©\")\n",
    "print(f\"   - Nombre d'√©chantillons : {len(df)}\")\n",
    "print(f\"   - Nombre de features : {len(iris.feature_names)}\")\n",
    "print(f\"   - Classes : {list(iris.target_names)}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description des Features\n",
    "\n",
    "- **sepal length (cm)** : Longueur du s√©pale\n",
    "- **sepal width (cm)** : Largeur du s√©pale\n",
    "- **petal length (cm)** : Longueur du p√©tale\n",
    "- **petal width (cm)** : Largeur du p√©tale\n",
    "- **species** : Esp√®ce (0=setosa, 1=versicolor, 2=virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse Exploratoire des Donn√©es (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations g√©n√©rales\n",
    "print(\"üìã Informations sur le dataset :\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"\\nüìà Statistiques descriptives :\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des classes\n",
    "print(\"üéØ Distribution des classes :\")\n",
    "print(df['species_name'].value_counts())\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Countplot\n",
    "sns.countplot(data=df, x='species_name', ax=ax[0], palette='Set2')\n",
    "ax[0].set_title('Distribution des Esp√®ces', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('Esp√®ce', fontsize=12)\n",
    "ax[0].set_ylabel('Nombre d\\'√©chantillons', fontsize=12)\n",
    "\n",
    "# Pie chart\n",
    "df['species_name'].value_counts().plot.pie(\n",
    "    autopct='%1.1f%%',\n",
    "    ax=ax[1],\n",
    "    colors=sns.color_palette('Set2'),\n",
    "    startangle=90\n",
    ")\n",
    "ax[1].set_title('Proportion des Esp√®ces', fontsize=14, fontweight='bold')\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Dataset √©quilibr√© : chaque classe a 50 √©chantillons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs manquantes\n",
    "print(\"üîç Valeurs manquantes :\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n‚úì Aucune valeur manquante d√©tect√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de chaque feature\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(iris.feature_names):\n",
    "    for species in df['species_name'].unique():\n",
    "        subset = df[df['species_name'] == species]\n",
    "        axes[i].hist(\n",
    "            subset[col],\n",
    "            alpha=0.6,\n",
    "            label=species,\n",
    "            bins=15,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "    axes[i].set_xlabel(col, fontsize=11)\n",
    "    axes[i].set_ylabel('Fr√©quence', fontsize=11)\n",
    "    axes[i].set_title(f'Distribution : {col}', fontsize=12, fontweight='bold')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Observations :\")\n",
    "print(\"   - Les features 'petal length' et 'petal width' semblent tr√®s discriminantes\")\n",
    "print(\"   - Setosa est bien s√©par√©e des deux autres esp√®ces\")\n",
    "print(\"   - Versicolor et Virginica ont un certain chevauchement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot : Visualisation Multivari√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot pour visualiser les relations entre features\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    hue='species_name',\n",
    "    palette='Set2',\n",
    "    diag_kind='kde',\n",
    "    markers=['o', 's', 'D'],\n",
    "    plot_kws={'alpha': 0.7}\n",
    ")\n",
    "plt.suptitle('Pairplot des Features Iris', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Le pairplot r√©v√®le des s√©parations claires entre les esp√®ces,\")\n",
    "print(\"   notamment avec les dimensions des p√©tales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de Corr√©lation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la corr√©lation\n",
    "correlation_matrix = df[iris.feature_names].corr()\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    "    fmt='.2f'\n",
    ")\n",
    "plt.title('Matrice de Corr√©lation des Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Observations :\")\n",
    "print(\"   - Forte corr√©lation entre petal length et petal width (0.96)\")\n",
    "print(\"   - Forte corr√©lation entre sepal length et petal length (0.87)\")\n",
    "print(\"   - Sepal width est moins corr√©l√©e avec les autres features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©paration features (X) et target (y)\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "print(f\"‚úì X shape: {X.shape}\")\n",
    "print(f\"‚úì y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Pr√©serve la distribution des classes\n",
    ")\n",
    "\n",
    "print(\"üìä Split des donn√©es :\")\n",
    "print(f\"   - Training set : {X_train.shape[0]} √©chantillons ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"   - Test set     : {X_test.shape[0]} √©chantillons ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "\n",
    "# V√©rification de la distribution des classes\n",
    "print(\"\\nüéØ Distribution des classes dans le train set :\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"   - Classe {cls} ({iris.target_names[cls]}): {count} √©chantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des Features\n",
    "\n",
    "Certains algorithmes (KNN, SVM) sont sensibles √† l'√©chelle des features. On standardise les donn√©es pour avoir moyenne=0 et √©cart-type=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit sur train uniquement\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform avec les stats du train\n",
    "\n",
    "print(\"‚úì Features standardis√©es\")\n",
    "print(f\"\\nMoyennes (train) : {X_train_scaled.mean(axis=0).round(2)}\")\n",
    "print(f\"√âcart-types (train) : {X_train_scaled.std(axis=0).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entra√Ænement de Plusieurs Mod√®les\n",
    "\n",
    "Nous allons entra√Æner et comparer 5 algorithmes diff√©rents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de mod√®les √† tester\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='rbf', random_state=42)\n",
    "}\n",
    "\n",
    "print(\"ü§ñ Mod√®les √† entra√Æner :\")\n",
    "for i, name in enumerate(models.keys(), 1):\n",
    "    print(f\"   {i}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement et √©valuation\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ ENTRA√éNEMENT DES MOD√àLES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"‚è≥ Entra√Ænement : {name}...\")\n",
    "    \n",
    "    # Entra√Ænement (sur donn√©es standardis√©es pour certains mod√®les)\n",
    "    if name in ['K-Nearest Neighbors', 'Support Vector Machine', 'Logistic Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcul de l'accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Validation crois√©e sur le train set (5-fold)\n",
    "    if name in ['K-Nearest Neighbors', 'Support Vector Machine', 'Logistic Regression']:\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Stockage des r√©sultats\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚úì Accuracy (test) : {accuracy:.4f}\")\n",
    "    print(f\"   ‚úì CV Score (mean) : {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Tous les mod√®les ont √©t√© entra√Æn√©s avec succ√®s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Mod√®le': list(results.keys()),\n",
    "    'Accuracy (Test)': [r['accuracy'] for r in results.values()],\n",
    "    'CV Mean': [r['cv_mean'] for r in results.values()],\n",
    "    'CV Std': [r['cv_std'] for r in results.values()]\n",
    "}).sort_values('Accuracy (Test)', ascending=False)\n",
    "\n",
    "print(\"\\nüìä TABLEAU COMPARATIF DES PERFORMANCES\")\n",
    "print(\"=\"*60)\n",
    "display(comparison_df.style.background_gradient(cmap='RdYlGn', subset=['Accuracy (Test)', 'CV Mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "comparison_df.set_index('Mod√®le')['Accuracy (Test)'].plot(\n",
    "    kind='barh',\n",
    "    ax=ax[0],\n",
    "    color=sns.color_palette('viridis', len(comparison_df)),\n",
    "    edgecolor='black'\n",
    ")\n",
    "ax[0].set_xlabel('Accuracy', fontsize=12)\n",
    "ax[0].set_title('Accuracy sur le Test Set', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlim([0.9, 1.0])\n",
    "ax[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# CV scores with error bars\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "ax[1].barh(\n",
    "    x_pos,\n",
    "    comparison_df['CV Mean'],\n",
    "    xerr=comparison_df['CV Std'],\n",
    "    color=sns.color_palette('viridis', len(comparison_df)),\n",
    "    edgecolor='black',\n",
    "    capsize=5\n",
    ")\n",
    "ax[1].set_yticks(x_pos)\n",
    "ax[1].set_yticklabels(comparison_df['Mod√®le'])\n",
    "ax[1].set_xlabel('CV Score (mean ¬± std)', fontsize=12)\n",
    "ax[1].set_title('Validation Crois√©e (5-Fold)', fontsize=14, fontweight='bold')\n",
    "ax[1].set_xlim([0.9, 1.0])\n",
    "ax[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection du meilleur mod√®le\n",
    "best_model_name = comparison_df.iloc[0]['Mod√®le']\n",
    "best_model = results[best_model_name]['model']\n",
    "best_accuracy = comparison_df.iloc[0]['Accuracy (Test)']\n",
    "\n",
    "print(f\"\\nüèÜ MEILLEUR MOD√àLE : {best_model_name}\")\n",
    "print(f\"   Accuracy : {best_accuracy:.4f}\")\n",
    "print(f\"   CV Score : {results[best_model_name]['cv_mean']:.4f} (+/- {results[best_model_name]['cv_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. √âvaluation D√©taill√©e du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    results[best_model_name]['y_pred'],\n",
    "    target_names=iris.target_names\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpr√©tation des m√©triques** :\n",
    "- **Precision** : Parmi les pr√©dictions positives, quelle proportion est correcte ?\n",
    "- **Recall** : Parmi les vrais positifs, quelle proportion a √©t√© d√©tect√©e ?\n",
    "- **F1-score** : Moyenne harmonique de precision et recall\n",
    "- **Support** : Nombre d'√©chantillons r√©els de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, results[best_model_name]['y_pred'])\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Matrice de confusion (nombres)\n",
    "disp1 = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=iris.target_names\n",
    ")\n",
    "disp1.plot(ax=ax[0], cmap='Blues', values_format='d')\n",
    "ax[0].set_title('Matrice de Confusion (Nombres)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Matrice de confusion (proportions)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "disp2 = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_normalized,\n",
    "    display_labels=iris.target_names\n",
    ")\n",
    "disp2.plot(ax=ax[1], cmap='Blues', values_format='.2f')\n",
    "ax[1].set_title('Matrice de Confusion (Proportions)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpr√©tation :\")\n",
    "print(\"   - Diagonale : pr√©dictions correctes\")\n",
    "print(\"   - Hors diagonale : erreurs de classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pr√©diction sur de Nouvelles Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de nouvelles donn√©es fictives\n",
    "new_samples = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Ressemble √† setosa\n",
    "    [6.5, 3.0, 5.2, 2.0],  # Ressemble √† virginica\n",
    "    [5.9, 3.0, 4.2, 1.5],  # Ressemble √† versicolor\n",
    "])\n",
    "\n",
    "print(\"üîÆ PR√âDICTION SUR DE NOUVELLES DONN√âES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Standardisation si n√©cessaire\n",
    "if best_model_name in ['K-Nearest Neighbors', 'Support Vector Machine', 'Logistic Regression']:\n",
    "    new_samples_scaled = scaler.transform(new_samples)\n",
    "    predictions = best_model.predict(new_samples_scaled)\n",
    "    probas = best_model.predict_proba(new_samples_scaled)\n",
    "else:\n",
    "    predictions = best_model.predict(new_samples)\n",
    "    probas = best_model.predict_proba(new_samples)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "for i, (sample, pred, proba) in enumerate(zip(new_samples, predictions, probas), 1):\n",
    "    print(f\"\\n√âchantillon {i} : {sample}\")\n",
    "    print(f\"   Pr√©diction : {iris.target_names[pred]} (classe {pred})\")\n",
    "    print(f\"   Probabilit√©s :\")\n",
    "    for j, species in enumerate(iris.target_names):\n",
    "        print(f\"      - {species:12s} : {proba[j]:.4f} ({proba[j]*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualisation des Fronti√®res de D√©cision\n",
    "\n",
    "Pour visualiser, on r√©duit √† 2 dimensions (petal length et petal width, les plus discriminantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection de 2 features pour visualisation\n",
    "feature_indices = [2, 3]  # Petal length et petal width\n",
    "X_2d = X[:, feature_indices]\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(\n",
    "    X_2d, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Entra√Ænement d'un mod√®le sur ces 2 features\n",
    "model_2d = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_2d.fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Cr√©ation du mesh pour les fronti√®res de d√©cision\n",
    "h = 0.02  # Pas du mesh\n",
    "x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(\n",
    "    np.arange(x_min, x_max, h),\n",
    "    np.arange(y_min, y_max, h)\n",
    ")\n",
    "\n",
    "# Pr√©dictions sur le mesh\n",
    "Z = model_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Fronti√®res de d√©cision\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis', levels=2)\n",
    "\n",
    "# Points du dataset\n",
    "scatter = plt.scatter(\n",
    "    X_2d[:, 0],\n",
    "    X_2d[:, 1],\n",
    "    c=y,\n",
    "    cmap='viridis',\n",
    "    edgecolors='black',\n",
    "    s=100,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "plt.xlabel(iris.feature_names[feature_indices[0]], fontsize=12)\n",
    "plt.ylabel(iris.feature_names[feature_indices[1]], fontsize=12)\n",
    "plt.title('Fronti√®res de D√©cision (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Esp√®ce', ticks=[0, 1, 2])\n",
    "plt.legend(\n",
    "    handles=scatter.legend_elements()[0],\n",
    "    labels=iris.target_names,\n",
    "    loc='upper left'\n",
    ")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Les zones color√©es repr√©sentent les r√©gions de d√©cision du mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sauvegarde du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du meilleur mod√®le et du scaler\n",
    "import os\n",
    "\n",
    "# Cr√©er le r√©pertoire si n√©cessaire\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Sauvegarde\n",
    "model_path = 'models/best_iris_classifier.pkl'\n",
    "scaler_path = 'models/scaler.pkl'\n",
    "\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(\"üíæ Mod√®le sauvegard√© :\")\n",
    "print(f\"   - Mod√®le : {model_path}\")\n",
    "print(f\"   - Scaler : {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de chargement\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "\n",
    "# V√©rification\n",
    "if best_model_name in ['K-Nearest Neighbors', 'Support Vector Machine', 'Logistic Regression']:\n",
    "    test_pred = loaded_model.predict(loaded_scaler.transform(X_test))\n",
    "else:\n",
    "    test_pred = loaded_model.predict(X_test)\n",
    "\n",
    "accuracy_loaded = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"\\n‚úÖ V√©rification du mod√®le charg√© :\")\n",
    "print(f\"   - Accuracy : {accuracy_loaded:.4f}\")\n",
    "print(f\"   - Correspond au mod√®le original : {accuracy_loaded == best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. R√©sum√© du Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù R√âSUM√â DU PIPELINE ML\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = f\"\"\"\n",
    "1. üìä DONN√âES\n",
    "   - Dataset : Iris (150 √©chantillons, 4 features, 3 classes)\n",
    "   - Split : 80% train / 20% test\n",
    "   - Classes √©quilibr√©es : 50 √©chantillons par classe\n",
    "\n",
    "2. üîç EXPLORATION\n",
    "   - Aucune valeur manquante\n",
    "   - Features corr√©l√©es : petal length ‚Üî petal width (0.96)\n",
    "   - Features discriminantes : dimensions des p√©tales\n",
    "\n",
    "3. üõ†Ô∏è PR√âPARATION\n",
    "   - Standardisation (mean=0, std=1)\n",
    "   - Pr√©servation de la distribution des classes (stratify)\n",
    "\n",
    "4. ü§ñ MOD√âLISATION\n",
    "   - 5 mod√®les test√©s\n",
    "   - Validation crois√©e 5-fold\n",
    "   - Meilleur mod√®le : {best_model_name}\n",
    "\n",
    "5. üìà PERFORMANCES\n",
    "   - Accuracy (test) : {best_accuracy:.4f}\n",
    "   - CV Score : {results[best_model_name]['cv_mean']:.4f} (+/- {results[best_model_name]['cv_std']:.4f})\n",
    "\n",
    "6. üíæ D√âPLOIEMENT\n",
    "   - Mod√®le sauvegard√© : {model_path}\n",
    "   - Pr√™t pour l'inf√©rence\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Pipeline ML complet r√©alis√© avec succ√®s !\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Points Cl√©s\n",
    "\n",
    "1. **Pipeline structur√©** : Suivre un processus m√©thodique est essentiel\n",
    "2. **EDA critique** : L'exploration r√©v√®le des insights importants sur les donn√©es\n",
    "3. **Comparaison de mod√®les** : Tester plusieurs algorithmes aide √† choisir le meilleur\n",
    "4. **Validation crois√©e** : √âvalue mieux la g√©n√©ralisation que le simple train/test split\n",
    "5. **Sauvegarde** : Permet de r√©utiliser le mod√®le sans r√©entra√Ænement\n",
    "\n",
    "### Prochaines √âtapes\n",
    "\n",
    "- Optimisation des hyperparam√®tres (GridSearchCV, RandomizedSearchCV)\n",
    "- Feature engineering avanc√©\n",
    "- Essayer d'autres datasets plus complexes\n",
    "- D√©ploiement en production (API REST avec Flask/FastAPI)\n",
    "\n",
    "---\n",
    "\n",
    "**Exercices** : Voir `00_exercices.ipynb` pour pratiquer ces concepts !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}