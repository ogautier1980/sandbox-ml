{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/11_series_temporelles/11_demo_arima_prophet.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '11_demo_arima_prophet.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 12 - S√©ries Temporelles : ARIMA & Prophet\n",
    "\n",
    "**Objectifs :**\n",
    "- Analyser et visualiser des s√©ries temporelles\n",
    "- Tester la stationnarit√© (ADF test)\n",
    "- D√©composer en tendance, saisonnalit√©, r√©sidu\n",
    "- Mod√©liser avec ARIMA et SARIMA\n",
    "- Utiliser Prophet de Facebook pour forecasting\n",
    "- √âvaluer les pr√©dictions avec m√©triques appropri√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# S√©ries temporelles\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Prophet\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Prophet non install√©. Pour l'installer: pip install prophet\")\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "# M√©triques\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Biblioth√®ques charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. G√©n√©ration de Donn√©es Synth√©tiques\n",
    "\n",
    "Cr√©ons une s√©rie temporelle avec tendance, saisonnalit√© et bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(n=365*3, trend_coef=0.1, seasonal_period=365, noise_std=10, seed=42):\n",
    "    \"\"\"\n",
    "    G√©n√®re une s√©rie temporelle avec tendance, saisonnalit√© et bruit\n",
    "    \n",
    "    Param√®tres:\n",
    "    - n: nombre de points\n",
    "    - trend_coef: coefficient de tendance lin√©aire\n",
    "    - seasonal_period: p√©riode de la saisonnalit√©\n",
    "    - noise_std: √©cart-type du bruit\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Dates\n",
    "    dates = pd.date_range(start='2021-01-01', periods=n, freq='D')\n",
    "    \n",
    "    # Tendance lin√©aire\n",
    "    t = np.arange(n)\n",
    "    trend = trend_coef * t\n",
    "    \n",
    "    # Saisonnalit√© (annuelle)\n",
    "    seasonality = 20 * np.sin(2 * np.pi * t / seasonal_period)\n",
    "    \n",
    "    # Bruit\n",
    "    noise = np.random.normal(0, noise_std, n)\n",
    "    \n",
    "    # S√©rie compl√®te\n",
    "    y = 100 + trend + seasonality + noise\n",
    "    \n",
    "    # DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'value': y,\n",
    "        'trend': 100 + trend,\n",
    "        'seasonality': seasonality,\n",
    "        'noise': noise\n",
    "    })\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# G√©n√©rer donn√©es\n",
    "df = generate_timeseries(n=365*3, trend_coef=0.05, seasonal_period=365, noise_std=8)\n",
    "\n",
    "print(f\"S√©rie temporelle g√©n√©r√©e: {len(df)} observations\")\n",
    "print(f\"P√©riode: {df.index.min()} √† {df.index.max()}\")\n",
    "print(f\"\\nPremi√®res observations:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# S√©rie compl√®te\n",
    "axes[0].plot(df.index, df['value'], label='S√©rie temporelle', color='blue')\n",
    "axes[0].set_title('S√©rie Temporelle Compl√®te', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Tendance\n",
    "axes[1].plot(df.index, df['trend'], label='Tendance', color='green')\n",
    "axes[1].set_title('Composante Tendance', fontsize=12)\n",
    "axes[1].set_ylabel('Tendance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Saisonnalit√©\n",
    "axes[2].plot(df.index, df['seasonality'], label='Saisonnalit√©', color='orange')\n",
    "axes[2].set_title('Composante Saisonnalit√©', fontsize=12)\n",
    "axes[2].set_ylabel('Saisonnalit√©')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Bruit\n",
    "axes[3].plot(df.index, df['noise'], label='Bruit', color='red', alpha=0.5)\n",
    "axes[3].set_title('Composante Bruit', fontsize=12)\n",
    "axes[3].set_ylabel('Bruit')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse Exploratoire\n",
    "\n",
    "### 2.1 Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Statistiques Descriptives ===\")\n",
    "print(df['value'].describe())\n",
    "print(f\"\\nSkewness: {df['value'].skew():.4f}\")\n",
    "print(f\"Kurtosis: {df['value'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 D√©composition de la S√©rie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©composition additive\n",
    "decomposition = seasonal_decompose(df['value'], model='additive', period=365)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "decomposition.observed.plot(ax=axes[0], title='S√©rie Observ√©e', color='blue')\n",
    "axes[0].set_ylabel('Observ√©e')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "decomposition.trend.plot(ax=axes[1], title='Tendance', color='green')\n",
    "axes[1].set_ylabel('Tendance')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Saisonnalit√©', color='orange')\n",
    "axes[2].set_ylabel('Saisonnalit√©')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "decomposition.resid.plot(ax=axes[3], title='R√©sidus', color='red')\n",
    "axes[3].set_ylabel('R√©sidus')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test de Stationnarit√© (ADF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries, name=''):\n",
    "    \"\"\"\n",
    "    Test de Dickey-Fuller Augment√© pour la stationnarit√©\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Test ADF {name} ===\")\n",
    "    result = adfuller(timeseries.dropna())\n",
    "    \n",
    "    print(f\"ADF Statistic: {result[0]:.6f}\")\n",
    "    print(f\"p-value: {result[1]:.6f}\")\n",
    "    print(f\"Lags utilis√©s: {result[2]}\")\n",
    "    print(f\"Nombre d'observations: {result[3]}\")\n",
    "    \n",
    "    print(\"\\nValeurs critiques:\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    \n",
    "    if result[1] < 0.05:\n",
    "        print(\"\\n‚úÖ R√©sultat: S√©rie STATIONNAIRE (rejeter H0, p < 0.05)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå R√©sultat: S√©rie NON-STATIONNAIRE (ne pas rejeter H0, p >= 0.05)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test sur s√©rie originale\n",
    "adf_result = adf_test(df['value'], name='S√©rie Originale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Stationnarisation par Diff√©renciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Premi√®re diff√©renciation\n",
    "df['value_diff1'] = df['value'].diff()\n",
    "\n",
    "# Deuxi√®me diff√©renciation (si n√©cessaire)\n",
    "df['value_diff2'] = df['value_diff1'].diff()\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(df.index, df['value'], color='blue')\n",
    "axes[0].set_title('S√©rie Originale', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Valeur')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(df.index, df['value_diff1'], color='green')\n",
    "axes[1].set_title('Apr√®s 1√®re Diff√©renciation', fontsize=12)\n",
    "axes[1].set_ylabel('Diff√©rence 1')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(df.index, df['value_diff2'], color='orange')\n",
    "axes[2].set_title('Apr√®s 2√®me Diff√©renciation', fontsize=12)\n",
    "axes[2].set_ylabel('Diff√©rence 2')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tests ADF\n",
    "adf_test(df['value_diff1'], name='Apr√®s 1√®re Diff√©renciation')\n",
    "adf_test(df['value_diff2'], name='Apr√®s 2√®me Diff√©renciation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ACF et PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF et PACF de la s√©rie diff√©renci√©e\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ACF\n",
    "plot_acf(df['value_diff1'].dropna(), lags=40, ax=axes[0])\n",
    "axes[0].set_title('Autocorr√©lation (ACF)', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PACF\n",
    "plot_pacf(df['value_diff1'].dropna(), lags=40, ax=axes[1])\n",
    "axes[1].set_title('Autocorr√©lation Partielle (PACF)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mod√®le ARIMA\n",
    "\n",
    "### 3.1 S√©lection des Param√®tres (p, d, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split (80/20)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df['value'][:train_size]\n",
    "test = df['value'][train_size:]\n",
    "\n",
    "print(f\"Train size: {len(train)} observations\")\n",
    "print(f\"Test size: {len(test)} observations\")\n",
    "print(f\"Train period: {train.index.min()} √† {train.index.max()}\")\n",
    "print(f\"Test period: {test.index.min()} √† {test.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search pour trouver les meilleurs param√®tres ARIMA\n",
    "def arima_grid_search(train_data, p_range, d_range, q_range):\n",
    "    \"\"\"\n",
    "    Grid search pour s√©lectionner les meilleurs param√®tres ARIMA\n",
    "    \"\"\"\n",
    "    best_aic = np.inf\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in p_range:\n",
    "        for d in d_range:\n",
    "            for q in q_range:\n",
    "                try:\n",
    "                    model = ARIMA(train_data, order=(p, d, q))\n",
    "                    fitted = model.fit()\n",
    "                    aic = fitted.aic\n",
    "                    \n",
    "                    results.append({\n",
    "                        'p': p, 'd': d, 'q': q,\n",
    "                        'AIC': aic,\n",
    "                        'BIC': fitted.bic\n",
    "                    })\n",
    "                    \n",
    "                    if aic < best_aic:\n",
    "                        best_aic = aic\n",
    "                        best_params = (p, d, q)\n",
    "                        best_model = fitted\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    \n",
    "    return best_params, best_model, pd.DataFrame(results)\n",
    "\n",
    "# Recherche\n",
    "print(\"Recherche des meilleurs param√®tres ARIMA...\")\n",
    "best_params, best_model, results_df = arima_grid_search(\n",
    "    train,\n",
    "    p_range=range(0, 4),\n",
    "    d_range=range(0, 3),\n",
    "    q_range=range(0, 4)\n",
    ")\n",
    "\n",
    "print(f\"\\nMeilleurs param√®tres: ARIMA{best_params}\")\n",
    "print(f\"AIC: {best_model.aic:.2f}\")\n",
    "print(f\"BIC: {best_model.bic:.2f}\")\n",
    "\n",
    "# Top 10 mod√®les\n",
    "print(\"\\nTop 10 mod√®les (par AIC):\")\n",
    "print(results_df.sort_values('AIC').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Entra√Ænement et Pr√©diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©sum√© du mod√®le\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur test set\n",
    "forecast = best_model.forecast(steps=len(test))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train.index, train, label='Train', color='blue')\n",
    "plt.plot(test.index, test, label='Test (R√©el)', color='green')\n",
    "plt.plot(test.index, forecast, label=f'Pr√©dictions ARIMA{best_params}', color='red', linestyle='--')\n",
    "plt.axvline(train.index[-1], color='black', linestyle=':', label='Train/Test Split')\n",
    "plt.title(f'Pr√©dictions ARIMA{best_params}', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 √âvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_true, y_pred, model_name='Mod√®le'):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les m√©triques de forecasting\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"\\n=== M√©triques {model_name} ===\")\n",
    "    print(f\"MAE (Mean Absolute Error):       {mae:.4f}\")\n",
    "    print(f\"MSE (Mean Squared Error):        {mse:.4f}\")\n",
    "    print(f\"RMSE (Root Mean Squared Error):  {rmse:.4f}\")\n",
    "    print(f\"MAPE (Mean Absolute % Error):    {mape:.2f}%\")\n",
    "    \n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "arima_metrics = evaluate_forecast(test.values, forecast.values, f'ARIMA{best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Diagnostic des R√©sidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot\n",
    "best_model.plot_diagnostics(figsize=(14, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mod√®le SARIMA (avec Saisonnalit√©)\n",
    "\n",
    "Pour capturer la saisonnalit√© annuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARIMA avec saisonnalit√© annuelle (p√©riode = 365 jours)\n",
    "# Param√®tres: SARIMA(p,d,q)(P,D,Q,s)\n",
    "sarima_order = (1, 1, 1)  # Non-saisonnier\n",
    "seasonal_order = (1, 1, 1, 365)  # Saisonnier avec p√©riode 365\n",
    "\n",
    "print(f\"Entra√Ænement SARIMA{sarima_order}x{seasonal_order}...\")\n",
    "\n",
    "sarima_model = SARIMAX(train, \n",
    "                       order=sarima_order,\n",
    "                       seasonal_order=seasonal_order)\n",
    "sarima_fitted = sarima_model.fit(disp=False)\n",
    "\n",
    "print(f\"\\nAIC: {sarima_fitted.aic:.2f}\")\n",
    "print(f\"BIC: {sarima_fitted.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions SARIMA\n",
    "sarima_forecast = sarima_fitted.forecast(steps=len(test))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train.index, train, label='Train', color='blue')\n",
    "plt.plot(test.index, test, label='Test (R√©el)', color='green')\n",
    "plt.plot(test.index, sarima_forecast, label=f'SARIMA{sarima_order}x{seasonal_order}', \n",
    "         color='purple', linestyle='--')\n",
    "plt.axvline(train.index[-1], color='black', linestyle=':', label='Train/Test Split')\n",
    "plt.title('Pr√©dictions SARIMA', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# M√©triques\n",
    "sarima_metrics = evaluate_forecast(test.values, sarima_forecast.values, 'SARIMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prophet de Facebook\n",
    "\n",
    "Framework simple et robuste pour le forecasting avec saisonnalit√©s multiples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Pr√©parer les donn√©es au format Prophet (colonnes 'ds' et 'y')\n",
    "    train_prophet = pd.DataFrame({\n",
    "        'ds': train.index,\n",
    "        'y': train.values\n",
    "    })\n",
    "    \n",
    "    # Cr√©er et entra√Æner le mod√®le\n",
    "    prophet_model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode='additive',\n",
    "        changepoint_prior_scale=0.05  # Flexibilit√© des changepoints\n",
    "    )\n",
    "    \n",
    "    print(\"Entra√Ænement du mod√®le Prophet...\")\n",
    "    prophet_model.fit(train_prophet)\n",
    "    print(\"‚úÖ Entra√Ænement termin√©\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Prophet non disponible. Installer avec: pip install prophet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Cr√©er dataframe pour pr√©dictions futures\n",
    "    future = prophet_model.make_future_dataframe(periods=len(test), freq='D')\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    prophet_forecast = prophet_model.predict(future)\n",
    "    \n",
    "    # Extraire pr√©dictions sur test set\n",
    "    prophet_test_pred = prophet_forecast.iloc[-len(test):]['yhat'].values\n",
    "    \n",
    "    # Visualisation Prophet\n",
    "    fig1 = prophet_model.plot(prophet_forecast, figsize=(14, 6))\n",
    "    plt.title('Pr√©dictions Prophet', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Composantes (tendance + saisonnalit√©)\n",
    "    fig2 = prophet_model.plot_components(prophet_forecast, figsize=(14, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # M√©triques\n",
    "    prophet_metrics = evaluate_forecast(test.values, prophet_test_pred, 'Prophet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparaison des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison = pd.DataFrame({\n",
    "    f'ARIMA{best_params}': arima_metrics,\n",
    "    'SARIMA': sarima_metrics,\n",
    "})\n",
    "\n",
    "if PROPHET_AVAILABLE:\n",
    "    comparison['Prophet'] = prophet_metrics\n",
    "\n",
    "print(\"\\n=== Comparaison des Mod√®les ===\")\n",
    "print(comparison.T)\n",
    "\n",
    "# Meilleur mod√®le (RMSE)\n",
    "best_model_name = comparison.loc['RMSE'].idxmin()\n",
    "print(f\"\\nüèÜ Meilleur mod√®le (RMSE): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train.index, train, label='Train', color='blue', alpha=0.7)\n",
    "plt.plot(test.index, test, label='Test (R√©el)', color='green', linewidth=2)\n",
    "plt.plot(test.index, forecast, label=f'ARIMA{best_params}', \n",
    "         color='red', linestyle='--', alpha=0.8)\n",
    "plt.plot(test.index, sarima_forecast, label='SARIMA', \n",
    "         color='purple', linestyle='--', alpha=0.8)\n",
    "\n",
    "if PROPHET_AVAILABLE:\n",
    "    plt.plot(test.index, prophet_test_pred, label='Prophet', \n",
    "             color='orange', linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.axvline(train.index[-1], color='black', linestyle=':', linewidth=2, label='Train/Test Split')\n",
    "plt.title('Comparaison des Pr√©dictions - ARIMA vs SARIMA vs Prophet', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecasting Multi-Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dire sur plusieurs horizons (7, 30, 90 jours)\n",
    "horizons = [7, 30, 90, 180]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, horizon in enumerate(horizons):\n",
    "    # ARIMA forecast\n",
    "    forecast_h = best_model.forecast(steps=horizon)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.plot(train.index[-180:], train.values[-180:], label='Train (derniers 180 jours)', color='blue')\n",
    "    \n",
    "    # Dates futures\n",
    "    future_dates = pd.date_range(start=train.index[-1] + timedelta(days=1), periods=horizon, freq='D')\n",
    "    ax.plot(future_dates, forecast_h, label=f'Pr√©diction {horizon}j', color='red', linestyle='--', marker='o')\n",
    "    \n",
    "    ax.axvline(train.index[-1], color='black', linestyle=':', label='D√©but Forecast')\n",
    "    ax.set_title(f'Horizon: {horizon} jours', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Valeur')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons explor√© :\n",
    "\n",
    "1. **Analyse exploratoire** : d√©composition, stationnarit√©, ACF/PACF\n",
    "2. **ARIMA** : mod√®le classique pour s√©ries stationnaires\n",
    "3. **SARIMA** : extension avec saisonnalit√©\n",
    "4. **Prophet** : framework robuste de Facebook pour forecasting\n",
    "5. **√âvaluation** : MAE, RMSE, MAPE\n",
    "6. **Comparaison** : analyse des performances de chaque mod√®le\n",
    "\n",
    "**Points cl√©s :**\n",
    "- Toujours tester la stationnarit√© avant ARIMA\n",
    "- Utiliser ACF/PACF pour guider la s√©lection de (p, q)\n",
    "- SARIMA pour saisonnalit√©s claires\n",
    "- Prophet excellent pour donn√©es r√©elles avec outliers et manquantes\n",
    "- Valider avec Time Series Split (pas de CV classique)\n",
    "\n",
    "**Prochaine √©tape** : Deep Learning pour s√©ries temporelles (LSTM, GRU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}