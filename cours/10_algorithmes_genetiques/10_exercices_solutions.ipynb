{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Google Colab Setup",
    "",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/10_algorithmes_genetiques/10_exercices_solutions.ipynb)",
    "",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "if IN_COLAB:",
    "    print('üì¶ Installation des packages...')",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "    print('‚úÖ Installation termin√©e !')",
    "else:",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 10 - Solutions : Algorithmes G√©n√©tiques",
    "",
    "Ce notebook contient des exercices pratiques pour consolider les concepts du Chapitre 10.",
    "",
    "**Instructions** :",
    "- Compl√©tez les cellules marqu√©es `# SOLUTION:",
    "# Remplacez cette ligne par votre code de solution`",
    "- Les solutions sont disponibles dans `10_exercices_solutions.ipynb`",
    "- N'h√©sitez pas √† consulter la documentation (NumPy, scikit-learn)",
    "",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires",
    "import numpy as np",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "from sklearn.datasets import load_wine, load_breast_cancer, load_diabetes",
    "from sklearn.model_selection import train_test_split, cross_val_score",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor",
    "from sklearn.metrics import accuracy_score, mean_squared_error",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "# Configuration",
    "sns.set_style('whitegrid')",
    "plt.rcParams['figure.figsize'] = (12, 6)",
    "np.random.seed(42)",
    "",
    "print(\"‚úì Biblioth√®ques import√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 1 : Algorithme G√©n√©tique de Base",
    "",
    "**Objectif** : Impl√©menter un AG pour optimiser la fonction de Rastrigin.",
    "",
    "### 1.1 Fonction de Rastrigin",
    "",
    "La fonction de Rastrigin est une fonction de benchmark classique pour tester les algorithmes d'optimisation :",
    "",
    "$$f(\\mathbf{x}) = 10n + \\sum_{i=1}^{n} \\left[x_i^2 - 10\\cos(2\\pi x_i)\\right]$$",
    "",
    "Minimum global : $f(0, 0, ..., 0) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez la fonction de Rastrigin",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def rastrigin(x):",
    "    \"\"\"",
    "    Fonction de Rastrigin.",
    "    Args:",
    "        x: vecteur de dimension n (valeurs entre -5.12 et 5.12)",
    "    Returns:",
    "        Valeur de la fonction (√† MINIMISER)",
    "    \"\"\"",
    "    # SOLUTION: Impl√©mentez la formule",
    "    pass",
    "",
    "# Test",
    "x_test = np.array([0, 0])",
    "print(f\"Rastrigin([0, 0]) = {rastrigin(x_test):.6f} (attendu : 0.0)\")",
    "",
    "x_test2 = np.array([1, 1])",
    "print(f\"Rastrigin([1, 1]) = {rastrigin(x_test2):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualisation de la Fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez la fonction de Rastrigin en 2D",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "x = np.linspace(-5.12, 5.12, 200)",
    "y = np.linspace(-5.12, 5.12, 200)",
    "X, Y = np.meshgrid(x, y)",
    "",
    "# SOLUTION: Calculez Z = rastrigin pour chaque point (X, Y)",
    "",
    "# SOLUTION: Tracez un contour plot ou surface 3D",
    "plt.figure(figsize=(10, 8))",
    "# contourf, colorbar, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Impl√©mentation de l'AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez l'algorithme g√©n√©tique",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "class GeneticAlgorithm:",
    "    def __init__(self, fitness_func, dim, bounds, pop_size=50, mutation_rate=0.1, crossover_rate=0.8):",
    "        \"\"\"",
    "        Args:",
    "            fitness_func: Fonction √† MINIMISER",
    "            dim: Dimension du probl√®me",
    "            bounds: Tuple (min, max) pour les valeurs des g√®nes",
    "            pop_size: Taille de la population",
    "            mutation_rate: Probabilit√© de mutation",
    "            crossover_rate: Probabilit√© de crossover",
    "        \"\"\"",
    "        self.fitness_func = fitness_func",
    "        self.dim = dim",
    "        self.bounds = bounds",
    "        self.pop_size = pop_size",
    "        self.mutation_rate = mutation_rate",
    "        self.crossover_rate = crossover_rate",
    "        self.population = None",
    "        self.best_fitness_history = []",
    "        self.avg_fitness_history = []",
    "    ",
    "    def initialize_population(self):",
    "        \"\"\"Initialise la population al√©atoirement.\"\"\"",
    "        # SOLUTION: Cr√©ez une population de pop_size individus",
    "        # Chaque individu est un vecteur de dimension dim avec valeurs dans bounds",
    "        pass",
    "    ",
    "    def evaluate(self, individual):",
    "        \"\"\"√âvalue un individu (fitness).\"\"\"",
    "        # SOLUTION: Retournez fitness_func(individual)",
    "        pass",
    "    ",
    "    def selection(self):",
    "        \"\"\"S√©lection par tournoi (taille 3).\"\"\"",
    "        # SOLUTION: Choisissez 3 individus al√©atoires et retournez le meilleur",
    "        pass",
    "    ",
    "    def crossover(self, parent1, parent2):",
    "        \"\"\"Crossover uniforme.\"\"\"",
    "        if np.random.rand() > self.crossover_rate:",
    "            return parent1.copy(), parent2.copy()",
    "        ",
    "        # SOLUTION: Pour chaque g√®ne, choisissez al√©atoirement parent1 ou parent2",
    "        pass",
    "    ",
    "    def mutation(self, individual):",
    "        \"\"\"Mutation gaussienne.\"\"\"",
    "        # SOLUTION: Pour chaque g√®ne, avec probabilit√© mutation_rate,",
    "        # ajoutez un bruit gaussien (sigma=0.5) et clippez dans bounds",
    "        pass",
    "    ",
    "    def evolve(self, n_generations=100):",
    "        \"\"\"Boucle principale de l'AG.\"\"\"",
    "        # SOLUTION: Initialisez la population",
    "        ",
    "        for gen in range(n_generations):",
    "            # SOLUTION: √âvaluez la population",
    "            fitnesses = None  # [self.evaluate(ind) for ind in self.population]",
    "            ",
    "            # SOLUTION: Stockez les statistiques",
    "            best_fitness = None",
    "            avg_fitness = None",
    "            self.best_fitness_history.append(best_fitness)",
    "            self.avg_fitness_history.append(avg_fitness)",
    "            ",
    "            if (gen + 1) % 20 == 0:",
    "                print(f\"G√©n√©ration {gen+1}/{n_generations} | Best: {best_fitness:.6f} | Avg: {avg_fitness:.6f}\")",
    "            ",
    "            # SOLUTION: Cr√©ez la nouvelle g√©n√©ration",
    "            # 1. √âlitisme : gardez les 2 meilleurs",
    "            # 2. Pour le reste : s√©lection, crossover, mutation",
    "            pass",
    "        ",
    "        # Retournez le meilleur individu",
    "        fitnesses = [self.evaluate(ind) for ind in self.population]",
    "        best_idx = np.argmin(fitnesses)",
    "        return self.population[best_idx], fitnesses[best_idx]",
    "",
    "print(\"‚úì Classe GeneticAlgorithm cr√©√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Ex√©cution de l'AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cutez l'AG sur la fonction de Rastrigin",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "ga = GeneticAlgorithm(",
    "    fitness_func=rastrigin,",
    "    dim=2,",
    "    bounds=(-5.12, 5.12),",
    "    pop_size=50,",
    "    mutation_rate=0.1,",
    "    crossover_rate=0.8",
    ")",
    "",
    "best_individual, best_fitness = ga.evolve(n_generations=100)",
    "",
    "print(f\"\\n‚úì Optimisation termin√©e\")",
    "print(f\"Meilleur individu : {best_individual}\")",
    "print(f\"Meilleure fitness : {best_fitness:.6f}\")",
    "print(f\"Cible : [0, 0] avec fitness = 0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Visualisation de la Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracez l'√©volution de la fitness",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "plt.figure(figsize=(12, 5))",
    "",
    "plt.subplot(1, 2, 1)",
    "# SOLUTION: Tracez best_fitness_history",
    "",
    "plt.subplot(1, 2, 2)",
    "# SOLUTION: Tracez avg_fitness_history",
    "",
    "plt.tight_layout()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 2 : Optimisation d'Hyperparam√®tres avec AG",
    "",
    "**Dataset** : Wine",
    "",
    "**Objectif** : Utiliser un AG pour optimiser les hyperparam√®tres d'un RandomForest.",
    "",
    "### 2.1 Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez le dataset Wine",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "wine = load_wine()",
    "X, y = wine.data, wine.target  # type: ignore",
    "",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
    "",
    "print(f\"Train : {X_train.shape}, Test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Fonction de Fitness pour Hyperparam√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finissez la fonction de fitness",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def rf_fitness(params):",
    "    \"\"\"",
    "    Fitness pour RandomForest.",
    "    Args:",
    "        params: [n_estimators, max_depth, min_samples_split, min_samples_leaf]",
    "    Returns:",
    "        -cv_score (pour minimisation)",
    "    \"\"\"",
    "    # SOLUTION: D√©codez les param√®tres (assurez-vous qu'ils sont des entiers)",
    "    n_estimators = int(params[0])",
    "    max_depth = int(params[1])",
    "    min_samples_split = int(params[2])",
    "    min_samples_leaf = int(params[3])",
    "    ",
    "    # SOLUTION: Cr√©ez le mod√®le",
    "    model = None  # RandomForestClassifier(...)",
    "    ",
    "    # SOLUTION: Calculez le CV score (5-fold)",
    "    cv_scores = None  # cross_val_score(...)",
    "    ",
    "    # Retournez -mean(cv_scores) car on minimise",
    "    return -cv_scores.mean()",
    "",
    "# Test",
    "test_params = [100, 10, 2, 1]",
    "print(f\"Fitness test : {rf_fitness(test_params):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 D√©finition des Bornes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finissez les bornes pour chaque hyperparam√®tre",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# n_estimators : [10, 200]",
    "# max_depth : [2, 30]",
    "# min_samples_split : [2, 20]",
    "# min_samples_leaf : [1, 10]",
    "",
    "# Note : L'AG actuel utilise des bornes uniformes. Vous devrez adapter",
    "# pour g√©rer des bornes diff√©rentes par dimension (optionnel : bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Adaptation de l'AG pour Hyperparam√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptez l'AG pour g√©rer des bornes diff√©rentes par param√®tre",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Option 1 : Modifiez la classe GeneticAlgorithm pour accepter bounds=[(...), (...), ...]",
    "# Option 2 : Cr√©ez une nouvelle classe GeneticAlgorithmHyperparams",
    "# Option 3 : Normalisez les param√®tres (0-1) puis d√©normalisez dans fitness_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Ex√©cution et Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cutez l'AG pour trouver les meilleurs hyperparam√®tres",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Comparez avec les valeurs par d√©faut de RandomForest",
    "",
    "# Baseline : RandomForest avec valeurs par d√©faut",
    "rf_baseline = RandomForestClassifier(random_state=42)",
    "baseline_cv = cross_val_score(rf_baseline, X_train, y_train, cv=5)",
    "print(f\"Baseline CV Score : {baseline_cv.mean():.4f} ¬± {baseline_cv.std():.4f}\")",
    "",
    "# SOLUTION: Ex√©cutez l'AG",
    "# SOLUTION: Entra√Ænez un mod√®le avec les meilleurs hyperparam√®tres",
    "# SOLUTION: Comparez les scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 3 : S√©lection de Features avec AG",
    "",
    "**Dataset** : Breast Cancer",
    "",
    "**Objectif** : Utiliser un AG pour s√©lectionner les features les plus pertinentes.",
    "",
    "### 3.1 Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez Breast Cancer",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "cancer = load_breast_cancer()",
    "X, y = cancer.data, cancer.target  # type: ignore",
    "",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
    "",
    "print(f\"Nombre de features : {X.shape[1]}\")",
    "print(f\"Train : {X_train.shape}, Test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Encodage Binaire pour Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'individu sera un vecteur binaire de longueur 30",
    "# 1 = feature s√©lectionn√©e, 0 = feature ignor√©e",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def feature_selection_fitness(binary_mask):",
    "    \"\"\"",
    "    Fitness pour feature selection.",
    "    Args:",
    "        binary_mask: vecteur binaire (0 ou 1) de longueur n_features",
    "    Returns:",
    "        fitness (√† minimiser) = -accuracy + p√©nalit√© pour nombre de features",
    "    \"\"\"",
    "    # SOLUTION: Convertissez en masque bool√©en",
    "    mask = binary_mask > 0.5  # Seuil pour interpr√©ter comme binaire",
    "    ",
    "    # SOLUTION: V√©rifiez qu'au moins une feature est s√©lectionn√©e",
    "    if mask.sum() == 0:",
    "        return 1000  # P√©nalit√© √©lev√©e",
    "    ",
    "    # SOLUTION: S√©lectionnez les features",
    "    X_train_selected = None  # X_train[:, mask]",
    "    ",
    "    # SOLUTION: Entra√Ænez un mod√®le et calculez le CV score",
    "    model = RandomForestClassifier(n_estimators=50, random_state=42)",
    "    cv_scores = None  # cross_val_score(...)",
    "    ",
    "    # SOLUTION: Calculez la fitness avec p√©nalit√© pour complexit√©",
    "    # fitness = -cv_score + lambda * (nombre_de_features / total_features)",
    "    # lambda = 0.1 par exemple",
    "    pass",
    "",
    "# Test",
    "test_mask = np.random.randint(0, 2, size=30)",
    "print(f\"Features s√©lectionn√©es : {test_mask.sum()}/30\")",
    "print(f\"Fitness test : {feature_selection_fitness(test_mask):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Adaptation de l'AG pour Vecteurs Binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptez l'AG pour des vecteurs binaires",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Conseil : Pour mutation binaire, flip chaque bit avec probabilit√© mutation_rate",
    "# Pour crossover, utilisez le crossover uniforme standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Ex√©cution et Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cutez l'AG pour feature selection",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# SOLUTION: Ex√©cutez l'AG",
    "# SOLUTION: Affichez les features s√©lectionn√©es",
    "# SOLUTION: Comparez avec utilisation de toutes les features",
    "",
    "# Baseline : Toutes les features",
    "rf_all = RandomForestClassifier(n_estimators=50, random_state=42)",
    "cv_all = cross_val_score(rf_all, X_train, y_train, cv=5)",
    "print(f\"Baseline (toutes features) : {cv_all.mean():.4f} ¬± {cv_all.std():.4f}\")",
    "",
    "# SOLUTION: Comparez avec les features s√©lectionn√©es par l'AG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 4 : Comparaison AG vs GridSearch (Bonus)",
    "",
    "**Objectif** : Comparer l'efficacit√© de l'AG par rapport √† GridSearchCV.",
    "",
    "### 4.1 GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cutez GridSearchCV sur les m√™mes hyperparam√®tres",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "from sklearn.model_selection import GridSearchCV",
    "",
    "param_grid = {",
    "    'n_estimators': [10, 50, 100, 150, 200],",
    "    'max_depth': [2, 5, 10, 15, 20, 30],",
    "    'min_samples_split': [2, 5, 10, 15, 20],",
    "    'min_samples_leaf': [1, 2, 4, 6, 10]",
    "}",
    "",
    "# SOLUTION: Ex√©cutez GridSearchCV et comptez le nombre d'√©valuations",
    "# SOLUTION: Comparez le temps d'ex√©cution et le meilleur score avec l'AG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Analyse Comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ez un tableau comparatif",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Colonnes : M√©thode | Nombre d'√©valuations | Temps (s) | Meilleur Score | Meilleurs Params",
    "",
    "results_df = pd.DataFrame({",
    "    'M√©thode': ['AG', 'GridSearch', 'RandomSearch'],",
    "    'N¬∞ √âvaluations': [None, None, None],",
    "    'Temps (s)': [None, None, None],",
    "    'Meilleur Score': [None, None, None]",
    "})",
    "",
    "# SOLUTION: Remplissez le DataFrame",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 5 : Questions de R√©flexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** : Quels sont les avantages des AG par rapport √† GridSearch et RandomSearch ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 2** : Dans quels cas les AG ne sont PAS appropri√©s ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 3** : Comment √©viter la convergence pr√©matur√©e (stagnation) dans un AG ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 4** : Pourquoi utilise-t-on l'√©litisme dans les AG ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Conclusion",
    "",
    "F√©licitations pour avoir compl√©t√© ces exercices !",
    "",
    "**Points cl√©s √† retenir** :",
    "- Les AG sont des m√©taheuristiques d'optimisation sans gradient",
    "- Ils fonctionnent bien sur des espaces de recherche complexes et non-convexes",
    "- Les op√©rateurs g√©n√©tiques (s√©lection, crossover, mutation) √©quilibrent exploration et exploitation",
    "- Les AG sont efficaces pour l'optimisation d'hyperparam√®tres et la s√©lection de features",
    "- Le design de la fonction de fitness est crucial (objectif + p√©nalit√©s)",
    "",
    "**Prochaines √©tapes** :",
    "- Consultez les solutions dans `10_exercices_solutions.ipynb`",
    "- Testez les AG sur d'autres probl√®mes d'optimisation",
    "- Explorez des variantes : Differential Evolution, Particle Swarm Optimization",
    "- Passez au Chapitre 11 (S√©ries Temporelles)",
    "",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}