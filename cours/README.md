# Cours Complet de Machine Learning

**Niveau** : Interm√©diaire √† Avanc√©
**Pr√©requis** : Bon niveau scientifique/math√©matique/informatique, Python
**Dur√©e estim√©e** : 70-84 heures (6 parties, 14 chapitres)

---

## üìö Vue d'Ensemble

Ce cours offre une formation compl√®te en Machine Learning, couvrant :
- Les fondamentaux th√©oriques (math√©matiques, statistiques)
- Les algorithmes classiques (r√©gression, classification, clustering)
- Le Deep Learning (CNN, RNN, Transformers)
- Les paradigmes avanc√©s (Reinforcement Learning, Algorithmes G√©n√©tiques)
- Les bonnes pratiques de production (MLOps, d√©ploiement)

Chaque chapitre comprend :
- **PDF th√©orique** (15-35 pages) - Concepts, math√©matiques, algorithmes
- **Notebooks de d√©monstration** (1-4 par chapitre) - Code comment√© et visualisations
- **Exercices pratiques** avec solutions

---

## üìñ Structure du Cours

### Partie 1 : Fondations (3 chapitres, 6-9h)

#### [Chapitre 00 - Introduction au Machine Learning](00_introduction/)
- D√©finitions et histoire du ML
- Types d'apprentissage (supervis√©, non-supervis√©, par renforcement)
- Pipeline ML et vocabulaire fondamental
- Applications et √©thique

#### [Chapitre 01 - Fondamentaux Math√©matiques](01_fondamentaux_mathematiques/)
- Alg√®bre lin√©aire (vecteurs, matrices, SVD)
- Statistiques et probabilit√©s (distributions, th√©or√®me de Bayes)
- Calcul diff√©rentiel (gradient, descente de gradient)

#### [Chapitre 02 - M√©triques d'√âvaluation](02_metriques_evaluation/)
- M√©triques de classification (accuracy, precision, recall, F1, ROC-AUC)
- M√©triques de r√©gression (MSE, RMSE, MAE, R¬≤)
- Validation crois√©e (K-fold, stratified, time series split)

---

### Partie 2 : Machine Learning Classique (3 chapitres, 16-20h)

#### [Chapitre 03 - R√©gression](03_regression/)
- R√©gression lin√©aire (simple, multiple, polynomiale)
- R√©gularisation (Ridge, Lasso, Elastic Net)
- Diagnostic et analyse des r√©sidus

#### [Chapitre 04 - Classification Supervis√©e](04_classification_supervisee/)
- Arbres de d√©cision (CART, Random Forest)
- K-Nearest Neighbors (KNN)
- Support Vector Machines (SVM)
- M√©thodes d'ensemble (Bagging, Boosting, XGBoost)

#### [Chapitre 05 - Apprentissage Non-Supervis√©](05_apprentissage_non_supervise/)
- Clustering (K-means, DBSCAN, hierarchique)
- R√©duction de dimensionnalit√© (PCA, t-SNE, UMAP)
- D√©tection d'anomalies

---

### Partie 3 : Deep Learning (3 chapitres, 18-22h)

#### [Chapitre 06 - R√©seaux de Neurones Fondamentaux](06_reseaux_neurones_fondamentaux/)
- Perceptron et MLP
- Backpropagation (d√©rivation compl√®te)
- Fonctions d'activation et optimiseurs
- R√©gularisation (dropout, batch normalization)

#### [Chapitre 07 - Deep Learning - CNN](07_deep_learning_cnn/)
- Convolution 2D et pooling
- Architectures classiques (LeNet, AlexNet, ResNet)
- Transfer learning
- Applications en vision par ordinateur

#### [Chapitre 08 - Deep Learning - RNN et Transformers](08_deep_learning_rnn/)
- RNN, LSTM, GRU
- Attention mechanism
- Transformers (BERT, GPT introduction)
- Applications NLP et s√©ries temporelles

---

### Partie 4 : Paradigmes Alternatifs (2 chapitres, 8-10h)

#### [Chapitre 09 - Reinforcement Learning](09_reinforcement_learning/)
- MDP et √©quation de Bellman
- Q-Learning et SARSA
- Deep Q-Network (DQN)
- Policy Gradient et Actor-Critic
- Applications (jeux, robotique)

#### [Chapitre 10 - Algorithmes G√©n√©tiques](10_algorithmes_genetiques/)
- Inspiration √©volutionnaire
- S√©lection, croisement, mutation
- Optimisation de fonctions
- Applications (TSP, hyperparameter tuning)

---

### Partie 5 : Applications Avanc√©es du Deep Learning (3 chapitres, 12-15h)

#### [Chapitre 11 - S√©ries Temporelles et Forecasting](11_series_temporelles/)
- Stationnarit√©, d√©composition, autocorr√©lation
- Mod√®les classiques (ARIMA, SARIMA, Prophet)
- Deep Learning (LSTM, GRU, Attention)
- M√©triques et validation temporelles
- D√©tection d'anomalies

#### [Chapitre 12 - Vision par Ordinateur Avanc√©e](12_vision_avancee/)
- Object Detection (R-CNN, Fast/Faster R-CNN, YOLO)
- Semantic Segmentation (FCN, U-Net, DeepLab)
- Instance Segmentation (Mask R-CNN)
- Vision Transformers (ViT, Swin)
- Vision-Language Models (CLIP)

#### [Chapitre 13 - Syst√®mes de Recommandation](13_systemes_recommandation/)
- Collaborative Filtering (User-Based, Item-Based, Matrix Factorization)
- Deep Learning (NCF, Autoencoders, Two-Tower Models)
- Content-Based Filtering (TF-IDF, Embeddings)
- Syst√®mes Hybrides
- M√©triques (RMSE, Precision@K, Recall@K, NDCG)
- Probl√®mes pratiques (Cold Start, Sparsity, Scalability)

---

### Partie 6 : Production et Best Practices (1 chapitre, 6-8h)

#### [Chapitre 14 - MLOps et D√©ploiement](14_best_practices/)
- Pipeline ML complet (EDA, feature engineering, validation)
- Hyperparameter tuning (GridSearch, Optuna)
- Interpr√©tabilit√© (SHAP, LIME)
- MLOps (tracking, versioning, monitoring)
- D√©ploiement (API FastAPI, conteneurisation Docker)
- Scalabilit√© et production

---

### Annexes

- **Annexe A** : Datasets de r√©f√©rence (30+ datasets annot√©s)
- **Annexe B** : Ressources suppl√©mentaires (livres, cours, blogs)
- **Annexe C** : Glossaire (150+ termes fran√ßais/anglais)

---

## üöÄ D√©marrage Rapide

### Installation

```bash
# Cloner le repository
git clone https://github.com/ogautier1980/sandbox-ml.git
cd sandbox-ml

# D√©marrer l'environnement Docker
docker-compose up -d --build

# Acc√©der √† Jupyter Lab
# http://localhost:8888
```

### Navigation

1. **Lire le PDF th√©orique** dans chaque chapitre
2. **Ex√©cuter les notebooks de d√©monstration** dans Jupyter Lab
3. **Faire les exercices** (solutions s√©par√©es)
4. **Passer au chapitre suivant**

---

## üìä Datasets Utilis√©s

- **Iris** - Classification multi-classe (ch. 00, 04, 05)
- **Diabetes** - R√©gression (ch. 03)
- **Breast Cancer** - Classification binaire (ch. 04)
- **MNIST** - Vision, chiffres manuscrits (ch. 05, 06, 07)
- **CIFAR-10** - Images couleur (ch. 07)
- **IMDB Reviews** - NLP, sentiment analysis (ch. 08)
- **Frozen Lake / CartPole** - Reinforcement Learning (ch. 09)
- **MovieLens** - Syst√®mes de recommandation (ch. 14)
- **Kaggle Competitions** - Projets r√©alistes (ch. 11)

---

## üõ†Ô∏è Outils et Librairies

### ML Classique
- **scikit-learn** - Algorithmes, m√©triques, pipelines
- **NumPy, Pandas** - Manipulation de donn√©es
- **Matplotlib, Seaborn, Plotly** - Visualisation

### Deep Learning
- **PyTorch** - Framework principal
- **torchvision** - Vision par ordinateur
- **Hugging Face Transformers** - NLP

### MLOps
- **MLflow** - Tracking exp√©riences
- **Optuna** - Hyperparameter tuning
- **SHAP** - Interpr√©tabilit√©
- **FastAPI, Streamlit** - D√©ploiement

---

## üìà Progression Recommand√©e

### D√©butant ‚Üí Interm√©diaire
Chapitres **00 ‚Üí 05** (fondations + ML classique)

### Interm√©diaire ‚Üí Avanc√©
Chapitres **06 ‚Üí 08** (Deep Learning)

### Avanc√© ‚Üí Expert
Chapitres **09 ‚Üí 11** (RL, GA, production)

---

## üéØ Objectifs d'Apprentissage

√Ä la fin de ce cours, vous serez capable de :

‚úÖ Comprendre les fondements math√©matiques du ML
‚úÖ Choisir et impl√©menter l'algorithme adapt√© √† un probl√®me
‚úÖ √âvaluer rigoureusement les performances d'un mod√®le
‚úÖ Construire des r√©seaux de neurones profonds (CNN, RNN, Transformers)
‚úÖ Appliquer le Reinforcement Learning √† des probl√®mes de d√©cision
‚úÖ D√©ployer des mod√®les en production avec MLOps
‚úÖ Interpr√©ter et expliquer les pr√©dictions d'un mod√®le

---

## üîó R√©f√©rences Principales

- **Documentation officielle** : [scikit-learn](https://scikit-learn.org/), [PyTorch](https://pytorch.org/)
- **Livres** : Hands-On ML (G√©ron), Deep Learning Book (Goodfellow)
- **Cours** : Stanford CS229, fast.ai, Coursera ML Specialization

---

## üë• Public Cible

Ce cours s'adresse √† :
- √âtudiants en Master/Ing√©nierie (informatique, math√©matiques, physique)
- Data Scientists souhaitant approfondir leurs connaissances
- D√©veloppeurs voulant se sp√©cialiser en ML/IA
- Chercheurs n√©cessitant des bases solides en apprentissage automatique

**Pr√©requis techniques** :
- Python (NumPy, Pandas)
- Math√©matiques (alg√®bre lin√©aire, probabilit√©s, d√©riv√©es)
- Statistiques de base

---

## üìù Licence

Ce cours est destin√© √† un usage √©ducatif.

---

## ü§ù Contribution

Pour toute suggestion ou correction :
- Ouvrir une issue sur [GitHub](https://github.com/ogautier1980/sandbox-ml/issues)
- Proposer une pull request

---

**Bonne formation ! üöÄ**
