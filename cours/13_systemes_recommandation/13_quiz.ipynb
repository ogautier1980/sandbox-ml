{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz d'Auto-√âvaluation - Chapitre 13 : Syst√®mes de Recommandation\n",
    "\n",
    "**Instructions** :\n",
    "- Ce quiz contient 15 questions pour tester votre compr√©hension du chapitre\n",
    "- R√©pondez aux questions par vous-m√™me avant de regarder les r√©ponses\n",
    "- Les r√©ponses sont dans une cellule masqu√©e √† la fin\n",
    "- Comptez 1 point par bonne r√©ponse\n",
    "\n",
    "**Bar√®me** :\n",
    "- 13-15 : Excellent ! Vous ma√Ætrisez le chapitre üí™\n",
    "- 10-12 : Bien, relisez les sections o√π vous avez des lacunes\n",
    "- 7-9 : Moyen, relisez le chapitre attentivement\n",
    "- < 7 : Insuffisant, reprenez le chapitre depuis le d√©but\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "### Question 1 : D√©finition des Syst√®mes de Recommandation\n",
    "Parmi les statistiques suivantes sur l'impact business des recommandations, laquelle est FAUSSE selon le cours ?\n",
    "\n",
    "A) Netflix : 80% du contenu visionn√© provient de recommandations  \n",
    "B) Amazon : 35% des ventes proviennent de recommandations  \n",
    "C) YouTube : 50% du temps de visionnage provient de recommandations  \n",
    "D) Spotify : Les playlists personnalis√©es augmentent l'engagement de 40%  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : User-Item Matrix\n",
    "Quelle est la caract√©ristique principale de la matrice user-item dans la plupart des applications r√©elles ?\n",
    "\n",
    "A) Elle est dense (la plupart des entr√©es sont remplies)  \n",
    "B) Elle est sparse (la plupart des entr√©es sont manquantes)  \n",
    "C) Elle contient uniquement des valeurs binaires  \n",
    "D) Elle est toujours de petite taille  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : Similarit√© Cosine vs Pearson\n",
    "Quelle mesure de similarit√© est plus appropri√©e pour capturer les pr√©f√©rences relatives entre utilisateurs ?\n",
    "\n",
    "A) Similarit√© Cosine  \n",
    "B) Corr√©lation de Pearson  \n",
    "C) Similarit√© Jaccard  \n",
    "D) Distance Euclidienne  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : User-Based vs Item-Based CF\n",
    "Pourquoi l'Item-Based Collaborative Filtering est-il souvent pr√©f√©r√© au User-Based ?\n",
    "\n",
    "A) Il est plus pr√©cis dans tous les cas  \n",
    "B) Les similarit√©s items sont plus stables et faciles √† pr√©-calculer  \n",
    "C) Il n√©cessite moins de donn√©es  \n",
    "D) Il fonctionne mieux avec peu d'utilisateurs  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : Matrix Factorization\n",
    "Dans la factorisation de matrice $\\mathbf{R} \\approx \\mathbf{U} \\mathbf{V}^T$, que repr√©sentent les matrices $\\mathbf{U}$ et $\\mathbf{V}$ ?\n",
    "\n",
    "A) Les ratings observ√©s et pr√©dits  \n",
    "B) Les features latentes des utilisateurs et des items  \n",
    "C) Les similarit√©s entre utilisateurs et items  \n",
    "D) Les donn√©es d'entra√Ænement et de test  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : ALS (Alternating Least Squares)\n",
    "Quel est le principe de l'algorithme ALS pour la factorisation de matrice ?\n",
    "\n",
    "A) Optimiser simultan√©ment U et V avec gradient descent  \n",
    "B) Fixer alternativement U puis V et optimiser l'autre  \n",
    "C) Utiliser uniquement SVD classique  \n",
    "D) Calculer directement l'inverse de la matrice  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 : Neural Collaborative Filtering (NCF)\n",
    "Quelle est la principale diff√©rence entre NCF et Matrix Factorization classique ?\n",
    "\n",
    "A) NCF utilise des donn√©es textuelles  \n",
    "B) NCF remplace le produit scalaire par un r√©seau de neurones  \n",
    "C) NCF ne n√©cessite pas d'embeddings  \n",
    "D) NCF est plus rapide √† entra√Æner  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 : Two-Tower Model\n",
    "Quel est l'avantage principal du mod√®le Two-Tower pour la scalabilit√© ?\n",
    "\n",
    "A) Il n√©cessite moins de m√©moire  \n",
    "B) Les embeddings items peuvent √™tre pr√©-calcul√©s pour une recherche rapide  \n",
    "C) Il converge plus rapidement  \n",
    "D) Il √©limine le cold start problem  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 : Content-Based Filtering\n",
    "Quelle technique est utilis√©e pour repr√©senter des items textuels en Content-Based Filtering ?\n",
    "\n",
    "A) K-Means clustering  \n",
    "B) TF-IDF vectorization  \n",
    "C) Random Forest  \n",
    "D) Dropout regularization  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 : M√©triques de Ranking\n",
    "Pour un syst√®me de recommandation Top-K, quelle m√©trique prend en compte l'ORDRE des recommandations et permet des relevances graduelles ?\n",
    "\n",
    "A) Precision@K  \n",
    "B) Recall@K  \n",
    "C) NDCG@K  \n",
    "D) RMSE  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11 : Cold Start Problem\n",
    "Quelle approche est la PLUS efficace pour r√©soudre le cold start des nouveaux utilisateurs ?\n",
    "\n",
    "A) Utiliser uniquement Collaborative Filtering  \n",
    "B) Utiliser un syst√®me hybride (CF + Content-Based) ou onboarding  \n",
    "C) Augmenter le nombre de facteurs latents  \n",
    "D) R√©duire la r√©gularisation  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12 : Sparsity\n",
    "Dans le dataset MovieLens avec 100,000 ratings, 1,682 films et 943 utilisateurs, quelle est approximativement la densit√© de la matrice ?\n",
    "\n",
    "A) ~1%  \n",
    "B) ~6%  \n",
    "C) ~25%  \n",
    "D) ~50%  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13 : Scalabilit√©\n",
    "Pour un syst√®me de recommandation avec des millions d'items, quelle technique permet une recherche rapide des voisins les plus proches en $O(\\log n)$ ?\n",
    "\n",
    "A) Calcul exhaustif de toutes les similarit√©s  \n",
    "B) Approximate Nearest Neighbors (ANN) avec FAISS ou Annoy  \n",
    "C) User-Based Collaborative Filtering  \n",
    "D) Augmentation du batch size  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14 : Diversity vs Accuracy\n",
    "Quel probl√®me peut survenir si on maximise uniquement l'accuracy (RMSE, NDCG) d'un syst√®me de recommandation ?\n",
    "\n",
    "A) Le mod√®le convergera plus lentement  \n",
    "B) Le syst√®me n√©cessitera plus de m√©moire  \n",
    "C) Filter bubble et manque de diversit√© dans les recommandations  \n",
    "D) L'entra√Ænement sera plus co√ªteux  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15 : Pipeline Two-Stage\n",
    "Dans les syst√®mes de recommandation industriels (YouTube, Netflix), pourquoi utilise-t-on un pipeline en deux √©tapes ?\n",
    "\n",
    "A) Pour r√©duire le co√ªt de stockage  \n",
    "B) Pour g√©n√©rer rapidement des candidats puis les ranker finement  \n",
    "C) Pour am√©liorer la diversit√© uniquement  \n",
    "D) Pour faciliter le debugging  \n",
    "\n",
    "**Votre r√©ponse** : ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Auto-Correction\n",
    "\n",
    "Avant de regarder les r√©ponses, comptez combien de r√©ponses vous avez donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrez vos r√©ponses ici (ex: ['C', 'B', 'B', ...])\n",
    "mes_reponses = []  # TODO: remplir avec vos r√©ponses\n",
    "\n",
    "# R√©ponses correctes (masqu√©es)\n",
    "reponses_correctes = ['C', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'C', 'B', 'B', 'B', 'C', 'B']\n",
    "\n",
    "if len(mes_reponses) == 15:\n",
    "    score = sum([1 for i, r in enumerate(mes_reponses) if r.upper() == reponses_correctes[i]])\n",
    "    print(f\"Votre score : {score}/15\")\n",
    "    \n",
    "    if score >= 13:\n",
    "        print(\"\\nüéâ Excellent ! Vous ma√Ætrisez le chapitre !\")\n",
    "    elif score >= 10:\n",
    "        print(\"\\n‚úÖ Bien ! Relisez les sections o√π vous avez des lacunes.\")\n",
    "    elif score >= 7:\n",
    "        print(\"\\n‚ö†Ô∏è  Moyen. Relisez le chapitre attentivement.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Insuffisant. Reprenez le chapitre depuis le d√©but.\")\n",
    "    \n",
    "    # Afficher les erreurs\n",
    "    print(\"\\nD√©tail :\")\n",
    "    for i, (ma_rep, bonne_rep) in enumerate(zip(mes_reponses, reponses_correctes), 1):\n",
    "        if ma_rep.upper() == bonne_rep:\n",
    "            print(f\"Q{i}: ‚úì Correct\")\n",
    "        else:\n",
    "            print(f\"Q{i}: ‚úó Votre r√©ponse: {ma_rep}, Correcte: {bonne_rep}\")\n",
    "else:\n",
    "    print(\"Veuillez remplir toutes les r√©ponses (15 lettres A, B, C ou D)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Explications des R√©ponses\n",
    "\n",
    "### Q1 : C\n",
    "**FAUX** : YouTube g√©n√®re **70%** (et non 50%) du temps de visionnage via recommandations selon le cours.\n",
    "\n",
    "### Q2 : B\n",
    "La matrice user-item est **sparse** - la plupart des utilisateurs n'ont rat√© qu'une petite fraction des items disponibles. MovieLens a une densit√© de ~6.3%.\n",
    "\n",
    "### Q3 : B\n",
    "La **corr√©lation de Pearson** capture mieux les pr√©f√©rences relatives car elle centre les ratings autour de la moyenne, contrairement √† la similarit√© cosine.\n",
    "\n",
    "### Q4 : B\n",
    "L'**Item-Based CF** est pr√©f√©r√© car les items changent moins que les utilisateurs, permettant de **pr√©-calculer et mettre en cache** les similarit√©s de mani√®re stable.\n",
    "\n",
    "### Q5 : B\n",
    "Les matrices $\\mathbf{U}$ et $\\mathbf{V}$ contiennent les **features latentes** (facteurs latents) apprises pour utilisateurs et items respectivement.\n",
    "\n",
    "### Q6 : B\n",
    "ALS **fixe alternativement** une matrice (U ou V) et optimise l'autre de mani√®re analytique, r√©p√©tant jusqu'√† convergence.\n",
    "\n",
    "### Q7 : B\n",
    "NCF remplace le **produit scalaire** des embeddings par un **MLP** (r√©seau de neurones) pour capturer des interactions non-lin√©aires.\n",
    "\n",
    "### Q8 : B\n",
    "Le mod√®le Two-Tower permet de **pr√©-calculer les embeddings items** et d'utiliser des structures ANN (Approximate Nearest Neighbors) pour une recherche ultra-rapide.\n",
    "\n",
    "### Q9 : B\n",
    "**TF-IDF** (Term Frequency - Inverse Document Frequency) est la technique standard pour vectoriser des documents textuels en Content-Based Filtering.\n",
    "\n",
    "### Q10 : C\n",
    "**NDCG@K** (Normalized Discounted Cumulative Gain) prend en compte l'**ordre** des recommandations et permet des **relevances graduelles** (pas seulement binaire).\n",
    "\n",
    "### Q11 : B\n",
    "Les **syst√®mes hybrides** (CF + content-based) ou l'**onboarding** (demander les pr√©f√©rences initiales) sont les solutions les plus efficaces pour le cold start.\n",
    "\n",
    "### Q12 : B\n",
    "Densit√© = $\\frac{100,000}{1,682 \\times 943} \\approx$ **6.3%**. La matrice est donc sparse √† ~94%.\n",
    "\n",
    "### Q13 : B\n",
    "Les algorithmes **ANN** (Approximate Nearest Neighbors) comme **FAISS** (Facebook) et **Annoy** (Spotify) permettent une recherche en $O(\\log n)$ au lieu de $O(n)$.\n",
    "\n",
    "### Q14 : C\n",
    "Maximiser uniquement l'accuracy peut conduire √† une **filter bubble** (bulle de filtres), un **manque de diversit√©** et un **popularity bias** (sur-recommandation des items populaires).\n",
    "\n",
    "### Q15 : B\n",
    "Le pipeline **candidate generation + ranking** permet de g√©n√©rer rapidement 100-1000 candidats avec un mod√®le simple, puis de les **ranker finement** avec un mod√®le complexe pour √©quilibrer vitesse et pr√©cision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prochaines √âtapes\n",
    "\n",
    "- **Score < 10** : Relisez le chapitre 13 attentivement, en particulier les sections sur CF, Matrix Factorization et Deep Learning\n",
    "- **Score >= 10** : Passez au Chapitre 14 (Best Practices)\n",
    "- **R√©vision recommand√©e** : Pratiquez avec les notebooks `13_demo_collaborative_filtering.ipynb`, `13_demo_neural_recommenders.ipynb` et `13_exercices.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
