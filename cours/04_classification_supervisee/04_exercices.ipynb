{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/04_classification_supervisee/04_exercices.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '04_exercices.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 04 - Exercices de Classification Supervis√©e\n",
    "\n",
    "Ce notebook contient des exercices pratiques sur les algorithmes de classification.\n",
    "\n",
    "## Objectifs\n",
    "- Appliquer KNN, arbres, boosting et SVM\n",
    "- Comparer les performances\n",
    "- Optimiser les hyperparam√®tres\n",
    "- Diagnostiquer les probl√®mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits, fetch_covtype\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Classification de Chiffres Manuscrits (Digits Dataset)\n",
    "\n",
    "**Objectif** : Classifier les chiffres manuscrits (0-9) avec diff√©rents algorithmes.\n",
    "\n",
    "**Consignes** :\n",
    "1. Charger le dataset Digits (8x8 images)\n",
    "2. Explorer les donn√©es et visualiser quelques exemples\n",
    "3. Entra√Æner KNN, Decision Tree, Random Forest, XGBoost\n",
    "4. Comparer les performances (accuracy, F1, temps)\n",
    "5. Analyser les erreurs avec la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement des donn√©es\n",
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "print(f\"Shape: {X_digits.shape}\")\n",
    "print(f\"Nombre de classes: {len(np.unique(y_digits))}\")\n",
    "print(f\"Distribution des classes:\\n{np.bincount(y_digits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Visualisation d'exemples\n",
    "fig, axes = plt.subplots(2, 10, figsize=(16, 4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(digits.images[i], cmap='gray')\n",
    "    axes[i].set_title(f'Label: {y_digits[i]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pr√©paration des donn√©es\n",
    "X_train_dig, X_test_dig, y_train_dig, y_test_dig = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.2, random_state=42, stratify=y_digits\n",
    ")\n",
    "\n",
    "# Standardisation pour KNN\n",
    "scaler_dig = StandardScaler()\n",
    "X_train_dig_scaled = scaler_dig.fit_transform(X_train_dig)\n",
    "X_test_dig_scaled = scaler_dig.transform(X_test_dig)\n",
    "\n",
    "print(f\"Train set: {X_train_dig.shape}\")\n",
    "print(f\"Test set: {X_test_dig.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Entra√Ænement et comparaison des mod√®les\n",
    "models_dig = {\n",
    "    'KNN (k=5)': (KNeighborsClassifier(n_neighbors=5), True),  # True = needs scaling\n",
    "    'Decision Tree': (DecisionTreeClassifier(max_depth=10, random_state=42), False),\n",
    "    'Random Forest': (RandomForestClassifier(n_estimators=100, random_state=42), False),\n",
    "    'XGBoost': (xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss'), False)\n",
    "}\n",
    "\n",
    "results_dig = []\n",
    "\n",
    "for name, (model, needs_scaling) in models_dig.items():\n",
    "    # Choisir les donn√©es appropri√©es\n",
    "    X_tr = X_train_dig_scaled if needs_scaling else X_train_dig\n",
    "    X_te = X_test_dig_scaled if needs_scaling else X_test_dig\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    start = time()\n",
    "    model.fit(X_tr, y_train_dig)\n",
    "    train_time = time() - start\n",
    "    \n",
    "    # Pr√©diction\n",
    "    start = time()\n",
    "    y_pred = model.predict(X_te)\n",
    "    pred_time = time() - start\n",
    "    \n",
    "    # M√©triques\n",
    "    results_dig.append({\n",
    "        'Model': name,\n",
    "        'Train Acc': model.score(X_tr, y_train_dig),\n",
    "        'Test Acc': accuracy_score(y_test_dig, y_pred),\n",
    "        'Precision': precision_score(y_test_dig, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test_dig, y_pred, average='weighted'),\n",
    "        'F1': f1_score(y_test_dig, y_pred, average='weighted'),\n",
    "        'Train Time': train_time,\n",
    "        'Pred Time': pred_time\n",
    "    })\n",
    "\n",
    "results_dig_df = pd.DataFrame(results_dig)\n",
    "print(\"R√©sultats sur Digits Dataset:\")\n",
    "print(results_dig_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].barh(results_dig_df['Model'], results_dig_df['Test Acc'], alpha=0.7)\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_title('Test Accuracy')\n",
    "axes[0].set_xlim(0.8, 1.0)\n",
    "\n",
    "# F1 Score\n",
    "axes[1].barh(results_dig_df['Model'], results_dig_df['F1'], alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('F1 Score')\n",
    "axes[1].set_title('F1 Score (Weighted)')\n",
    "axes[1].set_xlim(0.8, 1.0)\n",
    "\n",
    "# Train Time\n",
    "axes[2].barh(results_dig_df['Model'], results_dig_df['Train Time'], alpha=0.7, color='green')\n",
    "axes[2].set_xlabel('Temps (s)')\n",
    "axes[2].set_title('Temps d\\'Entra√Ænement')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Analyse des erreurs (meilleur mod√®le)\n",
    "best_idx = results_dig_df['Test Acc'].idxmax()\n",
    "best_model_name = results_dig_df.loc[best_idx, 'Model']\n",
    "best_model, needs_scaling = models_dig[best_model_name]\n",
    "\n",
    "X_te = X_test_dig_scaled if needs_scaling else X_test_dig\n",
    "y_pred_best = best_model.predict(X_te)\n",
    "\n",
    "print(f\"Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_dig, y_pred_best))\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test_dig, y_pred_best)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=digits.target_names)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(f'Matrice de Confusion - {best_model_name}')\n",
    "plt.show()\n",
    "\n",
    "# Visualiser quelques erreurs\n",
    "errors = y_test_dig != y_pred_best\n",
    "X_errors = X_test_dig[errors]\n",
    "y_true_errors = y_test_dig[errors]\n",
    "y_pred_errors = y_pred_best[errors]\n",
    "\n",
    "print(f\"\\nNombre d'erreurs: {errors.sum()} / {len(y_test_dig)} ({100*errors.sum()/len(y_test_dig):.2f}%)\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(min(10, len(X_errors))):\n",
    "    axes[i].imshow(X_errors[i].reshape(8, 8), cmap='gray')\n",
    "    axes[i].set_title(f'True: {y_true_errors[i]}\\nPred: {y_pred_errors[i]}', color='red')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Exemples d\\'Erreurs de Classification')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Optimisation des Hyperparam√®tres\n",
    "\n",
    "**Objectif** : Optimiser un Random Forest et un SVM sur le dataset Digits.\n",
    "\n",
    "**Consignes** :\n",
    "1. Random Forest: Optimiser `n_estimators`, `max_depth`, `min_samples_split`\n",
    "2. SVM RBF: Optimiser `C` et `gamma`\n",
    "3. Comparer les performances avant/apr√®s optimisation\n",
    "4. G√©n√©rer les learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Optimisation Random Forest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf, param_dist_rf, n_iter=20, cv=5, \n",
    "    scoring='f1_weighted', random_state=42, n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Optimisation Random Forest...\")\n",
    "rf_search.fit(X_train_dig, y_train_dig)\n",
    "\n",
    "print(f\"\\nMeilleurs param√®tres: {rf_search.best_params_}\")\n",
    "print(f\"Meilleur score F1 (CV): {rf_search.best_score_:.4f}\")\n",
    "\n",
    "# Comparaison avant/apr√®s\n",
    "rf_default = RandomForestClassifier(random_state=42)\n",
    "rf_default.fit(X_train_dig, y_train_dig)\n",
    "\n",
    "y_pred_default = rf_default.predict(X_test_dig)\n",
    "y_pred_optimized = rf_search.best_estimator_.predict(X_test_dig)\n",
    "\n",
    "print(\"\\nComparaison Random Forest:\")\n",
    "print(f\"D√©faut - Test Accuracy: {accuracy_score(y_test_dig, y_pred_default):.4f}\")\n",
    "print(f\"Optimis√© - Test Accuracy: {accuracy_score(y_test_dig, y_pred_optimized):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Optimisation SVM RBF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "svm_search = GridSearchCV(\n",
    "    svm, param_grid_svm, cv=5, \n",
    "    scoring='f1_weighted', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "print(\"Optimisation SVM RBF...\")\n",
    "svm_search.fit(X_train_dig_scaled, y_train_dig)\n",
    "\n",
    "print(f\"\\nMeilleurs param√®tres: {svm_search.best_params_}\")\n",
    "print(f\"Meilleur score F1 (CV): {svm_search.best_score_:.4f}\")\n",
    "\n",
    "# Comparaison avant/apr√®s\n",
    "svm_default = SVC(kernel='rbf')\n",
    "svm_default.fit(X_train_dig_scaled, y_train_dig)\n",
    "\n",
    "y_pred_svm_default = svm_default.predict(X_test_dig_scaled)\n",
    "y_pred_svm_optimized = svm_search.best_estimator_.predict(X_test_dig_scaled)\n",
    "\n",
    "print(\"\\nComparaison SVM:\")\n",
    "print(f\"D√©faut - Test Accuracy: {accuracy_score(y_test_dig, y_pred_svm_default):.4f}\")\n",
    "print(f\"Optimis√© - Test Accuracy: {accuracy_score(y_test_dig, y_pred_svm_optimized):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Learning Curves\n",
    "models_lc = {\n",
    "    'RF D√©faut': rf_default,\n",
    "    'RF Optimis√©': rf_search.best_estimator_,\n",
    "    'SVM D√©faut': svm_default,\n",
    "    'SVM Optimis√©': svm_search.best_estimator_\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, model) in enumerate(models_lc.items()):\n",
    "    # Choisir les donn√©es appropri√©es\n",
    "    if 'SVM' in name:\n",
    "        X_lc = X_train_dig_scaled\n",
    "    else:\n",
    "        X_lc = X_train_dig\n",
    "    \n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_lc, y_train_dig,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    axes[idx].plot(train_sizes, train_mean, 'o-', label='Train', linewidth=2)\n",
    "    axes[idx].fill_between(train_sizes, train_mean - train_std, \n",
    "                            train_mean + train_std, alpha=0.2)\n",
    "    \n",
    "    axes[idx].plot(train_sizes, val_mean, 's-', label='Validation', linewidth=2)\n",
    "    axes[idx].fill_between(train_sizes, val_mean - val_std, \n",
    "                            val_mean + val_std, alpha=0.2)\n",
    "    \n",
    "    axes[idx].set_xlabel('Taille du Training Set')\n",
    "    axes[idx].set_ylabel('Accuracy')\n",
    "    axes[idx].set_title(f'Learning Curve: {name}')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Gestion du D√©s√©quilibre des Classes\n",
    "\n",
    "**Objectif** : Traiter un dataset d√©s√©quilibr√© avec diff√©rentes techniques.\n",
    "\n",
    "**Consignes** :\n",
    "1. Cr√©er un dataset synth√©tique d√©s√©quilibr√© (95% classe 0, 5% classe 1)\n",
    "2. Entra√Æner un mod√®le baseline (sans traitement)\n",
    "3. Utiliser class_weight='balanced'\n",
    "4. Sous-√©chantillonner la classe majoritaire\n",
    "5. Sur-√©chantillonner la classe minoritaire (SMOTE)\n",
    "6. Comparer les performances avec pr√©cision, rappel, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cr√©ation d'un dataset d√©s√©quilibr√©\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.95, 0.05],  # 95% classe 0, 5% classe 1\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Distribution des classes: {np.bincount(y_imb)}\")\n",
    "print(f\"Proportion classe 1: {100 * y_imb.sum() / len(y_imb):.2f}%\")\n",
    "\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.3, random_state=42, stratify=y_imb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Baseline (sans traitement)\n",
    "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_baseline.fit(X_train_imb, y_train_imb)\n",
    "y_pred_baseline = rf_baseline.predict(X_test_imb)\n",
    "\n",
    "print(\"Baseline (sans traitement du d√©s√©quilibre):\")\n",
    "print(classification_report(y_test_imb, y_pred_baseline, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. class_weight='balanced'\n",
    "rf_balanced = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_balanced.fit(X_train_imb, y_train_imb)\n",
    "y_pred_balanced = rf_balanced.predict(X_test_imb)\n",
    "\n",
    "print(\"Avec class_weight='balanced':\")\n",
    "print(classification_report(y_test_imb, y_pred_balanced, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Sous-√©chantillonnage de la classe majoritaire\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train_imb, y_train_imb)\n",
    "\n",
    "print(f\"Apr√®s sous-√©chantillonnage: {np.bincount(y_train_under)}\")\n",
    "\n",
    "rf_under = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under = rf_under.predict(X_test_imb)\n",
    "\n",
    "print(\"\\nAvec sous-√©chantillonnage:\")\n",
    "print(classification_report(y_test_imb, y_pred_under, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Sur-√©chantillonnage avec SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_imb, y_train_imb)\n",
    "\n",
    "print(f\"Apr√®s SMOTE: {np.bincount(y_train_smote)}\")\n",
    "\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = rf_smote.predict(X_test_imb)\n",
    "\n",
    "print(\"\\nAvec SMOTE:\")\n",
    "print(classification_report(y_test_imb, y_pred_smote, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Comparaison globale\n",
    "strategies = {\n",
    "    'Baseline': y_pred_baseline,\n",
    "    'Balanced Weights': y_pred_balanced,\n",
    "    'Under-sampling': y_pred_under,\n",
    "    'SMOTE': y_pred_smote\n",
    "}\n",
    "\n",
    "results_imb = []\n",
    "\n",
    "for name, y_pred in strategies.items():\n",
    "    results_imb.append({\n",
    "        'Strategy': name,\n",
    "        'Accuracy': accuracy_score(y_test_imb, y_pred),\n",
    "        'Precision (Class 1)': precision_score(y_test_imb, y_pred),\n",
    "        'Recall (Class 1)': recall_score(y_test_imb, y_pred),\n",
    "        'F1 (Class 1)': f1_score(y_test_imb, y_pred)\n",
    "    })\n",
    "\n",
    "results_imb_df = pd.DataFrame(results_imb)\n",
    "print(\"\\nComparaison des Strat√©gies:\")\n",
    "print(results_imb_df.to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['Precision (Class 1)', 'Recall (Class 1)', 'F1 (Class 1)']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    axes[idx].barh(results_imb_df['Strategy'], results_imb_df[metric], alpha=0.7)\n",
    "    axes[idx].set_xlabel(metric)\n",
    "    axes[idx].set_title(metric)\n",
    "    axes[idx].set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusions:\")\n",
    "print(\"- Baseline: Haute accuracy mais mauvais rappel pour classe minoritaire\")\n",
    "print(\"- Balanced Weights: Compromis raisonnable\")\n",
    "print(\"- Under-sampling: Perte d'information, peut d√©grader les performances\")\n",
    "print(\"- SMOTE: Souvent le meilleur compromis, g√©n√®re des exemples synth√©tiques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©capitulatif\n",
    "\n",
    "### Points cl√©s abord√©s\n",
    "\n",
    "1. **Classification Multi-classe**\n",
    "   - Application sur dataset Digits (10 classes)\n",
    "   - Comparaison KNN, arbres, boosting\n",
    "   - Analyse des erreurs avec matrice de confusion\n",
    "\n",
    "2. **Optimisation des Hyperparam√®tres**\n",
    "   - GridSearchCV pour recherche exhaustive\n",
    "   - RandomizedSearchCV pour recherche al√©atoire (plus rapide)\n",
    "   - Learning curves pour diagnostiquer biais/variance\n",
    "   - Impact de l'optimisation sur les performances\n",
    "\n",
    "3. **D√©s√©quilibre des Classes**\n",
    "   - Probl√®me fr√©quent en pratique (fraude, maladies rares, etc.)\n",
    "   - Accuracy peut √™tre trompeuse\n",
    "   - Strat√©gies:\n",
    "     - `class_weight='balanced'`: P√©nalise les erreurs sur classe minoritaire\n",
    "     - Under-sampling: R√©duit classe majoritaire\n",
    "     - Over-sampling (SMOTE): Augmente classe minoritaire\n",
    "   - M√©triques appropri√©es: Pr√©cision, Rappel, F1, AUC-ROC\n",
    "\n",
    "### Recommandations pratiques\n",
    "\n",
    "1. **Exploration pr√©liminaire**\n",
    "   - Toujours v√©rifier la distribution des classes\n",
    "   - Visualiser quelques exemples\n",
    "   - Comprendre les features\n",
    "\n",
    "2. **Choix du mod√®le**\n",
    "   - Commencer simple (arbres, KNN)\n",
    "   - Essayer ensemble methods (RF, XGBoost)\n",
    "   - SVM si dataset de taille raisonnable\n",
    "\n",
    "3. **Optimisation**\n",
    "   - Utiliser validation crois√©e\n",
    "   - RandomizedSearchCV si grand espace de recherche\n",
    "   - Ne pas sur-optimiser sur le test set\n",
    "\n",
    "4. **D√©s√©quilibre**\n",
    "   - D√©tecter le d√©s√©quilibre t√¥t\n",
    "   - Choisir m√©triques appropri√©es\n",
    "   - Tester plusieurs strat√©gies\n",
    "   - SMOTE souvent efficace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}