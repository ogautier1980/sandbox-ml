{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/14_best_practices/14_exercices.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('üì¶ Installation des packages...')\n",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn\n",
    "    !pip install -q mlflow fastapi pydantic uvicorn requests joblib\n",
    "    print('‚úÖ Installation termin√©e !')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 14 - Exercices : Best Practices & MLOps\n",
    "\n",
    "Ce notebook contient des exercices pratiques pour consolider les concepts du Chapitre 14.\n",
    "\n",
    "**Instructions** :\n",
    "- Compl√©tez les cellules marqu√©es `# VOTRE CODE ICI`\n",
    "- Les solutions sont disponibles dans `14_exercices_solutions.ipynb`\n",
    "- N'h√©sitez pas √† consulter la documentation (MLflow, FastAPI, Pydantic)\n",
    "\n",
    "**Note** : Certains exercices n√©cessitent l'ex√©cution locale (serveur FastAPI, MLflow UI).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_diabetes, load_wine\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import uvicorn\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Biblioth√®ques import√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 1 : MLflow Tracking\n",
    "\n",
    "**Dataset** : Diabetes (r√©gression)\n",
    "\n",
    "**Objectif** : Utiliser MLflow pour tracker plusieurs exp√©riences.\n",
    "\n",
    "### 1.1 Configuration MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurez MLflow\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# TODO: D√©finissez le tracking URI (local)\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# TODO: Cr√©ez ou d√©finissez une exp√©rience\n",
    "experiment_name = \"diabetes-regression\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úì Exp√©rience MLflow : {experiment_name}\")\n",
    "print(f\"Tracking URI : {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez le dataset Diabetes\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target  # type: ignore\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train : {X_train.shape}, Test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Entra√Ænement avec Tracking MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænez plusieurs mod√®les avec tracking MLflow\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest_10': RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "    'RandomForest_50': RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    'RandomForest_100': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # TODO: D√©marrez un run MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # TODO: Loggez les param√®tres\n",
    "        # mlflow.log_param(\"model_type\", model_name)\n",
    "        # if hasattr(model, 'n_estimators'):\n",
    "        #     mlflow.log_param(\"n_estimators\", model.n_estimators)\n",
    "        \n",
    "        # TODO: Entra√Ænez le mod√®le\n",
    "        start_time = time.time()\n",
    "        # model.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # TODO: Pr√©dictions\n",
    "        # y_pred_train = model.predict(X_train)\n",
    "        # y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        # TODO: Calculez les m√©triques\n",
    "        # train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "        # test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        # train_r2 = r2_score(y_train, y_pred_train)\n",
    "        # test_r2 = r2_score(y_test, y_pred_test)\n",
    "        \n",
    "        # TODO: Loggez les m√©triques\n",
    "        # mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "        # mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "        # mlflow.log_metric(\"train_r2\", train_r2)\n",
    "        # mlflow.log_metric(\"test_r2\", test_r2)\n",
    "        # mlflow.log_metric(\"training_time\", training_time)\n",
    "        \n",
    "        # TODO: Loggez le mod√®le\n",
    "        # mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"{model_name} | Test RMSE: {test_rmse:.2f} | Test R¬≤: {test_r2:.3f}\")\n",
    "\n",
    "print(\"\\n‚úì Toutes les exp√©riences sont enregistr√©es dans MLflow\")\n",
    "print(\"Lancez 'mlflow ui' dans le terminal pour visualiser les r√©sultats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Recherche et Comparaison des Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rez et comparez les runs\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# TODO: R√©cup√©rez l'experiment\n",
    "# experiment = client.get_experiment_by_name(experiment_name)\n",
    "# runs = client.search_runs(experiment.experiment_id)\n",
    "\n",
    "# TODO: Cr√©ez un DataFrame avec les r√©sultats\n",
    "results = []\n",
    "# for run in runs:\n",
    "#     results.append({\n",
    "#         'run_name': run.data.tags.get('mlflow.runName', 'Unknown'),\n",
    "#         'test_rmse': run.data.metrics.get('test_rmse'),\n",
    "#         'test_r2': run.data.metrics.get('test_r2'),\n",
    "#         'training_time': run.data.metrics.get('training_time')\n",
    "#     })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "\n",
    "print(\"\\nComparaison des mod√®les :\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Chargement d'un Mod√®le depuis MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez le meilleur mod√®le\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# TODO: R√©cup√©rez le run_id du meilleur mod√®le\n",
    "# best_run_id = runs[0].info.run_id  # (apr√®s tri par test_rmse)\n",
    "\n",
    "# TODO: Chargez le mod√®le\n",
    "# model_uri = f\"runs:/{best_run_id}/model\"\n",
    "# loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# TODO: Testez le mod√®le charg√©\n",
    "# y_pred = loaded_model.predict(X_test)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(f\"\\nMod√®le charg√© depuis MLflow | Test RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 2 : API REST avec FastAPI\n",
    "\n",
    "**Objectif** : Cr√©er une API pour servir des pr√©dictions.\n",
    "\n",
    "### 2.1 D√©finition des Sch√©mas Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finissez les sch√©mas de validation\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "class DiabetesInput(BaseModel):\n",
    "    \"\"\"\n",
    "    Sch√©ma de validation pour les inputs du mod√®le Diabetes.\n",
    "    10 features : age, sex, bmi, bp, s1, s2, s3, s4, s5, s6\n",
    "    \"\"\"\n",
    "    # TODO: D√©finissez les 10 features avec contraintes\n",
    "    age: float = Field(..., ge=-3, le=3, description=\"Age (standardis√©)\")\n",
    "    sex: float = Field(..., ge=-3, le=3, description=\"Sex (standardis√©)\")\n",
    "    bmi: float = Field(..., ge=-3, le=3, description=\"Body Mass Index\")\n",
    "    bp: float = Field(..., ge=-3, le=3, description=\"Blood Pressure\")\n",
    "    s1: float = Field(..., ge=-3, le=3, description=\"Serum 1\")\n",
    "    s2: float = Field(..., ge=-3, le=3, description=\"Serum 2\")\n",
    "    s3: float = Field(..., ge=-3, le=3, description=\"Serum 3\")\n",
    "    s4: float = Field(..., ge=-3, le=3, description=\"Serum 4\")\n",
    "    s5: float = Field(..., ge=-3, le=3, description=\"Serum 5\")\n",
    "    s6: float = Field(..., ge=-3, le=3, description=\"Serum 6\")\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"age\": 0.05, \"sex\": 0.05, \"bmi\": 0.06, \"bp\": 0.02,\n",
    "                \"s1\": -0.04, \"s2\": -0.03, \"s3\": -0.00, \"s4\": -0.00,\n",
    "                \"s5\": 0.01, \"s6\": -0.04\n",
    "            }\n",
    "        }\n",
    "\n",
    "class PredictionOutput(BaseModel):\n",
    "    \"\"\"Sch√©ma de sortie.\"\"\"\n",
    "    prediction: float\n",
    "    model_name: str\n",
    "    timestamp: str\n",
    "\n",
    "print(\"‚úì Sch√©mas Pydantic d√©finis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cr√©ation de l'API FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ez l'application FastAPI\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# Note : Ce code doit √™tre ex√©cut√© dans un script Python s√©par√© (api.py)\n",
    "# pour √™tre lanc√© avec uvicorn\n",
    "\n",
    "# Exemple de structure :\n",
    "\"\"\"\n",
    "# api.py\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "import joblib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Cr√©ez l'app\n",
    "app = FastAPI(title=\"Diabetes Prediction API\", version=\"1.0\")\n",
    "\n",
    "# TODO: Chargez le mod√®le au d√©marrage\n",
    "model = None  # joblib.load('diabetes_model.pkl')\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"Diabetes Prediction API\", \"version\": \"1.0\"}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    # TODO: V√©rifiez que le mod√®le est charg√©\n",
    "    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionOutput)\n",
    "def predict(data: DiabetesInput):\n",
    "    # TODO: Convertissez les donn√©es en array\n",
    "    # TODO: Faites la pr√©diction\n",
    "    # TODO: Retournez le r√©sultat\n",
    "    pass\n",
    "\n",
    "@app.post(\"/predict/batch\")\n",
    "def predict_batch(data: list[DiabetesInput]):\n",
    "    # TODO: Pr√©dictions en batch\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "print(\"Exemple de structure API cr√©√©\")\n",
    "print(\"\\nPour ex√©cuter :\")\n",
    "print(\"1. Sauvegardez le code ci-dessus dans 'api.py'\")\n",
    "print(\"2. Sauvegardez un mod√®le : joblib.dump(model, 'diabetes_model.pkl')\")\n",
    "print(\"3. Lancez : uvicorn api:app --reload\")\n",
    "print(\"4. Documentation : http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sauvegarde du Mod√®le pour l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegardez un mod√®le entra√Æn√©\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# TODO: Entra√Ænez un mod√®le\n",
    "model_api = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model_api.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Sauvegardez avec joblib\n",
    "joblib.dump(model_api, 'diabetes_model.pkl')\n",
    "\n",
    "print(\"‚úì Mod√®le sauvegard√© dans 'diabetes_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Test de l'API (apr√®s d√©marrage du serveur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez l'API avec requests\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# Note : L'API doit √™tre d√©marr√©e (uvicorn api:app)\n",
    "\n",
    "# TODO: Test health check\n",
    "# response = requests.get(\"http://localhost:8000/health\")\n",
    "# print(f\"Health Check : {response.json()}\")\n",
    "\n",
    "# TODO: Test pr√©diction\n",
    "# test_data = {\n",
    "#     \"age\": 0.05, \"sex\": 0.05, \"bmi\": 0.06, \"bp\": 0.02,\n",
    "#     \"s1\": -0.04, \"s2\": -0.03, \"s3\": -0.00, \"s4\": -0.00,\n",
    "#     \"s5\": 0.01, \"s6\": -0.04\n",
    "# }\n",
    "# response = requests.post(\"http://localhost:8000/predict\", json=test_data)\n",
    "# print(f\"\\nPr√©diction : {response.json()}\")\n",
    "\n",
    "print(\"\\nPour tester l'API :\")\n",
    "print(\"1. Assurez-vous que l'API est d√©marr√©e\")\n",
    "print(\"2. D√©commentez et ex√©cutez le code ci-dessus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 3 : Monitoring et M√©triques\n",
    "\n",
    "**Objectif** : Ajouter du monitoring √† l'API.\n",
    "\n",
    "### 3.1 Classe de Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez une classe de monitoring\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "class APIMonitor:\n",
    "    def __init__(self):\n",
    "        # TODO: Initialisez les compteurs\n",
    "        self.total_requests = 0\n",
    "        self.total_errors = 0\n",
    "        self.response_times = []\n",
    "        self.predictions = []\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def log_request(self, response_time, success=True, prediction=None):\n",
    "        \"\"\"Enregistre une requ√™te.\"\"\"\n",
    "        # TODO: Incr√©mentez les compteurs\n",
    "        pass\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Retourne les m√©triques.\"\"\"\n",
    "        # TODO: Calculez les statistiques\n",
    "        uptime = time.time() - self.start_time\n",
    "        \n",
    "        return {\n",
    "            \"total_requests\": self.total_requests,\n",
    "            \"total_errors\": self.total_errors,\n",
    "            \"error_rate\": self.total_errors / max(self.total_requests, 1),\n",
    "            \"avg_response_time\": np.mean(self.response_times) if self.response_times else 0,\n",
    "            \"p95_response_time\": np.percentile(self.response_times, 95) if self.response_times else 0,\n",
    "            \"uptime_seconds\": uptime,\n",
    "            \"requests_per_second\": self.total_requests / max(uptime, 1)\n",
    "        }\n",
    "\n",
    "# Test\n",
    "monitor = APIMonitor()\n",
    "monitor.log_request(0.05, success=True, prediction=150.0)\n",
    "monitor.log_request(0.03, success=True, prediction=180.0)\n",
    "monitor.log_request(0.10, success=False)\n",
    "\n",
    "print(\"M√©triques :\")\n",
    "print(monitor.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ajout du Monitoring √† l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code √† ajouter dans api.py\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "\"\"\"\n",
    "# Dans api.py\n",
    "\n",
    "monitor = APIMonitor()\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def add_monitoring(request, call_next):\n",
    "    start_time = time.time()\n",
    "    response = await call_next(request)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    # TODO: Loggez la requ√™te\n",
    "    monitor.log_request(response_time, success=response.status_code < 400)\n",
    "    \n",
    "    return response\n",
    "\n",
    "@app.get(\"/metrics\")\n",
    "def get_metrics():\n",
    "    return monitor.get_metrics()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Code de monitoring pour l'API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 4 : Load Testing\n",
    "\n",
    "**Objectif** : Tester les performances de l'API sous charge.\n",
    "\n",
    "### 4.1 Script de Load Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez un load test simple\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "def load_test(url, n_requests=100, n_workers=10):\n",
    "    \"\"\"\n",
    "    Effectue un load test sur l'API.\n",
    "    Args:\n",
    "        url: URL de l'endpoint\n",
    "        n_requests: Nombre total de requ√™tes\n",
    "        n_workers: Nombre de threads concurrents\n",
    "    \"\"\"\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    import time\n",
    "    \n",
    "    test_data = {\n",
    "        \"age\": 0.05, \"sex\": 0.05, \"bmi\": 0.06, \"bp\": 0.02,\n",
    "        \"s1\": -0.04, \"s2\": -0.03, \"s3\": -0.00, \"s4\": -0.00,\n",
    "        \"s5\": 0.01, \"s6\": -0.04\n",
    "    }\n",
    "    \n",
    "    response_times = []\n",
    "    errors = 0\n",
    "    \n",
    "    def send_request():\n",
    "        # TODO: Envoyez une requ√™te et mesurez le temps\n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = requests.post(url, json=test_data, timeout=5)\n",
    "            response_time = time.time() - start\n",
    "            return response_time, response.status_code == 200\n",
    "        except Exception as e:\n",
    "            return time.time() - start, False\n",
    "    \n",
    "    # TODO: Ex√©cutez les requ√™tes en parall√®le\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        results = list(executor.map(lambda _: send_request(), range(n_requests)))\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # TODO: Analysez les r√©sultats\n",
    "    response_times = [r[0] for r in results]\n",
    "    errors = sum(1 for r in results if not r[1])\n",
    "    \n",
    "    print(f\"\\n=== Load Test Results ===\")\n",
    "    print(f\"Total requests: {n_requests}\")\n",
    "    print(f\"Concurrent workers: {n_workers}\")\n",
    "    print(f\"Total time: {total_time:.2f}s\")\n",
    "    print(f\"Requests/sec: {n_requests / total_time:.2f}\")\n",
    "    print(f\"\\nResponse times:\")\n",
    "    print(f\"  Min: {min(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  Max: {max(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  Mean: {np.mean(response_times)*1000:.2f}ms\")\n",
    "    print(f\"  P95: {np.percentile(response_times, 95)*1000:.2f}ms\")\n",
    "    print(f\"\\nErrors: {errors} ({errors/n_requests*100:.1f}%)\")\n",
    "    \n",
    "    return response_times, errors\n",
    "\n",
    "# TODO: Ex√©cutez le load test (apr√®s avoir d√©marr√© l'API)\n",
    "# response_times, errors = load_test(\"http://localhost:8000/predict\", n_requests=100, n_workers=10)\n",
    "\n",
    "print(\"\\nPour ex√©cuter le load test :\")\n",
    "print(\"1. D√©marrez l'API\")\n",
    "print(\"2. D√©commentez et ex√©cutez la ligne ci-dessus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 5 : Model Registry avec MLflow\n",
    "\n",
    "**Objectif** : G√©rer le cycle de vie des mod√®les (dev ‚Üí staging ‚Üí production).\n",
    "\n",
    "### 5.1 Enregistrement dans le Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrez un mod√®le dans le Model Registry\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "# TODO: Entra√Ænez un mod√®le\n",
    "model_registry = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_registry.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Enregistrez le mod√®le avec MLflow\n",
    "with mlflow.start_run(run_name=\"production_candidate\"):\n",
    "    # Loggez les m√©triques\n",
    "    y_pred = model_registry.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2)\n",
    "    \n",
    "    # TODO: Enregistrez dans le Model Registry\n",
    "    # mlflow.sklearn.log_model(\n",
    "    #     model_registry,\n",
    "    #     \"model\",\n",
    "    #     registered_model_name=\"diabetes_predictor\"\n",
    "    # )\n",
    "    \n",
    "    print(f\"‚úì Mod√®le enregistr√© | RMSE: {rmse:.2f} | R¬≤: {r2:.3f}\")\n",
    "\n",
    "print(\"\\nV√©rifiez dans MLflow UI : http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Transition de Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promouvez un mod√®le vers staging puis production\n",
    "# VOTRE CODE ICI\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# TODO: R√©cup√©rez la derni√®re version du mod√®le\n",
    "# model_name = \"diabetes_predictor\"\n",
    "# latest_version = client.get_latest_versions(model_name)[0]\n",
    "\n",
    "# TODO: Transition vers \"Staging\"\n",
    "# client.transition_model_version_stage(\n",
    "#     name=model_name,\n",
    "#     version=latest_version.version,\n",
    "#     stage=\"Staging\"\n",
    "# )\n",
    "# print(f\"‚úì Mod√®le v{latest_version.version} ‚Üí Staging\")\n",
    "\n",
    "# TODO: Apr√®s validation, transition vers \"Production\"\n",
    "# client.transition_model_version_stage(\n",
    "#     name=model_name,\n",
    "#     version=latest_version.version,\n",
    "#     stage=\"Production\"\n",
    "# )\n",
    "# print(f\"‚úì Mod√®le v{latest_version.version} ‚Üí Production\")\n",
    "\n",
    "print(\"\\nWorkflow Model Registry :\")\n",
    "print(\"1. Entra√Ænez et enregistrez le mod√®le\")\n",
    "print(\"2. Testez en staging\")\n",
    "print(\"3. Promouvez en production si valid√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 6 : Questions de R√©flexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** : Pourquoi est-il important de valider les inputs avec Pydantic dans une API ?\n",
    "\n",
    "**VOTRE R√âPONSE ICI**\n",
    "\n",
    "---\n",
    "\n",
    "**Question 2** : Quelles m√©triques devriez-vous monitorer pour une API de ML en production ?\n",
    "\n",
    "**VOTRE R√âPONSE ICI**\n",
    "\n",
    "---\n",
    "\n",
    "**Question 3** : Quelle est la diff√©rence entre staging et production dans le Model Registry ?\n",
    "\n",
    "**VOTRE R√âPONSE ICI**\n",
    "\n",
    "---\n",
    "\n",
    "**Question 4** : Comment g√©reriez-vous un rollback si le nouveau mod√®le en production performe mal ?\n",
    "\n",
    "**VOTRE R√âPONSE ICI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "F√©licitations pour avoir compl√©t√© ces exercices !\n",
    "\n",
    "**Points cl√©s √† retenir** :\n",
    "- MLflow permet de tracker et comparer facilement les exp√©riences\n",
    "- FastAPI + Pydantic offrent une validation robuste et une documentation automatique\n",
    "- Le monitoring est essentiel pour d√©tecter les probl√®mes en production\n",
    "- Le Model Registry facilite la gestion du cycle de vie des mod√®les\n",
    "- Le load testing permet d'identifier les goulots d'√©tranglement\n",
    "\n",
    "**Prochaines √©tapes** :\n",
    "- Consultez les solutions dans `14_exercices_solutions.ipynb`\n",
    "- D√©ployez votre API sur un serveur cloud (AWS, GCP, Azure)\n",
    "- Explorez Docker et Kubernetes pour le d√©ploiement\n",
    "- Mettez en place du CI/CD (GitHub Actions, GitLab CI)\n",
    "- F√©licitations, vous avez termin√© le cours de Machine Learning !\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
