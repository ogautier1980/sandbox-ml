{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/XX_CHAPTER/XX_NOTEBOOK.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '05_demo_reduction_dimensionnalite.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 05 - D√©monstration R√©duction de Dimensionnalit√©\n",
    "\n",
    "Exploration de PCA, t-SNE et UMAP pour la r√©duction de dimensionnalit√© et la visualisation.\n",
    "\n",
    "## Objectifs\n",
    "- Ma√Ætriser PCA et interpr√©ter les composantes principales\n",
    "- Utiliser t-SNE pour la visualisation\n",
    "- Appliquer UMAP pour des projections 2D/3D\n",
    "- Comparer les m√©thodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits, load_wine, fetch_olivetti_faces\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 PCA sur Digits Dataset\n",
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "print(f\"Shape originale: {X_digits.shape}\")\n",
    "\n",
    "# Standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_digits)\n",
    "\n",
    "# PCA avec toutes les composantes\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "# Variance expliqu√©e\n",
    "explained_var = pca_full.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Variance par composante\n",
    "axes[0].bar(range(1, len(explained_var)+1), explained_var, alpha=0.7)\n",
    "axes[0].set_xlabel('Composante Principale')\n",
    "axes[0].set_ylabel('Variance Expliqu√©e')\n",
    "axes[0].set_title('Variance Expliqu√©e par Composante')\n",
    "axes[0].set_xlim(0, 20)\n",
    "\n",
    "# Variance cumul√©e\n",
    "axes[1].plot(range(1, len(cumulative_var)+1), cumulative_var, 'o-', linewidth=2)\n",
    "axes[1].axhline(y=0.95, color='r', linestyle='--', label='95% variance')\n",
    "axes[1].axhline(y=0.90, color='orange', linestyle='--', label='90% variance')\n",
    "axes[1].set_xlabel('Nombre de Composantes')\n",
    "axes[1].set_ylabel('Variance Cumul√©e')\n",
    "axes[1].set_title('Variance Cumul√©e Expliqu√©e')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Nombre de composantes pour 95% de variance\n",
    "n_components_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
    "print(f\"\\nComposantes pour 95% de variance: {n_components_95}/{X_digits.shape[1]}\")\n",
    "print(f\"R√©duction de dimensionnalit√©: {100*(1-n_components_95/X_digits.shape[1]):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Visualisation 2D avec PCA\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1], c=y_digits, \n",
    "                      cmap='tab10', s=20, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Digits Dataset - PCA 2D')\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Variance expliqu√©e (PC1+PC2): {pca_2d.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Visualisation des composantes principales\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    axes[i].imshow(pca_full.components_[i].reshape(8, 8), cmap='RdBu', \n",
    "                   vmin=-0.2, vmax=0.2)\n",
    "    axes[i].set_title(f'PC{i+1} ({explained_var[i]:.1%})')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Premi√®res Composantes Principales (Eigenfaces)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : t-SNE (t-Distributed Stochastic Neighbor Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 t-SNE sur Digits (√©chantillon pour vitesse)\n",
    "n_samples = 1000\n",
    "indices = np.random.RandomState(42).choice(len(X_digits), n_samples, replace=False)\n",
    "X_sample = X_scaled[indices]\n",
    "y_sample = y_digits[indices]\n",
    "\n",
    "# PCA preprocessing (recommand√© pour t-SNE)\n",
    "pca_50 = PCA(n_components=50)\n",
    "X_pca_50 = pca_50.fit_transform(X_sample)\n",
    "\n",
    "# t-SNE\n",
    "print(\"Calcul t-SNE...\")\n",
    "start = time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_jobs=-1)\n",
    "X_tsne = tsne.fit_transform(X_pca_50)\n",
    "print(f\"Temps: {time()-start:.2f}s\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_sample, \n",
    "                      cmap='tab10', s=30, alpha=0.7, edgecolors='k', linewidths=0.5)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('Digits Dataset - t-SNE 2D')\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Impact du perplexity\n",
    "perplexity_values = [5, 30, 50, 100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, perp in enumerate(perplexity_values):\n",
    "    print(f\"t-SNE avec perplexity={perp}...\")\n",
    "    tsne_p = TSNE(n_components=2, perplexity=perp, random_state=42, n_jobs=-1)\n",
    "    X_tsne_p = tsne_p.fit_transform(X_pca_50)\n",
    "    \n",
    "    axes[idx].scatter(X_tsne_p[:, 0], X_tsne_p[:, 1], c=y_sample,\n",
    "                      cmap='tab10', s=20, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "    axes[idx].set_title(f'perplexity={perp}')\n",
    "    axes[idx].set_xlabel('t-SNE 1')\n",
    "    axes[idx].set_ylabel('t-SNE 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerplexity:\")\n",
    "print(\"- Petit (5-10): Focus sur structure locale\")\n",
    "print(\"- Moyen (30-50): Recommand√©, bon compromis\")\n",
    "print(\"- Grand (>50): Focus sur structure globale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : UMAP (Uniform Manifold Approximation and Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 UMAP sur Digits\n",
    "print(\"Calcul UMAP...\")\n",
    "start = time()\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_model.fit_transform(X_pca_50)\n",
    "print(f\"Temps: {time()-start:.2f}s\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=y_sample,\n",
    "                      cmap='tab10', s=30, alpha=0.7, edgecolors='k', linewidths=0.5)\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.title('Digits Dataset - UMAP 2D')\n",
    "plt.colorbar(scatter, label='Digit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Comparaison PCA vs t-SNE vs UMAP\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "methods = [\n",
    "    ('PCA', X_pca_2d[indices]),\n",
    "    ('t-SNE', X_tsne),\n",
    "    ('UMAP', X_umap)\n",
    "]\n",
    "\n",
    "for idx, (name, X_proj) in enumerate(methods):\n",
    "    scatter = axes[idx].scatter(X_proj[:, 0], X_proj[:, 1], c=y_sample,\n",
    "                                cmap='tab10', s=20, alpha=0.6, \n",
    "                                edgecolors='k', linewidths=0.5)\n",
    "    axes[idx].set_title(f'{name}', fontsize=14)\n",
    "    axes[idx].set_xlabel('Dimension 1')\n",
    "    axes[idx].set_ylabel('Dimension 2')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(scatter, ax=axes, label='Digit')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 UMAP 3D\n",
    "umap_3d = umap.UMAP(n_components=3, random_state=42)\n",
    "X_umap_3d = umap_3d.fit_transform(X_pca_50)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(X_umap_3d[:, 0], X_umap_3d[:, 1], X_umap_3d[:, 2],\n",
    "                     c=y_sample, cmap='tab10', s=30, alpha=0.6,\n",
    "                     edgecolors='k', linewidths=0.5)\n",
    "\n",
    "ax.set_xlabel('UMAP 1')\n",
    "ax.set_ylabel('UMAP 2')\n",
    "ax.set_zlabel('UMAP 3')\n",
    "ax.set_title('Digits Dataset - UMAP 3D')\n",
    "plt.colorbar(scatter, label='Digit', shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 : Application sur Images (Olivetti Faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Chargement Olivetti Faces\n",
    "faces = fetch_olivetti_faces()\n",
    "X_faces = faces.data\n",
    "y_faces = faces.target\n",
    "\n",
    "print(f\"Shape: {X_faces.shape}\")\n",
    "print(f\"Nombre de visages: {len(np.unique(y_faces))}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(2, 10, figsize=(18, 4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].imshow(faces.images[i], cmap='gray')\n",
    "    axes[i].set_title(f'P{y_faces[i]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Olivetti Faces Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 PCA sur visages (Eigenfaces)\n",
    "n_components = 150\n",
    "pca_faces = PCA(n_components=n_components, whiten=True, random_state=42)\n",
    "X_pca_faces = pca_faces.fit_transform(X_faces)\n",
    "\n",
    "print(f\"Variance expliqu√©e: {pca_faces.explained_variance_ratio_.sum():.1%}\")\n",
    "\n",
    "# Eigenfaces\n",
    "fig, axes = plt.subplots(3, 8, figsize=(18, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(24):\n",
    "    axes[i].imshow(pca_faces.components_[i].reshape(64, 64), cmap='gray')\n",
    "    axes[i].set_title(f'Eigenface {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Eigenfaces (Composantes Principales)', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Reconstruction avec PCA\n",
    "n_components_list = [10, 50, 150]\n",
    "sample_idx = 0\n",
    "original = faces.images[sample_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(original, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Reconstructions\n",
    "for idx, n_comp in enumerate(n_components_list):\n",
    "    pca_rec = PCA(n_components=n_comp)\n",
    "    X_proj = pca_rec.fit_transform(X_faces)\n",
    "    X_reconstructed = pca_rec.inverse_transform(X_proj)\n",
    "    \n",
    "    axes[idx+1].imshow(X_reconstructed[sample_idx].reshape(64, 64), cmap='gray')\n",
    "    axes[idx+1].set_title(f'{n_comp} composantes\\n({pca_rec.explained_variance_ratio_.sum():.1%} variance)')\n",
    "    axes[idx+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©capitulatif\n",
    "\n",
    "### PCA\n",
    "\n",
    "**Avantages:**\n",
    "- Rapide et d√©terministe\n",
    "- Pr√©serve la variance globale\n",
    "- Interpr√©table (composantes principales)\n",
    "- Permet la reconstruction\n",
    "\n",
    "**Inconv√©nients:**\n",
    "- Lin√©aire uniquement\n",
    "- Sensible √† l'√©chelle (standardisation requise)\n",
    "- Peut manquer des structures non lin√©aires\n",
    "\n",
    "**Usage:**\n",
    "- R√©duction de dimensionnalit√©\n",
    "- Compression de donn√©es\n",
    "- D√©bruitage\n",
    "- Feature extraction\n",
    "\n",
    "### t-SNE\n",
    "\n",
    "**Avantages:**\n",
    "- Excellente visualisation 2D/3D\n",
    "- Pr√©serve structure locale\n",
    "- D√©tecte clusters complexes\n",
    "\n",
    "**Inconv√©nients:**\n",
    "- Lent sur grands datasets\n",
    "- Non d√©terministe\n",
    "- Pas de transformation pour nouvelles donn√©es\n",
    "- Distances globales non pr√©serv√©es\n",
    "\n",
    "**Hyperparam√®tres:**\n",
    "- `perplexity`: 5-50, balance local/global\n",
    "- `n_iter`: 1000+ pour convergence\n",
    "\n",
    "### UMAP\n",
    "\n",
    "**Avantages:**\n",
    "- Plus rapide que t-SNE\n",
    "- Pr√©serve structure locale ET globale\n",
    "- Transformation pour nouvelles donn√©es\n",
    "- Scalable\n",
    "\n",
    "**Inconv√©nients:**\n",
    "- Moins de recherche th√©orique\n",
    "- Sensible aux hyperparam√®tres\n",
    "\n",
    "**Hyperparam√®tres:**\n",
    "- `n_neighbors`: 5-50, structure locale\n",
    "- `min_dist`: 0.0-1.0, compacit√©\n",
    "\n",
    "### Comparaison\n",
    "\n",
    "| Crit√®re | PCA | t-SNE | UMAP |\n",
    "|---------|-----|-------|------|\n",
    "| Vitesse | Tr√®s rapide | Lent | Rapide |\n",
    "| Scalabilit√© | Excellente | Mauvaise | Bonne |\n",
    "| Structure locale | Non | Oui | Oui |\n",
    "| Structure globale | Oui | Non | Oui |\n",
    "| Nouveaux points | Oui | Non | Oui |\n",
    "| D√©terministe | Oui | Non | Non |\n",
    "\n",
    "### Workflow recommand√©\n",
    "\n",
    "1. **Exploration initiale:** PCA pour variance et vitesse\n",
    "2. **Visualisation:** t-SNE ou UMAP pour clusters\n",
    "3. **Production:** PCA ou UMAP pour transformation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}