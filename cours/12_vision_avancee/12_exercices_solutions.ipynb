{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Google Colab Setup",
    "",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/12_vision_avancee/12_exercices_solutions.ipynb)",
    "",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "if IN_COLAB:",
    "    print('üì¶ Installation des packages...')",
    "    !pip install -q torch torchvision",
    "    !pip install -q ultralytics  # YOLOv8",
    "    !pip install -q segmentation-models-pytorch",
    "    !pip install -q albumentations",
    "    !pip install -q numpy pandas matplotlib seaborn Pillow opencv-python",
    "    print('‚úÖ Installation termin√©e !')",
    "else:",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 12 - Solutions : Vision Avanc√©e",
    "",
    "Ce notebook contient des exercices pratiques pour consolider les concepts du Chapitre 12.",
    "",
    "**Instructions** :",
    "- Compl√©tez les cellules marqu√©es `# SOLUTION:",
    "# Remplacez cette ligne par votre code de solution`",
    "- Les solutions sont disponibles dans `12_exercices_solutions.ipynb`",
    "- N'h√©sitez pas √† consulter la documentation (Ultralytics, PyTorch, segmentation-models-pytorch)",
    "",
    "**Avertissement** : Ces exercices n√©cessitent des ressources GPU pour un entra√Ænement efficace. Sur CPU, limitez les epochs et la taille des mod√®les.",
    "",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports n√©cessaires",
    "import numpy as np",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "from PIL import Image",
    "import cv2",
    "",
    "import torch",
    "import torch.nn as nn",
    "import torch.nn.functional as F",
    "import torchvision",
    "from torchvision import transforms",
    "from torch.utils.data import Dataset, DataLoader",
    "",
    "from ultralytics import YOLO",
    "import segmentation_models_pytorch as smp",
    "import albumentations as A",
    "from albumentations.pytorch import ToTensorV2",
    "",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "# Configuration",
    "sns.set_style('whitegrid')",
    "plt.rcParams['figure.figsize'] = (14, 8)",
    "np.random.seed(42)",
    "torch.manual_seed(42)",
    "",
    "# D√©tection GPU",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
    "print(f\"Device : {device}\")",
    "",
    "print(\"‚úì Biblioth√®ques import√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 1 : IoU et NMS (Fondamentaux)",
    "",
    "**Objectif** : Impl√©menter les m√©triques de base pour l'object detection.",
    "",
    "### 1.1 Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez IoU",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def compute_iou(box1, box2):",
    "    \"\"\"",
    "    Calcule l'IoU entre deux bounding boxes.",
    "    Args:",
    "        box1, box2: [x1, y1, x2, y2] format (coin haut-gauche, coin bas-droit)",
    "    Returns:",
    "        IoU (float entre 0 et 1)",
    "    \"\"\"",
    "    # SOLUTION: Calculez l'aire d'intersection",
    "    x1 = max(box1[0], box2[0])",
    "    y1 = max(box1[1], box2[1])",
    "    x2 = min(box1[2], box2[2])",
    "    y2 = min(box1[3], box2[3])",
    "    ",
    "    intersection = None  # max(0, x2 - x1) * max(0, y2 - y1)",
    "    ",
    "    # SOLUTION: Calculez les aires de box1 et box2",
    "    area1 = None",
    "    area2 = None",
    "    ",
    "    # SOLUTION: Calculez l'union",
    "    union = None",
    "    ",
    "    # SOLUTION: Calculez l'IoU",
    "    iou = None",
    "    ",
    "    return iou",
    "",
    "# Tests",
    "box_a = [10, 10, 50, 50]  # Carr√© 40x40",
    "box_b = [30, 30, 70, 70]  # Carr√© 40x40, chevauchement partiel",
    "box_c = [10, 10, 50, 50]  # Identique √† box_a",
    "box_d = [100, 100, 140, 140]  # Pas de chevauchement",
    "",
    "print(f\"IoU(box_a, box_b) = {compute_iou(box_a, box_b):.4f}\")",
    "print(f\"IoU(box_a, box_c) = {compute_iou(box_a, box_c):.4f} (attendu : 1.0)\")",
    "print(f\"IoU(box_a, box_d) = {compute_iou(box_a, box_d):.4f} (attendu : 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Non-Maximum Suppression (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez NMS",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):",
    "    \"\"\"",
    "    Applique NMS pour √©liminer les d√©tections redondantes.",
    "    Args:",
    "        boxes: Liste de [x1, y1, x2, y2]",
    "        scores: Liste de scores de confiance",
    "        iou_threshold: Seuil d'IoU pour supprimer les boxes",
    "    Returns:",
    "        Indices des boxes √† garder",
    "    \"\"\"",
    "    # SOLUTION: Triez les boxes par score d√©croissant",
    "    # SOLUTION: Pour chaque box dans l'ordre :",
    "    #   - Gardez-la si elle n'a pas √©t√© supprim√©e",
    "    #   - Supprimez toutes les boxes avec IoU > iou_threshold",
    "    # SOLUTION: Retournez les indices des boxes conserv√©es",
    "    pass",
    "",
    "# Test",
    "boxes_test = [",
    "    [10, 10, 50, 50],",
    "    [15, 15, 55, 55],  # Tr√®s similaire √† la premi√®re",
    "    [100, 100, 140, 140],  # Diff√©rente",
    "    [12, 12, 52, 52]  # Tr√®s similaire √† la premi√®re",
    "]",
    "scores_test = [0.9, 0.8, 0.95, 0.7]",
    "",
    "kept_indices = non_max_suppression(boxes_test, scores_test, iou_threshold=0.5)",
    "print(f\"Boxes conserv√©es : {kept_indices}\")",
    "print(f\"Attendu : conserver box 0 (score 0.9) et box 2 (score 0.95, diff√©rente zone)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez l'effet du NMS",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def draw_boxes(image, boxes, scores, labels, color=(255, 0, 0), thickness=2):",
    "    \"\"\"Dessine les bounding boxes sur une image.\"\"\"",
    "    img_copy = image.copy()",
    "    for i, (box, score, label) in enumerate(zip(boxes, scores, labels)):",
    "        x1, y1, x2, y2 = box",
    "        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, thickness)",
    "        text = f\"{label} {score:.2f}\"",
    "        cv2.putText(img_copy, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)",
    "    return img_copy",
    "",
    "# SOLUTION: Cr√©ez une image blanche 200x200",
    "# SOLUTION: Dessinez les boxes avant et apr√®s NMS c√¥te √† c√¥te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 2 : YOLOv8 pour Object Detection",
    "",
    "**Objectif** : Utiliser YOLOv8 pour d√©tecter des objets dans des images.",
    "",
    "### 2.1 Chargement du Mod√®le Pr√©-entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez YOLOv8 nano (le plus l√©ger)",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "model_yolo = None  # YOLO('yolov8n.pt')  # n = nano, s = small, m = medium, l = large",
    "",
    "print(\"‚úì Mod√®le YOLOv8 charg√©\")",
    "print(f\"Classes disponibles : {len(model_yolo.names)}\")",
    "print(f\"Exemples : {list(model_yolo.names.values())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 D√©tection sur une Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©chargez ou utilisez une image test",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Option 1 : T√©l√©chargez depuis URL",
    "# !wget https://ultralytics.com/images/bus.jpg -O test_image.jpg",
    "",
    "# Option 2 : Utilisez une image locale",
    "# img_path = 'test_image.jpg'",
    "",
    "# SOLUTION: Effectuez la d√©tection",
    "# results = model_yolo(img_path)",
    "",
    "# SOLUTION: Affichez les r√©sultats",
    "# results[0].show()  # Affiche l'image avec les d√©tections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Analyse des D√©tections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrayez les informations des d√©tections",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# SOLUTION: Parcourez les d√©tections et extrayez :",
    "# - Bounding boxes",
    "# - Scores de confiance",
    "# - Classes d√©tect√©es",
    "",
    "# for result in results:",
    "#     boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]",
    "#     scores = result.boxes.conf.cpu().numpy()",
    "#     classes = result.boxes.cls.cpu().numpy()",
    "#     ",
    "#     for box, score, cls in zip(boxes, scores, classes):",
    "#         class_name = model_yolo.names[int(cls)]",
    "#         print(f\"{class_name} : {score:.3f} | Box : {box}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Fine-tuning YOLOv8 (Optionnel - Bonus)",
    "",
    "Pour cet exercice, vous devez pr√©parer un dataset au format YOLO (images + annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning YOLOv8 sur un dataset personnalis√©",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# Structure attendue du dataset :",
    "# dataset/",
    "#   train/",
    "#     images/",
    "#     labels/  # Fichiers .txt avec format : class x_center y_center width height (normalis√©s 0-1)",
    "#   val/",
    "#     images/",
    "#     labels/",
    "#   data.yaml  # Fichier de configuration",
    "",
    "# Contenu de data.yaml :",
    "# train: /path/to/dataset/train/images",
    "# val: /path/to/dataset/val/images",
    "# nc: 2  # Nombre de classes",
    "# names: ['class1', 'class2']",
    "",
    "# SOLUTION: Entra√Ænez le mod√®le",
    "# model_yolo.train(data='data.yaml', epochs=10, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 3 : U-Net pour Segmentation S√©mantique",
    "",
    "**Objectif** : Impl√©menter et entra√Æner un U-Net sur un dataset synth√©tique.",
    "",
    "### 3.1 G√©n√©ration de Donn√©es Synth√©tiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rez un dataset synth√©tique (formes g√©om√©triques)",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def generate_synthetic_data(n_samples=1000, img_size=128):",
    "    \"\"\"",
    "    G√©n√®re des images avec des formes g√©om√©triques et leurs masques.",
    "    Returns:",
    "        images: (n_samples, img_size, img_size, 3)",
    "        masks: (n_samples, img_size, img_size) avec classes 0=background, 1=circle, 2=rectangle",
    "    \"\"\"",
    "    images = []",
    "    masks = []",
    "    ",
    "    for _ in range(n_samples):",
    "        # SOLUTION: Cr√©ez une image blanche",
    "        img = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255",
    "        mask = np.zeros((img_size, img_size), dtype=np.uint8)",
    "        ",
    "        # SOLUTION: Ajoutez al√©atoirement des cercles et rectangles",
    "        # Utilisez cv2.circle et cv2.rectangle",
    "        # Remplissez le masque avec les labels correspondants",
    "        ",
    "        # Exemple : Cercle",
    "        if np.random.rand() > 0.5:",
    "            center = (np.random.randint(20, img_size-20), np.random.randint(20, img_size-20))",
    "            radius = np.random.randint(10, 30)",
    "            color = tuple(np.random.randint(0, 255, 3).tolist())",
    "            cv2.circle(img, center, radius, color, -1)",
    "            cv2.circle(mask, center, radius, 1, -1)  # Label 1 pour cercle",
    "        ",
    "        # SOLUTION: Ajoutez un rectangle de la m√™me mani√®re (label 2)",
    "        ",
    "        images.append(img)",
    "        masks.append(mask)",
    "    ",
    "    return np.array(images), np.array(masks)",
    "",
    "# G√©n√©rez le dataset",
    "X_train, y_train = generate_synthetic_data(n_samples=800, img_size=128)",
    "X_val, y_val = generate_synthetic_data(n_samples=200, img_size=128)",
    "",
    "print(f\"Train : {X_train.shape}, {y_train.shape}\")",
    "print(f\"Val : {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualisation du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez quelques exemples",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))",
    "",
    "for i in range(3):",
    "    idx = np.random.randint(0, len(X_train))",
    "    ",
    "    # Image",
    "    axes[i, 0].imshow(X_train[idx])",
    "    axes[i, 0].set_title('Image')",
    "    axes[i, 0].axis('off')",
    "    ",
    "    # Mask",
    "    axes[i, 1].imshow(y_train[idx], cmap='tab20')",
    "    axes[i, 1].set_title('Mask')",
    "    axes[i, 1].axis('off')",
    "    ",
    "    # SOLUTION: Affichez les canaux s√©par√©s pour chaque classe",
    "",
    "plt.tight_layout()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dataset et DataLoader PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ez un Dataset PyTorch",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "class SegmentationDataset(Dataset):",
    "    def __init__(self, images, masks, transform=None):",
    "        self.images = images",
    "        self.masks = masks",
    "        self.transform = transform",
    "    ",
    "    def __len__(self):",
    "        return len(self.images)",
    "    ",
    "    def __getitem__(self, idx):",
    "        image = self.images[idx]",
    "        mask = self.masks[idx]",
    "        ",
    "        # SOLUTION: Appliquez les transformations",
    "        if self.transform:",
    "            # Utilisez albumentations pour transformer image ET mask ensemble",
    "            pass",
    "        ",
    "        # SOLUTION: Convertissez en tenseurs",
    "        # Image : (C, H, W) normalis√©e [0, 1]",
    "        # Mask : (H, W) avec labels entiers",
    "        ",
    "        return image, mask",
    "",
    "# Transformations",
    "train_transform = A.Compose([",
    "    A.HorizontalFlip(p=0.5),",
    "    A.RandomBrightnessContrast(p=0.3),",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),",
    "    ToTensorV2()",
    "])",
    "",
    "val_transform = A.Compose([",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),",
    "    ToTensorV2()",
    "])",
    "",
    "# Cr√©ez les datasets et dataloaders",
    "train_dataset = SegmentationDataset(X_train, y_train, transform=train_transform)",
    "val_dataset = SegmentationDataset(X_val, y_val, transform=val_transform)",
    "",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)",
    "",
    "print(f\"‚úì Dataloaders cr√©√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Mod√®le U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisez segmentation-models-pytorch pour cr√©er un U-Net",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# SOLUTION: Cr√©ez le mod√®le",
    "model = smp.Unet(",
    "    encoder_name='resnet18',        # Encoder : resnet18, resnet34, efficientnet-b0, etc.",
    "    encoder_weights='imagenet',     # Poids pr√©-entra√Æn√©s sur ImageNet",
    "    in_channels=3,                  # RGB",
    "    classes=3                       # Nombre de classes (0=bg, 1=circle, 2=rectangle)",
    ")",
    "",
    "model = model.to(device)",
    "",
    "print(f\"‚úì Mod√®le U-Net cr√©√©\")",
    "print(f\"Nombre de param√®tres : {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Loss Function et Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finissez la loss function",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "# SOLUTION: Utilisez DiceLoss ou une combinaison Dice + CrossEntropy",
    "loss_fn = smp.losses.DiceLoss(mode='multiclass')",
    "",
    "# SOLUTION: Cr√©ez l'optimizer",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)",
    "",
    "# SOLUTION: Cr√©ez le scheduler (optionnel)",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)",
    "",
    "print(\"‚úì Loss et optimizer cr√©√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d'entra√Ænement",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def train_epoch(model, loader, loss_fn, optimizer, device):",
    "    model.train()",
    "    total_loss = 0",
    "    ",
    "    for images, masks in loader:",
    "        # SOLUTION: Entra√Ænement standard",
    "        # 1. Move to device",
    "        # 2. Forward pass",
    "        # 3. Compute loss",
    "        # 4. Backward",
    "        # 5. Optimizer step",
    "        pass",
    "    ",
    "    return total_loss / len(loader)",
    "",
    "def val_epoch(model, loader, loss_fn, device):",
    "    model.eval()",
    "    total_loss = 0",
    "    ",
    "    with torch.no_grad():",
    "        for images, masks in loader:",
    "            # SOLUTION: Validation",
    "            pass",
    "    ",
    "    return total_loss / len(loader)",
    "",
    "# SOLUTION: Boucle d'entra√Ænement principale",
    "n_epochs = 10",
    "train_losses = []",
    "val_losses = []",
    "",
    "for epoch in range(n_epochs):",
    "    # SOLUTION: Entra√Ænez et validez",
    "    pass",
    "",
    "print(\"\\n‚úì Entra√Ænement termin√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Visualisation des Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisez les pr√©dictions sur le validation set",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "model.eval()",
    "",
    "fig, axes = plt.subplots(4, 3, figsize=(12, 16))",
    "",
    "with torch.no_grad():",
    "    for i in range(4):",
    "        idx = np.random.randint(0, len(val_dataset))",
    "        image, mask = val_dataset[idx]",
    "        ",
    "        # SOLUTION: Pr√©diction",
    "        # pred = model(image.unsqueeze(0).to(device))",
    "        # pred_mask = torch.argmax(pred, dim=1).cpu().numpy()[0]",
    "        ",
    "        # SOLUTION: Affichez image, mask GT, mask pr√©dite",
    "",
    "plt.tight_layout()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 4 : M√©triques de Segmentation",
    "",
    "**Objectif** : Impl√©menter les m√©triques d'√©valuation pour la segmentation.",
    "",
    "### 4.1 Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impl√©mentez le Dice Coefficient (F1-score pour segmentation)",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def dice_coefficient(pred, target, smooth=1e-6):",
    "    \"\"\"",
    "    Calcule le Dice Coefficient.",
    "    Args:",
    "        pred: Pr√©dictions binaires (H, W)",
    "        target: Ground truth binaire (H, W)",
    "        smooth: Constante pour √©viter division par z√©ro",
    "    Returns:",
    "        Dice score (float entre 0 et 1)",
    "    \"\"\"",
    "    # SOLUTION: Dice = 2 * |A ‚à© B| / (|A| + |B|)",
    "    pass",
    "",
    "# Test",
    "pred_test = np.array([[1, 1, 0], [1, 0, 0], [0, 0, 0]])",
    "target_test = np.array([[1, 1, 0], [1, 1, 0], [0, 0, 0]])",
    "",
    "dice = dice_coefficient(pred_test, target_test)",
    "print(f\"Dice Coefficient : {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 IoU par Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez l'IoU pour chaque classe",
    "# SOLUTION COMPL√àTE:",
    "# Impl√©mentez le code selon les consignes",
    "",
    "def compute_iou_multiclass(pred, target, n_classes):",
    "    \"\"\"",
    "    Calcule l'IoU pour chaque classe.",
    "    Args:",
    "        pred: Pr√©dictions (H, W) avec labels 0, 1, 2, ...",
    "        target: Ground truth (H, W)",
    "        n_classes: Nombre de classes",
    "    Returns:",
    "        Liste d'IoU pour chaque classe",
    "    \"\"\"",
    "    ious = []",
    "    ",
    "    for cls in range(n_classes):",
    "        # SOLUTION: Cr√©ez des masques binaires pour la classe cls",
    "        # SOLUTION: Calculez IoU pour cette classe",
    "        pass",
    "    ",
    "    return ious",
    "",
    "# SOLUTION: Testez sur vos pr√©dictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Exercice 5 : Questions de R√©flexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** : Quelle est la diff√©rence entre segmentation s√©mantique et segmentation d'instance ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 2** : Pourquoi utilise-t-on Dice Loss plut√¥t que CrossEntropy pour la segmentation ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 3** : √Ä quoi servent les skip connections dans U-Net ?",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*",
    "",
    "---",
    "",
    "**Question 4** : Comparez YOLOv8 et Faster R-CNN en termes de vitesse et pr√©cision.",
    "",
    "**R√âPONSE:**\\n\\n*Compl√©tez avec votre r√©ponse bas√©e sur le contexte de l'exercice*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "",
    "## Conclusion",
    "",
    "F√©licitations pour avoir compl√©t√© ces exercices !",
    "",
    "**Points cl√©s √† retenir** :",
    "- IoU et NMS sont fondamentaux pour l'object detection",
    "- YOLOv8 offre un excellent compromis vitesse/pr√©cision pour la d√©tection temps r√©el",
    "- U-Net est l'architecture de r√©f√©rence pour la segmentation s√©mantique",
    "- Les skip connections pr√©servent les d√©tails spatiaux",
    "- Dice Loss et IoU sont les m√©triques standards pour la segmentation",
    "",
    "**Prochaines √©tapes** :",
    "- Consultez les solutions dans `12_exercices_solutions.ipynb`",
    "- Testez YOLOv8 sur vos propres images",
    "- Entra√Ænez U-Net sur des datasets r√©els (m√©dicaux, satellites)",
    "- Explorez Mask R-CNN pour la segmentation d'instance",
    "- Passez au Chapitre 13 (Syst√®mes de Recommandation)",
    "",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}