{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/12_vision_avancee/12_demo_segmentation.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '12_demo_segmentation.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 13 - Segmentation S√©mantique avec U-Net\n",
    "\n",
    "Ce notebook explore la **segmentation s√©mantique** avec U-Net et autres architectures.\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre la segmentation s√©mantique vs d√©tection\n",
    "- Impl√©menter U-Net from scratch en PyTorch\n",
    "- Entra√Æner sur un dataset de segmentation\n",
    "- √âvaluer avec IoU, Dice coefficient\n",
    "- Explorer DeepLab et Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Segmentation models pytorch (optionnel)\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "    SMP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è segmentation_models_pytorch not installed\")\n",
    "    print(\"Install with: pip install segmentation-models-pytorch\")\n",
    "    SMP_AVAILABLE = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. U-Net Architecture\n",
    "\n",
    "Impl√©mentation compl√®te de U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2D -> BatchNorm -> ReLU) x 2\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling avec MaxPooling puis DoubleConv\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling puis DoubleConv\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1: features de l'encoder (skip connection)\n",
    "        x2: features du decoder\n",
    "        \"\"\"\n",
    "        x2 = self.up(x2)\n",
    "        \n",
    "        # Padding pour correspondre aux dimensions (si n√©cessaire)\n",
    "        diffY = x1.size()[2] - x2.size()[2]\n",
    "        diffX = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2,\n",
    "                       diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concat√©ner skip connection\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net Architecture\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder (Contracting Path)\n",
    "        self.inc = DoubleConv(in_channels, features[0])\n",
    "        self.down1 = Down(features[0], features[1])\n",
    "        self.down2 = Down(features[1], features[2])\n",
    "        self.down3 = Down(features[2], features[3])\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.down4 = Down(features[3], features[3] * 2)\n",
    "        \n",
    "        # Decoder (Expansive Path)\n",
    "        self.up1 = Up(features[3] * 2, features[3])\n",
    "        self.up2 = Up(features[3], features[2])\n",
    "        self.up3 = Up(features[2], features[1])\n",
    "        self.up4 = Up(features[1], features[0])\n",
    "        \n",
    "        # Output\n",
    "        self.outc = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder avec skip connections\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Decoder avec skip connections\n",
    "        x = self.up1(x4, x5)\n",
    "        x = self.up2(x3, x)\n",
    "        x = self.up3(x2, x)\n",
    "        x = self.up4(x1, x)\n",
    "        \n",
    "        # Output\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Tester l'architecture\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "y = model(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "print(f\"\\nNombre de param√®tres: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Synth√©tique pour Tests\n",
    "\n",
    "Cr√©er un dataset simple pour tester U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticSegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset synth√©tique avec formes g√©om√©triques.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=1000, img_size=256, transform=None):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # G√©n√©rer image avec formes al√©atoires\n",
    "        img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "        mask = np.zeros((self.img_size, self.img_size), dtype=np.uint8)\n",
    "        \n",
    "        # Nombre de formes (1-3)\n",
    "        n_shapes = np.random.randint(1, 4)\n",
    "        \n",
    "        for _ in range(n_shapes):\n",
    "            shape_type = np.random.choice(['circle', 'rectangle', 'triangle'])\n",
    "            color = tuple(np.random.randint(50, 255, 3).tolist())\n",
    "            \n",
    "            if shape_type == 'circle':\n",
    "                center = (np.random.randint(50, self.img_size-50), \n",
    "                         np.random.randint(50, self.img_size-50))\n",
    "                radius = np.random.randint(20, 60)\n",
    "                cv2.circle(img, center, radius, color, -1)\n",
    "                cv2.circle(mask, center, radius, 255, -1)\n",
    "            \n",
    "            elif shape_type == 'rectangle':\n",
    "                x1, y1 = np.random.randint(20, self.img_size-80, 2)\n",
    "                x2, y2 = x1 + np.random.randint(40, 100), y1 + np.random.randint(40, 100)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, -1)\n",
    "                cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)\n",
    "            \n",
    "            elif shape_type == 'triangle':\n",
    "                pts = np.random.randint(20, self.img_size-20, (3, 2))\n",
    "                cv2.fillPoly(img, [pts], color)\n",
    "                cv2.fillPoly(mask, [pts], 255)\n",
    "        \n",
    "        # Convertir en PIL\n",
    "        img = Image.fromarray(img)\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = transforms.ToTensor()(mask)\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "# Cr√©er dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = SyntheticSegmentationDataset(num_samples=800, transform=transform)\n",
    "val_dataset = SyntheticSegmentationDataset(num_samples=200, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Val dataset: {len(val_dataset)} samples\")\n",
    "\n",
    "# Visualiser exemples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    img, mask = train_dataset[i]\n",
    "    \n",
    "    # D√©normaliser pour affichage\n",
    "    img_display = img.permute(1, 2, 0).numpy()\n",
    "    img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img_display = np.clip(img_display, 0, 1)\n",
    "    \n",
    "    axes[0, i].imshow(img_display)\n",
    "    axes[0, i].set_title(f'Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(mask.squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Mask {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. M√©triques de Segmentation\n",
    "\n",
    "Impl√©menter IoU et Dice coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Calcule le Dice coefficient.\n",
    "    \n",
    "    Dice = 2 * |A ‚à© B| / (|A| + |B|)\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "\n",
    "def iou_score(pred, target, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Calcule l'IoU (Jaccard Index).\n",
    "    \n",
    "    IoU = |A ‚à© B| / |A ‚à™ B|\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "\n",
    "def pixel_accuracy(pred, target):\n",
    "    \"\"\"\n",
    "    Calcule l'accuracy pixel-level.\n",
    "    \"\"\"\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    correct = (pred == target).sum()\n",
    "    total = target.numel()\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# Test sur pr√©dictions synth√©tiques\n",
    "pred = torch.rand(1, 1, 256, 256) > 0.5\n",
    "target = torch.rand(1, 1, 256, 256) > 0.5\n",
    "\n",
    "dice = dice_coefficient(pred.float(), target.float())\n",
    "iou = iou_score(pred.float(), target.float())\n",
    "acc = pixel_accuracy(pred, target)\n",
    "\n",
    "print(f\"Dice coefficient: {dice:.4f}\")\n",
    "print(f\"IoU score: {iou:.4f}\")\n",
    "print(f\"Pixel accuracy: {acc:.4f}\")\n",
    "\n",
    "# Relation Dice-IoU\n",
    "print(f\"\\nRelation: Dice = 2*IoU / (1 + IoU)\")\n",
    "print(f\"V√©rification: {2*iou / (1 + iou):.4f} ‚âà {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Functions pour Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss (1 - Dice Coefficient)\"\"\"\n",
    "    \n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        \n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    \"\"\"Combinaison de Dice Loss et Binary Cross Entropy\"\"\"\n",
    "    \n",
    "    def __init__(self, dice_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLoss()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice_weight = dice_weight\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        dice_loss = self.dice(pred, target)\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        \n",
    "        return self.dice_weight * dice_loss + (1 - self.dice_weight) * bce_loss\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss pour g√©rer d√©s√©quilibre de classes\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "# Comparer les losses\n",
    "pred = torch.randn(4, 1, 256, 256)\n",
    "target = torch.randint(0, 2, (4, 1, 256, 256)).float()\n",
    "\n",
    "dice_loss = DiceLoss()(pred, target)\n",
    "dice_bce_loss = DiceBCELoss()(pred, target)\n",
    "focal_loss = FocalLoss()(pred, target)\n",
    "bce_loss = nn.BCEWithLogitsLoss()(pred, target)\n",
    "\n",
    "print(f\"Dice Loss: {dice_loss:.4f}\")\n",
    "print(f\"Dice + BCE Loss: {dice_bce_loss:.4f}\")\n",
    "print(f\"Focal Loss: {focal_loss:.4f}\")\n",
    "print(f\"BCE Loss: {bce_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entra√Ænement U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Entra√Æne le mod√®le sur une epoch.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_dice = 0\n",
    "    epoch_iou = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # M√©triques\n",
    "        with torch.no_grad():\n",
    "            pred_masks = torch.sigmoid(outputs) > 0.5\n",
    "            dice = dice_coefficient(pred_masks.float(), masks)\n",
    "            iou = iou_score(pred_masks.float(), masks)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_dice += dice.item()\n",
    "        epoch_iou += iou.item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', \n",
    "                         'dice': f'{dice.item():.4f}'})\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_dice / len(loader), epoch_iou / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Valide le mod√®le.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_dice = 0\n",
    "    epoch_iou = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(loader, desc='Validation'):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            pred_masks = torch.sigmoid(outputs) > 0.5\n",
    "            dice = dice_coefficient(pred_masks.float(), masks)\n",
    "            iou = iou_score(pred_masks.float(), masks)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_dice += dice.item()\n",
    "            epoch_iou += iou.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_dice / len(loader), epoch_iou / len(loader)\n",
    "\n",
    "\n",
    "# Initialiser mod√®le\n",
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "criterion = DiceBCELoss(dice_weight=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                        factor=0.5, patience=3)\n",
    "\n",
    "# Entra√Æner\n",
    "num_epochs = 10\n",
    "best_dice = 0\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_dice': [], 'train_iou': [],\n",
    "    'val_loss': [], 'val_dice': [], 'val_iou': []\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Entra√Ænement U-Net sur {num_epochs} epochs\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_dice, train_iou = train_epoch(model, train_loader, \n",
    "                                                     criterion, optimizer, device)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_dice, val_iou = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step(val_dice)\n",
    "    \n",
    "    # Sauvegarder historique\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_dice'].append(train_dice)\n",
    "    history['train_iou'].append(train_iou)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    \n",
    "    # Sauvegarder meilleur mod√®le\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), '/tmp/best_unet.pth')\n",
    "        print(f\"‚úì Meilleur mod√®le sauvegard√© (Dice: {best_dice:.4f})\")\n",
    "    \n",
    "    print(f\"\\nTrain - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}\")\n",
    "    print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Entra√Ænement termin√© ! Meilleur Dice: {best_dice:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'apprentissage\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice\n",
    "axes[1].plot(history['train_dice'], label='Train', marker='o')\n",
    "axes[1].plot(history['val_dice'], label='Val', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Dice Coefficient')\n",
    "axes[1].set_title('Dice Coefficient')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[2].plot(history['train_iou'], label='Train', marker='o')\n",
    "axes[2].plot(history['val_iou'], label='Val', marker='s')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('IoU Score')\n",
    "axes[2].set_title('IoU Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur √©chantillons\n",
    "model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(4):\n",
    "        img, mask = val_dataset[i]\n",
    "        \n",
    "        # Pr√©diction\n",
    "        img_input = img.unsqueeze(0).to(device)\n",
    "        output = model(img_input)\n",
    "        pred_mask = torch.sigmoid(output) > 0.5\n",
    "        \n",
    "        # D√©normaliser image\n",
    "        img_display = img.permute(1, 2, 0).cpu().numpy()\n",
    "        img_display = img_display * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        # M√©triques\n",
    "        dice = dice_coefficient(pred_mask.cpu().float(), mask.unsqueeze(0))\n",
    "        iou = iou_score(pred_mask.cpu().float(), mask.unsqueeze(0))\n",
    "        \n",
    "        # Affichage\n",
    "        axes[i, 0].imshow(img_display)\n",
    "        axes[i, 0].set_title('Image Original')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred_mask.cpu().squeeze(), cmap='gray')\n",
    "        axes[i, 2].set_title(f'Pr√©diction\\nDice={dice:.3f}, IoU={iou:.3f}')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        overlay = img_display.copy()\n",
    "        pred_mask_np = pred_mask.cpu().squeeze().numpy()\n",
    "        overlay[pred_mask_np > 0] = [1, 0, 0]  # Rouge pour pr√©diction\n",
    "        axes[i, 3].imshow(overlay, alpha=0.7)\n",
    "        axes[i, 3].set_title('Overlay')\n",
    "        axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Segmentation Models PyTorch (smp)\n",
    "\n",
    "Utiliser la biblioth√®que `segmentation_models_pytorch` pour des architectures pr√©-entra√Æn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMP_AVAILABLE:\n",
    "    # U-Net avec encoder ResNet34\n",
    "    model_smp = smp.Unet(\n",
    "        encoder_name='resnet34',\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    )\n",
    "    \n",
    "    print(\"U-Net ResNet34 (smp) charg√©\")\n",
    "    print(f\"Param√®tres: {sum(p.numel() for p in model_smp.parameters()) / 1e6:.2f}M\")\n",
    "    \n",
    "    # Autres architectures disponibles\n",
    "    architectures = [\n",
    "        'Unet', 'UnetPlusPlus', 'MAnet', 'Linknet', 'FPN', 'PSPNet',\n",
    "        'DeepLabV3', 'DeepLabV3Plus', 'PAN'\n",
    "    ]\n",
    "    \n",
    "    encoders = [\n",
    "        'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "        'efficientnet-b0', 'efficientnet-b7',\n",
    "        'mobilenet_v2', 'densenet121'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nArchitectures disponibles: {', '.join(architectures)}\")\n",
    "    print(f\"Encoders disponibles: {', '.join(encoders[:5])}...\")\n",
    "else:\n",
    "    print(\"segmentation_models_pytorch non install√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMP_AVAILABLE:\n",
    "    # Exemple : DeepLabV3+ avec ResNet50\n",
    "    model_deeplabv3 = smp.DeepLabV3Plus(\n",
    "        encoder_name='resnet50',\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=3,\n",
    "        classes=1\n",
    "    )\n",
    "    \n",
    "    model_deeplabv3.to(device)\n",
    "    \n",
    "    print(\"DeepLabV3+ ResNet50 charg√©\")\n",
    "    print(f\"Param√®tres: {sum(p.numel() for p in model_deeplabv3.parameters()) / 1e6:.2f}M\")\n",
    "    \n",
    "    # Test inf√©rence\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(1, 3, 256, 256).to(device)\n",
    "        y = model_deeplabv3(x)\n",
    "        print(f\"\\nInput: {x.shape} -> Output: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mask R-CNN pour Segmentation d'Instances\n",
    "\n",
    "Utiliser Mask R-CNN de torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# Charger Mask R-CNN pr√©-entra√Æn√©\n",
    "model_maskrcnn = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model_maskrcnn.to(device)\n",
    "model_maskrcnn.eval()\n",
    "\n",
    "print(\"Mask R-CNN charg√© (pr√©-entra√Æn√© sur COCO)\")\n",
    "print(f\"Param√®tres: {sum(p.numel() for p in model_maskrcnn.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple inf√©rence Mask R-CNN\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    return img\n",
    "\n",
    "# Image test\n",
    "img_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "image = load_image_from_url(img_url)\n",
    "\n",
    "# Transformation\n",
    "transform = transforms.ToTensor()\n",
    "img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Inf√©rence\n",
    "with torch.no_grad():\n",
    "    predictions = model_maskrcnn(img_tensor)\n",
    "\n",
    "pred = predictions[0]\n",
    "print(f\"\\nNombre de d√©tections: {len(pred['boxes'])}\")\n",
    "print(f\"\\nCl√©s: {pred.keys()}\")\n",
    "print(f\"Boxes shape: {pred['boxes'].shape}\")\n",
    "print(f\"Masks shape: {pred['masks'].shape}\")\n",
    "print(f\"Labels: {pred['labels'][:5]}\")\n",
    "print(f\"Scores: {pred['scores'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser r√©sultats Mask R-CNN\n",
    "threshold = 0.7\n",
    "masks = pred['masks'][pred['scores'] > threshold].cpu().numpy()\n",
    "boxes = pred['boxes'][pred['scores'] > threshold].cpu().numpy()\n",
    "labels = pred['labels'][pred['scores'] > threshold].cpu().numpy()\n",
    "scores = pred['scores'][pred['scores'] > threshold].cpu().numpy()\n",
    "\n",
    "COCO_CLASSES = ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Image originale\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('Image Originale')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Image avec masques\n",
    "axes[1].imshow(image)\n",
    "\n",
    "# Overlay masques\n",
    "for i, (mask, box, label, score) in enumerate(zip(masks, boxes, labels, scores)):\n",
    "    # Masque (probabilit√© > 0.5)\n",
    "    mask = mask[0] > 0.5\n",
    "    \n",
    "    # Couleur al√©atoire\n",
    "    color = np.random.rand(3)\n",
    "    \n",
    "    # Appliquer masque\n",
    "    overlay = np.zeros_like(image)\n",
    "    overlay[mask] = (color * 255).astype(np.uint8)\n",
    "    axes[1].imshow(overlay, alpha=0.5)\n",
    "    \n",
    "    # Bounding box\n",
    "    x1, y1, x2, y2 = box\n",
    "    rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                         fill=False, edgecolor=color, linewidth=2)\n",
    "    axes[1].add_patch(rect)\n",
    "    \n",
    "    # Label\n",
    "    class_name = COCO_CLASSES[label] if label < len(COCO_CLASSES) else f'Class {label}'\n",
    "    axes[1].text(x1, y1-5, f'{class_name} {score:.2f}',\n",
    "               bbox=dict(facecolor=color, alpha=0.7), fontsize=10, color='white')\n",
    "\n",
    "axes[1].set_title(f'Mask R-CNN Segmentation ({len(masks)} instances)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√©\n",
    "\n",
    "Dans ce notebook, nous avons explor√© :\n",
    "\n",
    "1. **U-Net Architecture** :\n",
    "   - Encoder-decoder avec skip connections\n",
    "   - Impl√©mentation compl√®te from scratch\n",
    "   - Architecture embl√©matique pour segmentation m√©dicale\n",
    "\n",
    "2. **M√©triques de Segmentation** :\n",
    "   - IoU (Intersection over Union)\n",
    "   - Dice coefficient (F1-score pour segmentation)\n",
    "   - Pixel accuracy\n",
    "\n",
    "3. **Loss Functions** :\n",
    "   - Dice Loss\n",
    "   - Dice + BCE Loss (combinaison)\n",
    "   - Focal Loss (d√©s√©quilibre de classes)\n",
    "\n",
    "4. **Entra√Ænement** :\n",
    "   - Pipeline complet avec validation\n",
    "   - Learning rate scheduling\n",
    "   - Monitoring des m√©triques\n",
    "\n",
    "5. **Segmentation Models PyTorch** :\n",
    "   - Architectures pr√©-entra√Æn√©es (U-Net, DeepLabV3+, etc.)\n",
    "   - Encoders vari√©s (ResNet, EfficientNet, etc.)\n",
    "\n",
    "6. **Mask R-CNN** :\n",
    "   - Segmentation d'instances (vs s√©mantique)\n",
    "   - D√©tection + segmentation en un mod√®le\n",
    "\n",
    "### Points Cl√©s\n",
    "- **U-Net** : architecture de r√©f√©rence pour segmentation (m√©dical)\n",
    "- **Skip connections** : essentielles pour pr√©server d√©tails spatiaux\n",
    "- **Dice coefficient** : m√©trique privil√©gi√©e pour d√©s√©quilibre de classes\n",
    "- **Transfer learning** : utiliser encoders ImageNet (ResNet, etc.)\n",
    "\n",
    "### Prochaines √âtapes\n",
    "- Notebook suivant : Vision Transformers (ViT)\n",
    "- Appliquer sur datasets r√©els (Cityscapes, Medical Decathlon)\n",
    "- Explorer atrous convolutions (DeepLab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}