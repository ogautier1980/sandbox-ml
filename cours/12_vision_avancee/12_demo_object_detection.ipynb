{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "# üöÄ Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogautier1980/sandbox-ml/blob/main/cours/12_vision_avancee/12_demo_object_detection.ipynb)\n",
    "\n",
    "**Si vous ex√©cutez ce notebook sur Google Colab**, ex√©cutez la cellule suivante pour installer les d√©pendances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_install"
   },
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Google Colab uniquement)",
    "",
    "import sys",
    "",
    "IN_COLAB = 'google.colab' in sys.modules",
    "",
    "",
    "",
    "if IN_COLAB:",
    "",
    "    print('üì¶ Installation des packages...')",
    "",
    "    ",
    "",
    "    # Packages ML de base",
    "",
    "    !pip install -q numpy pandas matplotlib seaborn scikit-learn",
    "",
    "    ",
    "",
    "    # D√©tection du chapitre et installation des d√©pendances sp√©cifiques",
    "",
    "    notebook_name = '12_demo_object_detection.ipynb'  # Sera remplac√© automatiquement",
    "",
    "    ",
    "",
    "    # Ch 06-08 : Deep Learning",
    "",
    "    if any(x in notebook_name for x in ['06_', '07_', '08_']):",
    "",
    "        !pip install -q torch torchvision torchaudio",
    "",
    "    ",
    "",
    "    # Ch 08 : NLP",
    "",
    "    if '08_' in notebook_name:",
    "",
    "        !pip install -q transformers datasets tokenizers",
    "",
    "        if 'rag' in notebook_name:",
    "",
    "            !pip install -q sentence-transformers faiss-cpu rank-bm25",
    "",
    "    ",
    "",
    "    # Ch 09 : Reinforcement Learning",
    "",
    "    if '09_' in notebook_name:",
    "",
    "        !pip install -q gymnasium[classic-control]",
    "",
    "    ",
    "",
    "    # Ch 04 : Boosting",
    "",
    "    if '04_' in notebook_name and 'boosting' in notebook_name:",
    "",
    "        !pip install -q xgboost lightgbm catboost",
    "",
    "    ",
    "",
    "    # Ch 05 : Clustering avanc√©",
    "",
    "    if '05_' in notebook_name:",
    "",
    "        !pip install -q umap-learn",
    "",
    "    ",
    "",
    "    # Ch 11 : S√©ries temporelles",
    "",
    "    if '11_' in notebook_name:",
    "",
    "        !pip install -q statsmodels prophet",
    "",
    "    ",
    "",
    "    # Ch 12 : Vision avanc√©e",
    "",
    "    if '12_' in notebook_name:",
    "",
    "        !pip install -q ultralytics timm segmentation-models-pytorch",
    "",
    "    ",
    "",
    "    # Ch 13 : Recommandation",
    "",
    "    if '13_' in notebook_name:",
    "",
    "        !pip install -q scikit-surprise implicit",
    "",
    "    ",
    "",
    "    # Ch 14 : MLOps",
    "",
    "    if '14_' in notebook_name:",
    "",
    "        !pip install -q mlflow fastapi pydantic",
    "",
    "    ",
    "",
    "    print('‚úÖ Installation termin√©e !')",
    "",
    "else:",
    "",
    "    print('‚ÑπÔ∏è  Environnement local d√©tect√©, les packages sont d√©j√† install√©s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapitre 13 - D√©tection d'Objets avec YOLO\n",
    "\n",
    "Ce notebook explore la **d√©tection d'objets** avec les architectures YOLO (You Only Look Once).\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre les architectures de d√©tection (R-CNN vs YOLO)\n",
    "- Utiliser YOLOv5 et YOLOv8 pour la d√©tection temps r√©el\n",
    "- Entra√Æner un d√©tecteur sur un dataset custom\n",
    "- √âvaluer avec les m√©triques IoU, mAP\n",
    "- Impl√©menter Non-Maximum Suppression (NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.ops import nms, box_iou\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "# YOLOv8 (Ultralytics)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    YOLO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ultralytics not installed. Install with: pip install ultralytics\")\n",
    "    YOLO_AVAILABLE = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fondamentaux : IoU et NMS\n",
    "\n",
    "### 1.1 Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calcule l'IoU entre deux bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        box1, box2: [x1, y1, x2, y2] format (coin sup gauche, coin inf droit)\n",
    "    \n",
    "    Returns:\n",
    "        IoU score (0-1)\n",
    "    \"\"\"\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    \n",
    "    # Aire de l'intersection\n",
    "    inter_width = max(0, x2_inter - x1_inter)\n",
    "    inter_height = max(0, y2_inter - y1_inter)\n",
    "    inter_area = inter_width * inter_height\n",
    "    \n",
    "    # Aires des boxes\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    # Union = box1 + box2 - intersection\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Exemple\n",
    "box_gt = [50, 50, 150, 150]  # Ground truth\n",
    "box_pred1 = [60, 60, 160, 160]  # Bonne pr√©diction\n",
    "box_pred2 = [200, 200, 300, 300]  # Mauvaise pr√©diction\n",
    "\n",
    "iou1 = compute_iou(box_gt, box_pred1)\n",
    "iou2 = compute_iou(box_gt, box_pred2)\n",
    "\n",
    "print(f\"IoU (bonne d√©tection): {iou1:.3f}\")\n",
    "print(f\"IoU (mauvaise d√©tection): {iou2:.3f}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, box_pred, iou, title in zip(axes, [box_pred1, box_pred2], [iou1, iou2], \n",
    "                                     ['Bonne d√©tection', 'Mauvaise d√©tection']):\n",
    "    ax.set_xlim(0, 400)\n",
    "    ax.set_ylim(0, 400)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Ground truth (vert)\n",
    "    rect_gt = patches.Rectangle((box_gt[0], box_gt[1]), \n",
    "                                box_gt[2]-box_gt[0], box_gt[3]-box_gt[1],\n",
    "                                linewidth=2, edgecolor='green', facecolor='none', label='Ground Truth')\n",
    "    ax.add_patch(rect_gt)\n",
    "    \n",
    "    # Pr√©diction (rouge)\n",
    "    rect_pred = patches.Rectangle((box_pred[0], box_pred[1]), \n",
    "                                  box_pred[2]-box_pred[0], box_pred[3]-box_pred[1],\n",
    "                                  linewidth=2, edgecolor='red', facecolor='none', label='Prediction')\n",
    "    ax.add_patch(rect_pred)\n",
    "    \n",
    "    ax.set_title(f'{title}\\nIoU = {iou:.3f}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Non-Maximum Suppression (NMS)\n",
    "\n",
    "NMS √©limine les d√©tections redondantes (plusieurs boxes pour le m√™me objet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Applique Non-Maximum Suppression.\n",
    "    \n",
    "    Args:\n",
    "        boxes: Tensor [N, 4] de bounding boxes\n",
    "        scores: Tensor [N] de scores de confiance\n",
    "        iou_threshold: Seuil IoU pour supprimer boxes chevauchantes\n",
    "    \n",
    "    Returns:\n",
    "        indices: Indices des boxes √† garder\n",
    "    \"\"\"\n",
    "    # Trier par score d√©croissant\n",
    "    sorted_indices = torch.argsort(scores, descending=True)\n",
    "    \n",
    "    keep = []\n",
    "    \n",
    "    while len(sorted_indices) > 0:\n",
    "        # Garder la box avec le meilleur score\n",
    "        current = sorted_indices[0]\n",
    "        keep.append(current.item())\n",
    "        \n",
    "        if len(sorted_indices) == 1:\n",
    "            break\n",
    "        \n",
    "        # Calculer IoU avec les autres boxes\n",
    "        current_box = boxes[current].unsqueeze(0)\n",
    "        other_boxes = boxes[sorted_indices[1:]]\n",
    "        ious = box_iou(current_box, other_boxes)[0]\n",
    "        \n",
    "        # Garder seulement les boxes avec IoU < threshold\n",
    "        mask = ious < iou_threshold\n",
    "        sorted_indices = sorted_indices[1:][mask]\n",
    "    \n",
    "    return torch.tensor(keep)\n",
    "\n",
    "# Exemple : Plusieurs d√©tections pour le m√™me objet\n",
    "boxes = torch.tensor([\n",
    "    [100, 100, 200, 200],  # Box 1\n",
    "    [110, 110, 210, 210],  # Box 2 (tr√®s chevauchante avec 1)\n",
    "    [120, 120, 220, 220],  # Box 3 (tr√®s chevauchante avec 1 et 2)\n",
    "    [300, 300, 400, 400],  # Box 4 (objet diff√©rent)\n",
    "], dtype=torch.float32)\n",
    "\n",
    "scores = torch.tensor([0.9, 0.85, 0.7, 0.95])  # Scores de confiance\n",
    "\n",
    "# Appliquer NMS\n",
    "keep_indices = non_max_suppression(boxes, scores, iou_threshold=0.5)\n",
    "\n",
    "print(f\"Boxes avant NMS: {len(boxes)}\")\n",
    "print(f\"Boxes apr√®s NMS: {len(keep_indices)}\")\n",
    "print(f\"Indices gard√©s: {keep_indices.tolist()}\")\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, title, show_all in zip(axes, ['Avant NMS', 'Apr√®s NMS'], [True, False]):\n",
    "    ax.set_xlim(0, 500)\n",
    "    ax.set_ylim(0, 500)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    indices_to_show = range(len(boxes)) if show_all else keep_indices\n",
    "    \n",
    "    for i in indices_to_show:\n",
    "        box = boxes[i]\n",
    "        score = scores[i]\n",
    "        \n",
    "        color = 'green' if i in keep_indices else 'red'\n",
    "        alpha = 1.0 if i in keep_indices else 0.3\n",
    "        \n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
    "                                linewidth=2, edgecolor=color, facecolor='none', alpha=alpha)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(box[0], box[1]-5, f'Box {i} ({score:.2f})', color=color)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Faster R-CNN avec torchvision\n",
    "\n",
    "Faster R-CNN est un d√©tecteur two-stage (RPN + d√©tection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger mod√®le pr√©-entra√Æn√© Faster R-CNN (COCO dataset)\n",
    "model_frcnn = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_frcnn.to(device)\n",
    "model_frcnn.eval()\n",
    "\n",
    "# Classes COCO (91 classes)\n",
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "print(f\"Mod√®le charg√© : Faster R-CNN ResNet50-FPN\")\n",
    "print(f\"Nombre de classes : {len(COCO_CLASSES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_url(url):\n",
    "    \"\"\"Charge une image depuis une URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    return img\n",
    "\n",
    "def detect_faster_rcnn(image, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    D√©tecte des objets avec Faster R-CNN.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        model: Mod√®le Faster R-CNN\n",
    "        threshold: Seuil de confiance minimum\n",
    "    \n",
    "    Returns:\n",
    "        boxes, labels, scores\n",
    "    \"\"\"\n",
    "    # Transformation\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Inf√©rence\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # Extraire r√©sultats\n",
    "    pred = predictions[0]\n",
    "    boxes = pred['boxes'].cpu()\n",
    "    labels = pred['labels'].cpu()\n",
    "    scores = pred['scores'].cpu()\n",
    "    \n",
    "    # Filtrer par threshold\n",
    "    mask = scores > threshold\n",
    "    boxes = boxes[mask]\n",
    "    labels = labels[mask]\n",
    "    scores = scores[mask]\n",
    "    \n",
    "    return boxes, labels, scores, inference_time\n",
    "\n",
    "def visualize_detections(image, boxes, labels, scores, class_names):\n",
    "    \"\"\"Visualise les d√©tections.\"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        \n",
    "        # Rectangle\n",
    "        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                                linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Label\n",
    "        class_name = class_names[label]\n",
    "        ax.text(x1, y1-5, f'{class_name} {score:.2f}',\n",
    "               bbox=dict(facecolor='red', alpha=0.5), fontsize=10, color='white')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemple : d√©tecter dans une image\n",
    "img_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "image = load_image_from_url(img_url)\n",
    "\n",
    "boxes, labels, scores, inference_time = detect_faster_rcnn(image, model_frcnn, threshold=0.7)\n",
    "\n",
    "print(f\"\\n=== Faster R-CNN R√©sultats ===\")\n",
    "print(f\"Temps d'inf√©rence: {inference_time:.3f}s\")\n",
    "print(f\"Nombre de d√©tections: {len(boxes)}\")\n",
    "print(f\"\\nD√©tections:\")\n",
    "for i, (label, score) in enumerate(zip(labels, scores)):\n",
    "    print(f\"  {i+1}. {COCO_CLASSES[label]} (confiance: {score:.3f})\")\n",
    "\n",
    "visualize_detections(image, boxes, labels, scores, COCO_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOv8 avec Ultralytics\n",
    "\n",
    "YOLO est beaucoup plus rapide que Faster R-CNN (one-stage detector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    # Charger YOLOv8 nano (le plus rapide)\n",
    "    model_yolo = YOLO('yolov8n.pt')\n",
    "    \n",
    "    print(\"YOLOv8 nano charg√©\")\n",
    "    print(f\"Nombre de param√®tres: {sum(p.numel() for p in model_yolo.model.parameters()) / 1e6:.1f}M\")\n",
    "else:\n",
    "    print(\"YOLOv8 non disponible. Installer avec: pip install ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    # Inf√©rence avec YOLOv8\n",
    "    results = model_yolo(img_url)\n",
    "    \n",
    "    # Afficher r√©sultats\n",
    "    result = results[0]\n",
    "    \n",
    "    print(f\"\\n=== YOLOv8 R√©sultats ===\")\n",
    "    print(f\"Temps d'inf√©rence: {result.speed['inference']:.1f}ms\")\n",
    "    print(f\"Nombre de d√©tections: {len(result.boxes)}\")\n",
    "    print(f\"\\nD√©tections:\")\n",
    "    \n",
    "    for i, box in enumerate(result.boxes):\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        label = model_yolo.names[cls]\n",
    "        print(f\"  {i+1}. {label} (confiance: {conf:.3f})\")\n",
    "    \n",
    "    # Visualisation (YOLOv8 a une fonction plot int√©gr√©e)\n",
    "    result_img = result.plot()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('YOLOv8 D√©tections')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparaison Faster R-CNN vs YOLOv8\n",
    "\n",
    "Comparons les performances en vitesse et pr√©cision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    # Tester sur plusieurs images\n",
    "    test_images = [\n",
    "        \"https://ultralytics.com/images/bus.jpg\",\n",
    "        \"https://ultralytics.com/images/zidane.jpg\",\n",
    "    ]\n",
    "    \n",
    "    frcnn_times = []\n",
    "    yolo_times = []\n",
    "    \n",
    "    print(\"Benchmark Faster R-CNN vs YOLOv8...\\n\")\n",
    "    \n",
    "    for url in test_images:\n",
    "        img = load_image_from_url(url)\n",
    "        \n",
    "        # Faster R-CNN\n",
    "        _, _, _, frcnn_time = detect_faster_rcnn(img, model_frcnn, threshold=0.7)\n",
    "        frcnn_times.append(frcnn_time)\n",
    "        \n",
    "        # YOLOv8\n",
    "        start = time.time()\n",
    "        _ = model_yolo(img)\n",
    "        yolo_time = time.time() - start\n",
    "        yolo_times.append(yolo_time)\n",
    "        \n",
    "        print(f\"Image: {url.split('/')[-1]}\")\n",
    "        print(f\"  Faster R-CNN: {frcnn_time:.3f}s\")\n",
    "        print(f\"  YOLOv8: {yolo_time:.3f}s\")\n",
    "        print(f\"  Speedup: {frcnn_time/yolo_time:.1f}x\\n\")\n",
    "    \n",
    "    # Moyenne\n",
    "    avg_frcnn = np.mean(frcnn_times)\n",
    "    avg_yolo = np.mean(yolo_times)\n",
    "    \n",
    "    print(f\"=== Moyennes ===\")\n",
    "    print(f\"Faster R-CNN: {avg_frcnn:.3f}s ({1/avg_frcnn:.1f} FPS)\")\n",
    "    print(f\"YOLOv8: {avg_yolo:.3f}s ({1/avg_yolo:.1f} FPS)\")\n",
    "    print(f\"YOLOv8 est {avg_frcnn/avg_yolo:.1f}x plus rapide\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    models = ['Faster R-CNN', 'YOLOv8']\n",
    "    times = [avg_frcnn * 1000, avg_yolo * 1000]  # en ms\n",
    "    fps = [1/avg_frcnn, 1/avg_yolo]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, times, width, label='Temps (ms)', alpha=0.8)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.bar(x + width/2, fps, width, label='FPS', color='orange', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Temps (ms)')\n",
    "    ax2.set_ylabel('FPS')\n",
    "    ax.set_xlabel('Mod√®le')\n",
    "    ax.set_title('Comparaison Vitesse : Faster R-CNN vs YOLOv8')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entra√Ænement YOLOv8 sur Dataset Custom\n",
    "\n",
    "Entra√Æner YOLOv8 sur un dataset au format COCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    # Configuration dataset (format YAML)\n",
    "    dataset_config = \"\"\"\n",
    "# Dataset configuration for YOLOv8\n",
    "path: /workspace/data/custom_detection  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/val  # val images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: person\n",
    "  1: car\n",
    "  2: bike\n",
    "\"\"\"\n",
    "    \n",
    "    # Sauvegarder config\n",
    "    import yaml\n",
    "    config_path = '/tmp/custom_dataset.yaml'\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(dataset_config)\n",
    "    \n",
    "    print(\"Configuration dataset cr√©√©e\")\n",
    "    print(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    # Entra√Ænement (exemple - n√©cessite un dataset r√©el)\n",
    "    # ATTENTION: Cette cellule n√©cessite un dataset au format YOLO\n",
    "    \n",
    "    # Structure attendue:\n",
    "    # custom_detection/\n",
    "    #   ‚îú‚îÄ‚îÄ images/\n",
    "    #   ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "    #   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
    "    #   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img2.jpg\n",
    "    #   ‚îÇ   ‚îî‚îÄ‚îÄ val/\n",
    "    #   ‚îÇ       ‚îú‚îÄ‚îÄ img1.jpg\n",
    "    #   ‚îÇ       ‚îî‚îÄ‚îÄ img2.jpg\n",
    "    #   ‚îî‚îÄ‚îÄ labels/\n",
    "    #       ‚îú‚îÄ‚îÄ train/\n",
    "    #       ‚îÇ   ‚îú‚îÄ‚îÄ img1.txt  # Format: <class> <x_center> <y_center> <width> <height> (normalized)\n",
    "    #       ‚îÇ   ‚îî‚îÄ‚îÄ img2.txt\n",
    "    #       ‚îî‚îÄ‚îÄ val/\n",
    "    #           ‚îú‚îÄ‚îÄ img1.txt\n",
    "    #           ‚îî‚îÄ‚îÄ img2.txt\n",
    "    \n",
    "    print(\"\"\"Pour entra√Æner YOLOv8 sur un dataset custom:\n",
    "    \n",
    "1. Pr√©parer les donn√©es au format YOLO\n",
    "2. Cr√©er un fichier YAML de configuration\n",
    "3. Lancer l'entra√Ænement:\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # partir du mod√®le pr√©-entra√Æn√©\n",
    "results = model.train(\n",
    "    data='custom_dataset.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='yolov8_custom',\n",
    "    patience=50,  # early stopping\n",
    "    save=True,\n",
    "    device=0  # GPU 0\n",
    ")\n",
    "\n",
    "4. √âvaluer:\n",
    "\n",
    "metrics = model.val()\n",
    "print(f\"mAP50: {metrics.box.map50}\")\n",
    "print(f\"mAP50-95: {metrics.box.map}\")\n",
    "\n",
    "5. Inf√©rence:\n",
    "\n",
    "model = YOLO('runs/detect/yolov8_custom/weights/best.pt')\n",
    "results = model('path/to/image.jpg')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. M√©triques d'√âvaluation : mAP\n",
    "\n",
    "Calculer la Mean Average Precision pour √©valuer un d√©tecteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall(pred_boxes, pred_scores, gt_boxes, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calcule la courbe Precision-Recall.\n",
    "    \n",
    "    Args:\n",
    "        pred_boxes: Tensor [N, 4] de pr√©dictions\n",
    "        pred_scores: Tensor [N] de scores\n",
    "        gt_boxes: Tensor [M, 4] de ground truths\n",
    "        iou_threshold: Seuil IoU pour consid√©rer une d√©tection correcte\n",
    "    \n",
    "    Returns:\n",
    "        precisions, recalls\n",
    "    \"\"\"\n",
    "    # Trier pr√©dictions par score d√©croissant\n",
    "    sorted_indices = torch.argsort(pred_scores, descending=True)\n",
    "    pred_boxes = pred_boxes[sorted_indices]\n",
    "    pred_scores = pred_scores[sorted_indices]\n",
    "    \n",
    "    n_gt = len(gt_boxes)\n",
    "    tp = torch.zeros(len(pred_boxes))\n",
    "    fp = torch.zeros(len(pred_boxes))\n",
    "    \n",
    "    detected_gt = set()\n",
    "    \n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        # Calculer IoU avec tous les GT\n",
    "        ious = box_iou(pred_box.unsqueeze(0), gt_boxes)[0]\n",
    "        max_iou, max_idx = ious.max(0)\n",
    "        \n",
    "        if max_iou >= iou_threshold and max_idx.item() not in detected_gt:\n",
    "            # True Positive\n",
    "            tp[i] = 1\n",
    "            detected_gt.add(max_idx.item())\n",
    "        else:\n",
    "            # False Positive\n",
    "            fp[i] = 1\n",
    "    \n",
    "    # Calcul cumulatif\n",
    "    tp_cumsum = torch.cumsum(tp, dim=0)\n",
    "    fp_cumsum = torch.cumsum(fp, dim=0)\n",
    "    \n",
    "    # Precision et Recall\n",
    "    precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-10)\n",
    "    recalls = tp_cumsum / n_gt\n",
    "    \n",
    "    return precisions.numpy(), recalls.numpy()\n",
    "\n",
    "def compute_ap(precisions, recalls):\n",
    "    \"\"\"Calcule Average Precision (aire sous courbe PR).\"\"\"\n",
    "    # Ajouter points (0, 1) et (1, 0)\n",
    "    precisions = np.concatenate([[0], precisions, [0]])\n",
    "    recalls = np.concatenate([[0], recalls, [1]])\n",
    "    \n",
    "    # Interpolation\n",
    "    for i in range(len(precisions) - 2, -1, -1):\n",
    "        precisions[i] = max(precisions[i], precisions[i + 1])\n",
    "    \n",
    "    # Calcul aire (m√©thode des rectangles)\n",
    "    indices = np.where(recalls[1:] != recalls[:-1])[0] + 1\n",
    "    ap = np.sum((recalls[indices] - recalls[indices - 1]) * precisions[indices])\n",
    "    \n",
    "    return ap\n",
    "\n",
    "# Exemple\n",
    "pred_boxes = torch.tensor([\n",
    "    [50, 50, 150, 150],\n",
    "    [55, 55, 155, 155],\n",
    "    [200, 200, 300, 300],\n",
    "    [210, 210, 310, 310],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "pred_scores = torch.tensor([0.9, 0.85, 0.8, 0.75])\n",
    "\n",
    "gt_boxes = torch.tensor([\n",
    "    [50, 50, 150, 150],\n",
    "    [200, 200, 300, 300],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "precisions, recalls = compute_precision_recall(pred_boxes, pred_scores, gt_boxes, iou_threshold=0.5)\n",
    "ap = compute_ap(precisions, recalls)\n",
    "\n",
    "print(f\"Average Precision (AP@0.5): {ap:.3f}\")\n",
    "\n",
    "# Visualiser courbe PR\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions, marker='o', linewidth=2)\n",
    "plt.fill_between(recalls, precisions, alpha=0.3)\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title(f'Precision-Recall Curve (AP = {ap:.3f})', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. D√©tection Temps R√©el sur Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO_AVAILABLE:\n",
    "    print(\"\"\"Pour utiliser YOLOv8 en temps r√©el sur webcam:\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # D√©tection\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Affichage\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow('YOLOv8 Detection', annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Ou encore plus simple:\n",
    "model.predict(source=0, show=True)  # 0 = webcam\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√©\n",
    "\n",
    "Dans ce notebook, nous avons explor√© :\n",
    "\n",
    "1. **Fondamentaux** :\n",
    "   - IoU (Intersection over Union) pour mesurer chevauchement\n",
    "   - NMS (Non-Maximum Suppression) pour √©liminer d√©tections redondantes\n",
    "\n",
    "2. **Faster R-CNN** (two-stage) :\n",
    "   - RPN + RoI Pooling + classification/r√©gression\n",
    "   - Pr√©cis mais lent (~5 FPS)\n",
    "\n",
    "3. **YOLOv8** (one-stage) :\n",
    "   - D√©tection en une seule passe\n",
    "   - Tr√®s rapide (~80 FPS) pour temps r√©el\n",
    "   - API Ultralytics simple et moderne\n",
    "\n",
    "4. **M√©triques** :\n",
    "   - Courbe Precision-Recall\n",
    "   - Average Precision (AP)\n",
    "   - Mean Average Precision (mAP)\n",
    "\n",
    "5. **Applications** :\n",
    "   - D√©tection d'objets dans images/vid√©os\n",
    "   - Entra√Ænement sur datasets customs\n",
    "   - D√©tection temps r√©el webcam\n",
    "\n",
    "### Points Cl√©s\n",
    "- **Trade-off vitesse/pr√©cision** : Faster R-CNN (pr√©cis) vs YOLO (rapide)\n",
    "- **Transfer learning** : toujours partir d'un mod√®le pr√©-entra√Æn√© (COCO)\n",
    "- **mAP** : m√©trique standard pour √©valuer d√©tecteurs\n",
    "- **NMS** : essentiel pour √©liminer d√©tections multiples\n",
    "\n",
    "### Prochaines √âtapes\n",
    "- Notebook suivant : Segmentation s√©mantique (U-Net)\n",
    "- Explorer d'autres architectures : RetinaNet, EfficientDet\n",
    "- Appliquer √† vos propres donn√©es"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}